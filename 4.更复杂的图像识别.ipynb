{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True  #Tab代码自动提示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据\n",
    "用wget下载，这个url需要科学上网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "# 测试集\n",
    "url = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip'\n",
    "target = './tmp/validation-horse-or-human.zip'\n",
    "\n",
    "file_name = wget.download(url, out = target)\n",
    "\n",
    "# 训练集\n",
    "url = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip'\n",
    "target = './tmp/horse-or-human.zip'\n",
    "\n",
    "file_name = wget.download(url, out = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四部分 更复杂的图像识别\n",
    "## 4.2 ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建两个数据生成器，指定scaling范围0-1\n",
    "train_datagen = ImageDataGenerator(rescale = 1 / 255)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 指向训练数据文件夹\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './tmp/horse-or-human/',    # 训练数据所在的文件夹\n",
    "    target_size = (300, 300),   # 指定输出尺寸\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'       # 指定二分类\n",
    ")\n",
    "\n",
    "# 指向测试数据文件夹\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    './tmp/validation-horse-or-human/',\n",
    "    target_size = (300, 300),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 构建并训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               40141312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 40,165,409\n",
      "Trainable params: 40,165,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, (3, 3), activation = 'relu', \n",
    "                        input_shape = (300, 300, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/15\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 1.0132 - acc: 0.7936 - val_loss: 2.4316 - val_acc: 0.6094\n",
      "Epoch 2/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 0.1492 - acc: 0.9445 - val_loss: 5.1020 - val_acc: 0.6055\n",
      "Epoch 3/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 0.0986 - acc: 0.9688 - val_loss: 4.1372 - val_acc: 0.6367\n",
      "Epoch 4/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 0.1244 - acc: 0.9542 - val_loss: 2.0506 - val_acc: 0.8047\n",
      "Epoch 5/15\n",
      "33/33 [==============================] - 4s 132ms/step - loss: 0.0183 - acc: 0.9942 - val_loss: 2.4656 - val_acc: 0.8086\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 0.6976 - acc: 0.9903 - val_loss: 4.5152 - val_acc: 0.7422\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 1.5327e-04 - acc: 1.0000 - val_loss: 4.9781 - val_acc: 0.7344\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 0.1209 - acc: 0.9796 - val_loss: 2.4167 - val_acc: 0.8086\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 3.6559 - val_acc: 0.7461\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - 4s 132ms/step - loss: 9.7801e-05 - acc: 1.0000 - val_loss: 4.9720 - val_acc: 0.7266\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 0.7546 - acc: 0.9766 - val_loss: 5.4993 - val_acc: 0.6836\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 0.0055 - acc: 0.9971 - val_loss: 4.8537 - val_acc: 0.7422\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - 4s 132ms/step - loss: 7.0494e-05 - acc: 1.0000 - val_loss: 5.4274 - val_acc: 0.7461\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 2.0134e-05 - acc: 1.0000 - val_loss: 6.2111 - val_acc: 0.7344\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 5.3614e-06 - acc: 1.0000 - val_loss: 7.3203 - val_acc: 0.7188\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 优化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        hp.Choice('input_layer0',values=[16,64],default=16),\n",
    "        (3, 3), \n",
    "        activation = 'relu', \n",
    "        input_shape = (300, 300, 3)\n",
    "    ))\n",
    "    model.add(keras.layers.MaxPooling2D(2, 2))\n",
    "        \n",
    "    for i in range(hp.Int('num_conv_layers',1,3)):\n",
    "        model.add(keras.layers.Conv2D(\n",
    "            hp.Choice('conv2d_layer{0}'.format(i), values=[16,64],default=16), \n",
    "            (3, 3), \n",
    "            activation = 'relu'\n",
    "        ))\n",
    "        model.add(keras.layers.MaxPooling2D(2, 2))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(hp.Int('dense_layer0',128,512,step=32), activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "                  metrics=['acc']\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               10913920  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,916,817\n",
      "Trainable params: 10,916,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2508928   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,557,009\n",
      "Trainable params: 2,557,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 1:32 - loss: 0.7522 - acc: 0.0000e+0 - ETA: 58s - loss: 3.4517 - acc: 0.4286    - ETA: 38s - loss: 2.5292 - acc: 0.49 - ETA: 28s - loss: 2.2988 - acc: 0.48 - ETA: 22s - loss: 1.9949 - acc: 0.48 - ETA: 18s - loss: 1.7780 - acc: 0.46 - ETA: 15s - loss: 1.6229 - acc: 0.51 - ETA: 13s - loss: 1.5064 - acc: 0.55 - ETA: 11s - loss: 1.4135 - acc: 0.58 - ETA: 10s - loss: 1.3450 - acc: 0.57 - ETA: 8s - loss: 1.2852 - acc: 0.5820 - ETA: 7s - loss: 1.2345 - acc: 0.602 - ETA: 7s - loss: 1.1984 - acc: 0.586 - ETA: 6s - loss: 1.1647 - acc: 0.580 - ETA: 5s - loss: 1.1316 - acc: 0.576 - ETA: 5s - loss: 1.1034 - acc: 0.561 - ETA: 4s - loss: 1.0778 - acc: 0.559 - ETA: 4s - loss: 1.0556 - acc: 0.559 - ETA: 3s - loss: 1.0430 - acc: 0.549 - ETA: 3s - loss: 1.0233 - acc: 0.548 - ETA: 3s - loss: 1.0024 - acc: 0.549 - ETA: 2s - loss: 0.9999 - acc: 0.542 - ETA: 2s - loss: 0.9838 - acc: 0.538 - ETA: 2s - loss: 0.9710 - acc: 0.546 - ETA: 1s - loss: 0.9590 - acc: 0.553 - ETA: 1s - loss: 0.9473 - acc: 0.567 - ETA: 1s - loss: 0.9344 - acc: 0.577 - ETA: 1s - loss: 0.9457 - acc: 0.574 - ETA: 0s - loss: 0.9359 - acc: 0.578 - ETA: 0s - loss: 0.9262 - acc: 0.580 - ETA: 0s - loss: 0.9178 - acc: 0.578 - ETA: 0s - loss: 0.9108 - acc: 0.572 - 8s 233ms/step - loss: 0.9030 - acc: 0.5755 - val_loss: 0.5605 - val_acc: 0.6406\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.5526 - acc: 0.656 - ETA: 5s - loss: 0.4615 - acc: 0.812 - ETA: 4s - loss: 0.3994 - acc: 0.822 - ETA: 4s - loss: 1.6210 - acc: 0.765 - ETA: 3s - loss: 1.3747 - acc: 0.768 - ETA: 3s - loss: 1.2362 - acc: 0.729 - ETA: 3s - loss: 1.1266 - acc: 0.741 - ETA: 3s - loss: 1.0742 - acc: 0.742 - ETA: 3s - loss: 1.0261 - acc: 0.725 - ETA: 3s - loss: 0.9595 - acc: 0.743 - ETA: 2s - loss: 0.9138 - acc: 0.747 - ETA: 2s - loss: 0.8671 - acc: 0.750 - ETA: 2s - loss: 0.8222 - acc: 0.759 - ETA: 2s - loss: 0.7758 - acc: 0.774 - ETA: 2s - loss: 0.7419 - acc: 0.785 - ETA: 2s - loss: 0.7231 - acc: 0.789 - ETA: 2s - loss: 0.7026 - acc: 0.790 - ETA: 1s - loss: 0.6830 - acc: 0.789 - ETA: 1s - loss: 0.6648 - acc: 0.792 - ETA: 1s - loss: 0.6412 - acc: 0.800 - ETA: 1s - loss: 0.9469 - acc: 0.783 - ETA: 1s - loss: 0.9327 - acc: 0.772 - ETA: 1s - loss: 0.9115 - acc: 0.771 - ETA: 0s - loss: 0.9001 - acc: 0.765 - ETA: 0s - loss: 0.8812 - acc: 0.768 - ETA: 0s - loss: 0.8620 - acc: 0.773 - ETA: 0s - loss: 0.8456 - acc: 0.776 - ETA: 0s - loss: 0.8225 - acc: 0.783 - ETA: 0s - loss: 0.8119 - acc: 0.784 - ETA: 0s - loss: 0.8007 - acc: 0.784 - ETA: 0s - loss: 0.7899 - acc: 0.781 - 5s 143ms/step - loss: 0.7788 - acc: 0.7829 - val_loss: 0.8276 - val_acc: 0.6992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_layer0: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.69921875</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 341056)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 416)               141879712 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 417       \n",
      "=================================================================\n",
      "Total params: 141,918,849\n",
      "Trainable params: 141,918,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 20s - loss: 0.6941 - acc: 0.56 - ETA: 11s - loss: 56.3436 - acc: 0.625 - ETA: 8s - loss: 87.0077 - acc: 0.552 - ETA: 7s - loss: 67.0987 - acc: 0.51 - ETA: 6s - loss: 53.9631 - acc: 0.51 - ETA: 5s - loss: 48.8141 - acc: 0.50 - ETA: 5s - loss: 41.9231 - acc: 0.53 - ETA: 4s - loss: 36.7371 - acc: 0.56 - ETA: 4s - loss: 32.7826 - acc: 0.58 - ETA: 4s - loss: 31.1390 - acc: 0.59 - ETA: 3s - loss: 26.0186 - acc: 0.60 - ETA: 3s - loss: 24.0556 - acc: 0.61 - ETA: 2s - loss: 22.3758 - acc: 0.61 - ETA: 2s - loss: 20.9147 - acc: 0.62 - ETA: 2s - loss: 19.6369 - acc: 0.63 - ETA: 2s - loss: 18.5077 - acc: 0.64 - ETA: 2s - loss: 17.5119 - acc: 0.63 - ETA: 2s - loss: 16.6098 - acc: 0.64 - ETA: 1s - loss: 15.7911 - acc: 0.66 - ETA: 1s - loss: 15.0487 - acc: 0.67 - ETA: 1s - loss: 14.4153 - acc: 0.67 - ETA: 1s - loss: 13.9505 - acc: 0.65 - ETA: 1s - loss: 13.5206 - acc: 0.64 - ETA: 1s - loss: 13.0047 - acc: 0.65 - ETA: 0s - loss: 12.5289 - acc: 0.65 - ETA: 0s - loss: 12.0721 - acc: 0.66 - ETA: 0s - loss: 11.6440 - acc: 0.68 - ETA: 0s - loss: 11.2476 - acc: 0.68 - ETA: 0s - loss: 10.9163 - acc: 0.68 - ETA: 0s - loss: 10.5998 - acc: 0.67 - ETA: 0s - loss: 10.2768 - acc: 0.68 - 7s 211ms/step - loss: 9.9782 - acc: 0.6943 - val_loss: 1.1324 - val_acc: 0.7227\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 7s - loss: 0.1282 - acc: 0.937 - ETA: 5s - loss: 0.0999 - acc: 0.968 - ETA: 4s - loss: 0.1154 - acc: 0.958 - ETA: 4s - loss: 0.1242 - acc: 0.960 - ETA: 4s - loss: 0.1231 - acc: 0.956 - ETA: 3s - loss: 0.1113 - acc: 0.963 - ETA: 3s - loss: 0.1018 - acc: 0.968 - ETA: 3s - loss: 0.1034 - acc: 0.968 - ETA: 3s - loss: 0.1092 - acc: 0.968 - ETA: 3s - loss: 0.1075 - acc: 0.971 - ETA: 3s - loss: 0.1053 - acc: 0.971 - ETA: 2s - loss: 0.1097 - acc: 0.963 - ETA: 2s - loss: 0.1022 - acc: 0.966 - ETA: 2s - loss: 0.0967 - acc: 0.968 - ETA: 2s - loss: 0.0906 - acc: 0.970 - ETA: 2s - loss: 0.0854 - acc: 0.972 - ETA: 1s - loss: 0.0789 - acc: 0.972 - ETA: 1s - loss: 0.1152 - acc: 0.962 - ETA: 1s - loss: 0.1842 - acc: 0.942 - ETA: 1s - loss: 0.1834 - acc: 0.942 - ETA: 1s - loss: 0.3105 - acc: 0.920 - ETA: 1s - loss: 0.3005 - acc: 0.922 - ETA: 1s - loss: 0.2956 - acc: 0.921 - ETA: 1s - loss: 0.2908 - acc: 0.920 - ETA: 0s - loss: 0.2883 - acc: 0.920 - ETA: 0s - loss: 0.2821 - acc: 0.922 - ETA: 0s - loss: 0.2763 - acc: 0.922 - ETA: 0s - loss: 0.3257 - acc: 0.917 - ETA: 0s - loss: 0.3691 - acc: 0.907 - ETA: 0s - loss: 0.3614 - acc: 0.909 - ETA: 0s - loss: 0.3520 - acc: 0.912 - 7s 198ms/step - loss: 0.3450 - acc: 0.9133 - val_loss: 0.5502 - val_acc: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_layer0: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_conv_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.84375</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 448)               1835456   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 449       \n",
      "=================================================================\n",
      "Total params: 1,851,569\n",
      "Trainable params: 1,851,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 36s - loss: 0.6940 - acc: 0.43 - ETA: 18s - loss: 2.6289 - acc: 0.45 - ETA: 12s - loss: 1.9818 - acc: 0.53 - ETA: 9s - loss: 1.7398 - acc: 0.4844 - ETA: 7s - loss: 1.5304 - acc: 0.493 - ETA: 6s - loss: 1.3898 - acc: 0.520 - ETA: 5s - loss: 1.2864 - acc: 0.575 - ETA: 5s - loss: 1.2020 - acc: 0.585 - ETA: 4s - loss: 1.1330 - acc: 0.586 - ETA: 4s - loss: 1.0821 - acc: 0.590 - ETA: 4s - loss: 1.0277 - acc: 0.613 - ETA: 3s - loss: 1.0650 - acc: 0.601 - ETA: 3s - loss: 1.0368 - acc: 0.598 - ETA: 3s - loss: 1.0065 - acc: 0.609 - ETA: 2s - loss: 0.9811 - acc: 0.610 - ETA: 2s - loss: 0.9590 - acc: 0.610 - ETA: 2s - loss: 0.9668 - acc: 0.600 - ETA: 2s - loss: 0.9446 - acc: 0.616 - ETA: 2s - loss: 0.9230 - acc: 0.626 - ETA: 1s - loss: 0.9034 - acc: 0.635 - ETA: 1s - loss: 0.8848 - acc: 0.642 - ETA: 1s - loss: 0.8715 - acc: 0.641 - ETA: 1s - loss: 0.8679 - acc: 0.635 - ETA: 1s - loss: 0.8528 - acc: 0.644 - ETA: 1s - loss: 0.8371 - acc: 0.652 - ETA: 1s - loss: 0.8204 - acc: 0.656 - ETA: 0s - loss: 0.8037 - acc: 0.663 - ETA: 0s - loss: 0.7933 - acc: 0.663 - ETA: 0s - loss: 0.7812 - acc: 0.669 - ETA: 0s - loss: 0.7649 - acc: 0.676 - ETA: 0s - loss: 0.7493 - acc: 0.684 - ETA: 0s - loss: 0.7712 - acc: 0.679 - 5s 159ms/step - loss: 0.7681 - acc: 0.6738 - val_loss: 0.4031 - val_acc: 0.8711\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.5509 - acc: 0.687 - ETA: 4s - loss: 0.5060 - acc: 0.750 - ETA: 4s - loss: 0.4493 - acc: 0.833 - ETA: 4s - loss: 0.4115 - acc: 0.851 - ETA: 4s - loss: 0.3858 - acc: 0.868 - ETA: 4s - loss: 0.3736 - acc: 0.859 - ETA: 4s - loss: 0.3592 - acc: 0.875 - ETA: 3s - loss: 0.3399 - acc: 0.878 - ETA: 3s - loss: 0.3351 - acc: 0.871 - ETA: 3s - loss: 0.4094 - acc: 0.834 - ETA: 3s - loss: 0.4914 - acc: 0.806 - ETA: 3s - loss: 0.4957 - acc: 0.789 - ETA: 2s - loss: 0.5214 - acc: 0.766 - ETA: 2s - loss: 0.4974 - acc: 0.776 - ETA: 2s - loss: 0.4771 - acc: 0.783 - ETA: 2s - loss: 0.4626 - acc: 0.791 - ETA: 2s - loss: 0.4423 - acc: 0.801 - ETA: 2s - loss: 0.4308 - acc: 0.809 - ETA: 1s - loss: 0.4141 - acc: 0.817 - ETA: 1s - loss: 0.3972 - acc: 0.826 - ETA: 1s - loss: 0.3750 - acc: 0.832 - ETA: 1s - loss: 0.3721 - acc: 0.834 - ETA: 1s - loss: 0.3635 - acc: 0.840 - ETA: 1s - loss: 0.3522 - acc: 0.847 - ETA: 0s - loss: 0.3432 - acc: 0.850 - ETA: 0s - loss: 0.3332 - acc: 0.855 - ETA: 0s - loss: 0.3235 - acc: 0.860 - ETA: 0s - loss: 0.3171 - acc: 0.862 - ETA: 0s - loss: 0.3130 - acc: 0.864 - ETA: 0s - loss: 0.3104 - acc: 0.864 - ETA: 0s - loss: 0.3054 - acc: 0.866 - 5s 152ms/step - loss: 0.3010 - acc: 0.8676 - val_loss: 0.4980 - val_acc: 0.8906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.890625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 288)               5645088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 289       \n",
      "=================================================================\n",
      "Total params: 5,650,465\n",
      "Trainable params: 5,650,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 29s - loss: 0.7164 - acc: 0.25 - ETA: 9s - loss: 10.0491 - acc: 0.36 - ETA: 6s - loss: 6.4977 - acc: 0.4125 - ETA: 5s - loss: 5.5457 - acc: 0.411 - ETA: 5s - loss: 4.8611 - acc: 0.424 - ETA: 4s - loss: 4.3700 - acc: 0.425 - ETA: 4s - loss: 3.9665 - acc: 0.441 - ETA: 4s - loss: 3.6288 - acc: 0.490 - ETA: 3s - loss: 3.3550 - acc: 0.497 - ETA: 3s - loss: 3.1230 - acc: 0.520 - ETA: 3s - loss: 2.9243 - acc: 0.540 - ETA: 3s - loss: 2.7613 - acc: 0.540 - ETA: 2s - loss: 2.6130 - acc: 0.550 - ETA: 2s - loss: 2.4843 - acc: 0.552 - ETA: 2s - loss: 2.3160 - acc: 0.575 - ETA: 2s - loss: 2.2154 - acc: 0.590 - ETA: 1s - loss: 2.1278 - acc: 0.605 - ETA: 1s - loss: 2.0526 - acc: 0.608 - ETA: 1s - loss: 1.9971 - acc: 0.604 - ETA: 1s - loss: 1.9374 - acc: 0.602 - ETA: 1s - loss: 1.8807 - acc: 0.602 - ETA: 1s - loss: 1.8261 - acc: 0.604 - ETA: 0s - loss: 1.7693 - acc: 0.616 - ETA: 0s - loss: 1.7213 - acc: 0.622 - ETA: 0s - loss: 1.6686 - acc: 0.635 - ETA: 0s - loss: 1.6180 - acc: 0.646 - ETA: 0s - loss: 1.5716 - acc: 0.657 - ETA: 0s - loss: 1.5273 - acc: 0.667 - ETA: 0s - loss: 1.4852 - acc: 0.676 - 5s 158ms/step - loss: 1.4470 - acc: 0.6845 - val_loss: 0.6582 - val_acc: 0.7734\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.1992 - acc: 0.906 - ETA: 4s - loss: 0.1824 - acc: 0.921 - ETA: 3s - loss: 0.1720 - acc: 0.927 - ETA: 3s - loss: 0.1501 - acc: 0.937 - ETA: 3s - loss: 0.1552 - acc: 0.931 - ETA: 3s - loss: 0.2491 - acc: 0.880 - ETA: 3s - loss: 0.3102 - acc: 0.839 - ETA: 3s - loss: 0.3519 - acc: 0.816 - ETA: 3s - loss: 0.3695 - acc: 0.798 - ETA: 2s - loss: 0.3598 - acc: 0.815 - ETA: 2s - loss: 0.3514 - acc: 0.826 - ETA: 2s - loss: 0.3390 - acc: 0.838 - ETA: 2s - loss: 0.3280 - acc: 0.846 - ETA: 2s - loss: 0.3276 - acc: 0.848 - ETA: 2s - loss: 0.3389 - acc: 0.839 - ETA: 2s - loss: 0.3302 - acc: 0.845 - ETA: 1s - loss: 0.3179 - acc: 0.854 - ETA: 1s - loss: 0.3103 - acc: 0.857 - ETA: 1s - loss: 0.2994 - acc: 0.863 - ETA: 1s - loss: 0.2896 - acc: 0.868 - ETA: 1s - loss: 0.2781 - acc: 0.875 - ETA: 1s - loss: 0.2721 - acc: 0.879 - ETA: 1s - loss: 0.2635 - acc: 0.884 - ETA: 0s - loss: 0.2455 - acc: 0.889 - ETA: 0s - loss: 0.2368 - acc: 0.894 - ETA: 0s - loss: 0.2293 - acc: 0.898 - ETA: 0s - loss: 0.2272 - acc: 0.899 - ETA: 0s - loss: 0.2870 - acc: 0.885 - ETA: 0s - loss: 0.3213 - acc: 0.871 - ETA: 0s - loss: 0.3190 - acc: 0.875 - ETA: 0s - loss: 0.3232 - acc: 0.871 - 5s 137ms/step - loss: 0.3202 - acc: 0.8724 - val_loss: 0.7776 - val_acc: 0.7344\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 288</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7734375</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 288)               22579488  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 289       \n",
      "=================================================================\n",
      "Total params: 22,655,425\n",
      "Trainable params: 22,655,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 19s - loss: 0.7185 - acc: 0.0000e+ - ETA: 13s - loss: 33.9089 - acc: 0.2857   - ETA: 9s - loss: 23.1315 - acc: 0.343 - ETA: 7s - loss: 17.5582 - acc: 0.36 - ETA: 6s - loss: 14.1873 - acc: 0.37 - ETA: 5s - loss: 11.9376 - acc: 0.44 - ETA: 4s - loss: 10.3272 - acc: 0.50 - ETA: 4s - loss: 9.1452 - acc: 0.5022 - ETA: 4s - loss: 8.2047 - acc: 0.498 - ETA: 3s - loss: 7.4499 - acc: 0.508 - ETA: 3s - loss: 6.8502 - acc: 0.523 - ETA: 3s - loss: 6.3314 - acc: 0.526 - ETA: 3s - loss: 5.9023 - acc: 0.511 - ETA: 2s - loss: 5.5275 - acc: 0.534 - ETA: 2s - loss: 5.2013 - acc: 0.558 - ETA: 2s - loss: 4.9141 - acc: 0.577 - ETA: 2s - loss: 4.6570 - acc: 0.584 - ETA: 2s - loss: 4.4691 - acc: 0.577 - ETA: 2s - loss: 4.2894 - acc: 0.573 - ETA: 1s - loss: 4.1079 - acc: 0.571 - ETA: 1s - loss: 3.9406 - acc: 0.591 - ETA: 1s - loss: 3.7832 - acc: 0.605 - ETA: 1s - loss: 3.6382 - acc: 0.613 - ETA: 1s - loss: 3.5442 - acc: 0.608 - ETA: 1s - loss: 3.4265 - acc: 0.610 - ETA: 0s - loss: 3.3139 - acc: 0.615 - ETA: 0s - loss: 3.2067 - acc: 0.622 - ETA: 0s - loss: 3.1090 - acc: 0.628 - ETA: 0s - loss: 3.0963 - acc: 0.621 - ETA: 0s - loss: 3.0080 - acc: 0.624 - ETA: 0s - loss: 2.9229 - acc: 0.630 - ETA: 0s - loss: 2.8390 - acc: 0.639 - 5s 166ms/step - loss: 2.7734 - acc: 0.6436 - val_loss: 1.9168 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.4787 - acc: 0.656 - ETA: 5s - loss: 0.4713 - acc: 0.750 - ETA: 4s - loss: 0.4618 - acc: 0.770 - ETA: 4s - loss: 0.4337 - acc: 0.804 - ETA: 3s - loss: 0.4186 - acc: 0.818 - ETA: 3s - loss: 0.4117 - acc: 0.812 - ETA: 3s - loss: 0.3804 - acc: 0.830 - ETA: 3s - loss: 0.3823 - acc: 0.832 - ETA: 3s - loss: 0.3620 - acc: 0.847 - ETA: 3s - loss: 0.3558 - acc: 0.850 - ETA: 2s - loss: 0.3458 - acc: 0.855 - ETA: 2s - loss: 0.3333 - acc: 0.856 - ETA: 2s - loss: 0.3331 - acc: 0.855 - ETA: 2s - loss: 0.3485 - acc: 0.848 - ETA: 2s - loss: 0.3414 - acc: 0.852 - ETA: 2s - loss: 0.4231 - acc: 0.835 - ETA: 2s - loss: 0.5861 - acc: 0.821 - ETA: 1s - loss: 0.7098 - acc: 0.809 - ETA: 1s - loss: 0.6947 - acc: 0.809 - ETA: 1s - loss: 0.6750 - acc: 0.817 - ETA: 1s - loss: 0.6573 - acc: 0.821 - ETA: 1s - loss: 0.6375 - acc: 0.828 - ETA: 1s - loss: 0.6209 - acc: 0.832 - ETA: 1s - loss: 0.6453 - acc: 0.826 - ETA: 1s - loss: 0.6273 - acc: 0.831 - ETA: 0s - loss: 0.6084 - acc: 0.835 - ETA: 0s - loss: 0.5873 - acc: 0.841 - ETA: 0s - loss: 0.5683 - acc: 0.847 - ETA: 0s - loss: 0.5608 - acc: 0.849 - ETA: 0s - loss: 0.5500 - acc: 0.852 - ETA: 0s - loss: 0.5356 - acc: 0.856 - 5s 150ms/step - loss: 0.5081 - acc: 0.8598 - val_loss: 0.7363 - val_acc: 0.8789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 288</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.87890625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 448)               35123648  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 449       \n",
      "=================================================================\n",
      "Total params: 35,144,401\n",
      "Trainable params: 35,144,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 24s - loss: 0.7034 - acc: 0.46 - ETA: 13s - loss: 5.2300 - acc: 0.53 - ETA: 9s - loss: 5.0121 - acc: 0.5000 - ETA: 7s - loss: 3.9304 - acc: 0.546 - ETA: 6s - loss: 3.2929 - acc: 0.531 - ETA: 5s - loss: 2.8542 - acc: 0.541 - ETA: 5s - loss: 2.5454 - acc: 0.535 - ETA: 4s - loss: 2.3134 - acc: 0.539 - ETA: 4s - loss: 2.1332 - acc: 0.531 - ETA: 4s - loss: 1.9899 - acc: 0.521 - ETA: 3s - loss: 1.8707 - acc: 0.531 - ETA: 3s - loss: 1.7679 - acc: 0.531 - ETA: 3s - loss: 1.6768 - acc: 0.557 - ETA: 3s - loss: 2.0921 - acc: 0.549 - ETA: 2s - loss: 1.9963 - acc: 0.568 - ETA: 2s - loss: 1.9117 - acc: 0.568 - ETA: 2s - loss: 1.8357 - acc: 0.588 - ETA: 2s - loss: 1.7692 - acc: 0.590 - ETA: 2s - loss: 1.7138 - acc: 0.578 - ETA: 1s - loss: 1.6581 - acc: 0.595 - ETA: 1s - loss: 1.6063 - acc: 0.602 - ETA: 1s - loss: 1.5488 - acc: 0.615 - ETA: 1s - loss: 1.5099 - acc: 0.625 - ETA: 1s - loss: 1.4918 - acc: 0.623 - ETA: 1s - loss: 1.4529 - acc: 0.635 - ETA: 1s - loss: 1.4156 - acc: 0.647 - ETA: 0s - loss: 1.3738 - acc: 0.660 - ETA: 0s - loss: 1.3311 - acc: 0.671 - ETA: 0s - loss: 1.3890 - acc: 0.668 - ETA: 0s - loss: 1.7485 - acc: 0.666 - ETA: 0s - loss: 1.7106 - acc: 0.665 - ETA: 0s - loss: 1.6776 - acc: 0.660 - 6s 169ms/step - loss: 1.6349 - acc: 0.6699 - val_loss: 0.6251 - val_acc: 0.6094\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 1s - loss: 0.6087 - acc: 0.666 - ETA: 3s - loss: 0.5237 - acc: 0.885 - ETA: 3s - loss: 0.4676 - acc: 0.925 - ETA: 3s - loss: 1.3436 - acc: 0.798 - ETA: 3s - loss: 1.1872 - acc: 0.748 - ETA: 3s - loss: 1.0713 - acc: 0.748 - ETA: 3s - loss: 0.9641 - acc: 0.774 - ETA: 3s - loss: 0.8780 - acc: 0.797 - ETA: 2s - loss: 0.8048 - acc: 0.818 - ETA: 2s - loss: 0.7436 - acc: 0.831 - ETA: 2s - loss: 1.2029 - acc: 0.805 - ETA: 2s - loss: 1.1796 - acc: 0.774 - ETA: 2s - loss: 1.1289 - acc: 0.764 - ETA: 2s - loss: 1.0790 - acc: 0.761 - ETA: 2s - loss: 1.0318 - acc: 0.769 - ETA: 2s - loss: 0.9832 - acc: 0.780 - ETA: 1s - loss: 0.9423 - acc: 0.792 - ETA: 1s - loss: 0.9069 - acc: 0.795 - ETA: 1s - loss: 0.8731 - acc: 0.801 - ETA: 1s - loss: 0.8394 - acc: 0.810 - ETA: 1s - loss: 0.8037 - acc: 0.819 - ETA: 1s - loss: 0.7705 - acc: 0.826 - ETA: 1s - loss: 0.7831 - acc: 0.821 - ETA: 1s - loss: 0.7940 - acc: 0.814 - ETA: 0s - loss: 0.7738 - acc: 0.817 - ETA: 0s - loss: 0.7521 - acc: 0.820 - ETA: 0s - loss: 0.7301 - acc: 0.825 - ETA: 0s - loss: 0.7105 - acc: 0.829 - ETA: 0s - loss: 0.6902 - acc: 0.833 - ETA: 0s - loss: 0.6705 - acc: 0.837 - ETA: 0s - loss: 0.6521 - acc: 0.841 - ETA: 0s - loss: 0.6342 - acc: 0.845 - 5s 156ms/step - loss: 0.6195 - acc: 0.8481 - val_loss: 1.9447 - val_acc: 0.6914\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.69140625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 224)               4390624   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 225       \n",
      "=================================================================\n",
      "Total params: 4,438,801\n",
      "Trainable params: 4,438,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 21s - loss: 0.6964 - acc: 0.53 - ETA: 12s - loss: 0.9964 - acc: 0.53 - ETA: 9s - loss: 18.8209 - acc: 0.51 - ETA: 7s - loss: 14.3260 - acc: 0.57 - ETA: 6s - loss: 11.6568 - acc: 0.55 - ETA: 5s - loss: 9.8069 - acc: 0.5833 - ETA: 5s - loss: 8.5261 - acc: 0.567 - ETA: 4s - loss: 7.5393 - acc: 0.582 - ETA: 4s - loss: 6.7818 - acc: 0.569 - ETA: 3s - loss: 5.7316 - acc: 0.538 - ETA: 3s - loss: 5.3105 - acc: 0.532 - ETA: 3s - loss: 4.9528 - acc: 0.527 - ETA: 2s - loss: 4.6458 - acc: 0.539 - ETA: 2s - loss: 4.3763 - acc: 0.558 - ETA: 2s - loss: 4.1420 - acc: 0.565 - ETA: 2s - loss: 3.9384 - acc: 0.561 - ETA: 2s - loss: 3.7574 - acc: 0.563 - ETA: 2s - loss: 3.5917 - acc: 0.566 - ETA: 1s - loss: 3.4427 - acc: 0.569 - ETA: 1s - loss: 3.3028 - acc: 0.583 - ETA: 1s - loss: 3.1747 - acc: 0.591 - ETA: 1s - loss: 3.0942 - acc: 0.584 - ETA: 1s - loss: 2.9902 - acc: 0.587 - ETA: 1s - loss: 2.8962 - acc: 0.585 - ETA: 0s - loss: 2.8271 - acc: 0.585 - ETA: 0s - loss: 2.7478 - acc: 0.584 - ETA: 0s - loss: 2.6716 - acc: 0.583 - ETA: 0s - loss: 2.5990 - acc: 0.589 - ETA: 0s - loss: 2.5314 - acc: 0.592 - ETA: 0s - loss: 2.4643 - acc: 0.601 - ETA: 0s - loss: 2.4058 - acc: 0.604 - 5s 158ms/step - loss: 2.3490 - acc: 0.6066 - val_loss: 0.5696 - val_acc: 0.6211\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.3725 - acc: 0.968 - ETA: 4s - loss: 0.5486 - acc: 0.796 - ETA: 4s - loss: 0.5964 - acc: 0.718 - ETA: 4s - loss: 0.5443 - acc: 0.781 - ETA: 3s - loss: 0.5253 - acc: 0.787 - ETA: 3s - loss: 0.5038 - acc: 0.791 - ETA: 3s - loss: 0.4659 - acc: 0.799 - ETA: 3s - loss: 0.4306 - acc: 0.820 - ETA: 3s - loss: 0.4127 - acc: 0.829 - ETA: 3s - loss: 0.4358 - acc: 0.815 - ETA: 2s - loss: 0.4387 - acc: 0.818 - ETA: 2s - loss: 0.4479 - acc: 0.812 - ETA: 2s - loss: 0.4419 - acc: 0.822 - ETA: 2s - loss: 0.4310 - acc: 0.828 - ETA: 2s - loss: 0.4135 - acc: 0.837 - ETA: 2s - loss: 0.3979 - acc: 0.843 - ETA: 2s - loss: 0.3859 - acc: 0.847 - ETA: 1s - loss: 0.4938 - acc: 0.836 - ETA: 1s - loss: 0.4872 - acc: 0.833 - ETA: 1s - loss: 0.4872 - acc: 0.831 - ETA: 1s - loss: 0.4867 - acc: 0.824 - ETA: 1s - loss: 0.4810 - acc: 0.825 - ETA: 1s - loss: 0.4702 - acc: 0.827 - ETA: 1s - loss: 0.4576 - acc: 0.833 - ETA: 1s - loss: 0.4480 - acc: 0.836 - ETA: 0s - loss: 0.4370 - acc: 0.840 - ETA: 0s - loss: 0.4242 - acc: 0.844 - ETA: 0s - loss: 0.5146 - acc: 0.833 - ETA: 0s - loss: 0.5410 - acc: 0.823 - ETA: 0s - loss: 0.5387 - acc: 0.820 - ETA: 0s - loss: 0.5345 - acc: 0.824 - 5s 141ms/step - loss: 0.5294 - acc: 0.8247 - val_loss: 0.4715 - val_acc: 0.8359\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8359375</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               10913920  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,916,817\n",
      "Trainable params: 10,916,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 18s - loss: 0.6807 - acc: 0.62 - ETA: 10s - loss: 8.1920 - acc: 0.64 - ETA: 8s - loss: 14.6981 - acc: 0.56 - ETA: 6s - loss: 11.6188 - acc: 0.58 - ETA: 5s - loss: 9.5153 - acc: 0.5875 - ETA: 5s - loss: 8.1279 - acc: 0.557 - ETA: 4s - loss: 7.2727 - acc: 0.549 - ETA: 4s - loss: 6.4446 - acc: 0.546 - ETA: 4s - loss: 5.7916 - acc: 0.590 - ETA: 3s - loss: 5.2636 - acc: 0.628 - ETA: 3s - loss: 4.8380 - acc: 0.636 - ETA: 3s - loss: 4.5629 - acc: 0.612 - ETA: 3s - loss: 4.2462 - acc: 0.617 - ETA: 2s - loss: 3.9766 - acc: 0.627 - ETA: 2s - loss: 3.7352 - acc: 0.641 - ETA: 2s - loss: 3.5207 - acc: 0.658 - ETA: 2s - loss: 3.3352 - acc: 0.671 - ETA: 2s - loss: 3.2562 - acc: 0.670 - ETA: 2s - loss: 3.1038 - acc: 0.684 - ETA: 1s - loss: 2.9621 - acc: 0.696 - ETA: 1s - loss: 2.8339 - acc: 0.708 - ETA: 1s - loss: 2.7140 - acc: 0.718 - ETA: 1s - loss: 2.6038 - acc: 0.729 - ETA: 1s - loss: 2.5085 - acc: 0.737 - ETA: 1s - loss: 2.4330 - acc: 0.735 - ETA: 0s - loss: 2.3522 - acc: 0.740 - ETA: 0s - loss: 2.2745 - acc: 0.747 - ETA: 0s - loss: 2.1295 - acc: 0.754 - ETA: 0s - loss: 2.0622 - acc: 0.762 - ETA: 0s - loss: 1.9990 - acc: 0.769 - ETA: 0s - loss: 1.9494 - acc: 0.769 - 5s 157ms/step - loss: 1.9060 - acc: 0.7712 - val_loss: 0.3647 - val_acc: 0.8594\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.8890 - acc: 0.718 - ETA: 4s - loss: 0.5177 - acc: 0.843 - ETA: 4s - loss: 0.4251 - acc: 0.843 - ETA: 3s - loss: 0.3891 - acc: 0.843 - ETA: 3s - loss: 0.3613 - acc: 0.850 - ETA: 3s - loss: 0.3396 - acc: 0.849 - ETA: 3s - loss: 0.3140 - acc: 0.866 - ETA: 3s - loss: 0.2855 - acc: 0.878 - ETA: 3s - loss: 0.2604 - acc: 0.892 - ETA: 2s - loss: 0.2393 - acc: 0.903 - ETA: 2s - loss: 0.2290 - acc: 0.909 - ETA: 2s - loss: 0.2197 - acc: 0.914 - ETA: 2s - loss: 0.2119 - acc: 0.915 - ETA: 2s - loss: 0.1999 - acc: 0.921 - ETA: 2s - loss: 0.1879 - acc: 0.927 - ETA: 2s - loss: 0.1790 - acc: 0.931 - ETA: 2s - loss: 0.1710 - acc: 0.935 - ETA: 1s - loss: 0.1631 - acc: 0.939 - ETA: 1s - loss: 0.1566 - acc: 0.942 - ETA: 1s - loss: 0.1526 - acc: 0.943 - ETA: 1s - loss: 0.1470 - acc: 0.946 - ETA: 1s - loss: 0.1467 - acc: 0.946 - ETA: 1s - loss: 0.1611 - acc: 0.940 - ETA: 1s - loss: 0.1663 - acc: 0.937 - ETA: 0s - loss: 0.1638 - acc: 0.938 - ETA: 0s - loss: 0.1589 - acc: 0.941 - ETA: 0s - loss: 0.1487 - acc: 0.943 - ETA: 0s - loss: 0.1478 - acc: 0.943 - ETA: 0s - loss: 0.1465 - acc: 0.944 - ETA: 0s - loss: 0.1452 - acc: 0.945 - ETA: 0s - loss: 0.1421 - acc: 0.946 - 5s 141ms/step - loss: 0.1408 - acc: 0.9474 - val_loss: 0.9423 - val_acc: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.86328125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 384)               32741760  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 385       \n",
      "=================================================================\n",
      "Total params: 32,753,169\n",
      "Trainable params: 32,753,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 19s - loss: 0.6918 - acc: 0.56 - ETA: 11s - loss: 1.8907 - acc: 0.64 - ETA: 8s - loss: 18.0834 - acc: 0.60 - ETA: 7s - loss: 13.8815 - acc: 0.53 - ETA: 6s - loss: 11.5703 - acc: 0.55 - ETA: 5s - loss: 9.7420 - acc: 0.5677 - ETA: 5s - loss: 8.4534 - acc: 0.567 - ETA: 4s - loss: 7.5205 - acc: 0.550 - ETA: 4s - loss: 6.7577 - acc: 0.548 - ETA: 3s - loss: 6.1308 - acc: 0.571 - ETA: 3s - loss: 5.2398 - acc: 0.583 - ETA: 3s - loss: 4.8826 - acc: 0.586 - ETA: 2s - loss: 4.5742 - acc: 0.596 - ETA: 2s - loss: 4.3010 - acc: 0.607 - ETA: 2s - loss: 4.0633 - acc: 0.614 - ETA: 2s - loss: 3.8458 - acc: 0.631 - ETA: 2s - loss: 3.6579 - acc: 0.634 - ETA: 1s - loss: 3.4840 - acc: 0.649 - ETA: 1s - loss: 3.3291 - acc: 0.661 - ETA: 1s - loss: 3.1869 - acc: 0.667 - ETA: 1s - loss: 3.0588 - acc: 0.675 - ETA: 1s - loss: 2.9514 - acc: 0.677 - ETA: 1s - loss: 3.2314 - acc: 0.671 - ETA: 1s - loss: 3.1346 - acc: 0.668 - ETA: 0s - loss: 3.0787 - acc: 0.665 - ETA: 0s - loss: 2.9793 - acc: 0.667 - ETA: 0s - loss: 2.8846 - acc: 0.672 - ETA: 0s - loss: 2.7981 - acc: 0.675 - ETA: 0s - loss: 2.7114 - acc: 0.684 - ETA: 0s - loss: 2.6340 - acc: 0.690 - ETA: 0s - loss: 2.5561 - acc: 0.700 - 6s 167ms/step - loss: 2.4853 - acc: 0.7069 - val_loss: 2.1903 - val_acc: 0.5352\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.4846 - acc: 0.687 - ETA: 4s - loss: 0.4178 - acc: 0.781 - ETA: 4s - loss: 0.3648 - acc: 0.833 - ETA: 3s - loss: 0.2952 - acc: 0.875 - ETA: 3s - loss: 0.2460 - acc: 0.900 - ETA: 3s - loss: 0.2481 - acc: 0.901 - ETA: 3s - loss: 0.3975 - acc: 0.852 - ETA: 3s - loss: 0.3988 - acc: 0.855 - ETA: 3s - loss: 0.3825 - acc: 0.857 - ETA: 2s - loss: 0.3710 - acc: 0.856 - ETA: 2s - loss: 0.3507 - acc: 0.867 - ETA: 2s - loss: 0.3410 - acc: 0.873 - ETA: 2s - loss: 0.3269 - acc: 0.878 - ETA: 2s - loss: 0.3115 - acc: 0.884 - ETA: 2s - loss: 0.3000 - acc: 0.888 - ETA: 1s - loss: 0.2831 - acc: 0.895 - ETA: 1s - loss: 0.2814 - acc: 0.894 - ETA: 1s - loss: 0.2732 - acc: 0.898 - ETA: 1s - loss: 0.2747 - acc: 0.898 - ETA: 1s - loss: 0.2759 - acc: 0.894 - ETA: 1s - loss: 0.2818 - acc: 0.885 - ETA: 1s - loss: 0.2802 - acc: 0.888 - ETA: 1s - loss: 0.2767 - acc: 0.891 - ETA: 0s - loss: 0.4263 - acc: 0.875 - ETA: 0s - loss: 0.4142 - acc: 0.876 - ETA: 0s - loss: 1.2136 - acc: 0.856 - ETA: 0s - loss: 1.2524 - acc: 0.847 - ETA: 0s - loss: 1.2337 - acc: 0.842 - ETA: 0s - loss: 1.2005 - acc: 0.843 - ETA: 0s - loss: 1.1673 - acc: 0.847 - ETA: 0s - loss: 1.1365 - acc: 0.851 - 5s 150ms/step - loss: 1.1153 - acc: 0.8481 - val_loss: 2.3855 - val_acc: 0.6641\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 384</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6640625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 448)               35123648  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 449       \n",
      "=================================================================\n",
      "Total params: 35,144,401\n",
      "Trainable params: 35,144,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 22s - loss: 0.6872 - acc: 0.59 - ETA: 12s - loss: 12.6293 - acc: 0.578 - ETA: 9s - loss: 14.2292 - acc: 0.500 - ETA: 7s - loss: 10.8439 - acc: 0.50 - ETA: 6s - loss: 8.8030 - acc: 0.5250 - ETA: 5s - loss: 7.4479 - acc: 0.526 - ETA: 5s - loss: 6.7447 - acc: 0.544 - ETA: 4s - loss: 5.9682 - acc: 0.578 - ETA: 4s - loss: 5.4058 - acc: 0.576 - ETA: 4s - loss: 4.9296 - acc: 0.571 - ETA: 3s - loss: 4.2276 - acc: 0.566 - ETA: 3s - loss: 3.9498 - acc: 0.573 - ETA: 2s - loss: 3.7082 - acc: 0.584 - ETA: 2s - loss: 3.5104 - acc: 0.576 - ETA: 2s - loss: 3.3232 - acc: 0.602 - ETA: 2s - loss: 3.1558 - acc: 0.625 - ETA: 2s - loss: 3.0109 - acc: 0.619 - ETA: 2s - loss: 2.8788 - acc: 0.626 - ETA: 1s - loss: 2.7597 - acc: 0.639 - ETA: 1s - loss: 2.6496 - acc: 0.653 - ETA: 1s - loss: 2.5425 - acc: 0.668 - ETA: 1s - loss: 2.4573 - acc: 0.670 - ETA: 1s - loss: 2.5323 - acc: 0.664 - ETA: 1s - loss: 2.4489 - acc: 0.677 - ETA: 0s - loss: 2.3684 - acc: 0.688 - ETA: 0s - loss: 2.2946 - acc: 0.698 - ETA: 0s - loss: 2.2232 - acc: 0.707 - ETA: 0s - loss: 2.1758 - acc: 0.703 - ETA: 0s - loss: 2.1217 - acc: 0.700 - ETA: 0s - loss: 2.0647 - acc: 0.704 - ETA: 0s - loss: 2.0055 - acc: 0.713 - 6s 170ms/step - loss: 1.9515 - acc: 0.7225 - val_loss: 0.7611 - val_acc: 0.7227\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.3104 - acc: 0.812 - ETA: 4s - loss: 0.3003 - acc: 0.812 - ETA: 4s - loss: 0.2793 - acc: 0.843 - ETA: 4s - loss: 0.2394 - acc: 0.882 - ETA: 3s - loss: 0.2192 - acc: 0.900 - ETA: 3s - loss: 0.2666 - acc: 0.869 - ETA: 3s - loss: 0.2599 - acc: 0.879 - ETA: 3s - loss: 0.2480 - acc: 0.886 - ETA: 3s - loss: 0.2332 - acc: 0.895 - ETA: 2s - loss: 0.2868 - acc: 0.878 - ETA: 2s - loss: 0.3557 - acc: 0.849 - ETA: 2s - loss: 0.4485 - acc: 0.826 - ETA: 2s - loss: 0.4518 - acc: 0.825 - ETA: 2s - loss: 0.4309 - acc: 0.833 - ETA: 2s - loss: 0.4125 - acc: 0.842 - ETA: 1s - loss: 0.3978 - acc: 0.848 - ETA: 1s - loss: 0.3783 - acc: 0.857 - ETA: 1s - loss: 0.3633 - acc: 0.863 - ETA: 1s - loss: 0.3485 - acc: 0.870 - ETA: 1s - loss: 0.3398 - acc: 0.875 - ETA: 1s - loss: 0.3297 - acc: 0.880 - ETA: 1s - loss: 0.3187 - acc: 0.884 - ETA: 1s - loss: 0.3084 - acc: 0.889 - ETA: 0s - loss: 0.2975 - acc: 0.893 - ETA: 0s - loss: 0.2865 - acc: 0.897 - ETA: 0s - loss: 0.2783 - acc: 0.899 - ETA: 0s - loss: 0.2749 - acc: 0.900 - ETA: 0s - loss: 0.2739 - acc: 0.899 - ETA: 0s - loss: 0.2726 - acc: 0.900 - ETA: 0s - loss: 0.2643 - acc: 0.903 - ETA: 0s - loss: 0.2596 - acc: 0.905 - 4s 136ms/step - loss: 0.2584 - acc: 0.9056 - val_loss: 3.3095 - val_acc: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.72265625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 288)               5645088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 289       \n",
      "=================================================================\n",
      "Total params: 5,693,329\n",
      "Trainable params: 5,693,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 21s - loss: 0.6762 - acc: 0.59 - ETA: 12s - loss: 16.3360 - acc: 0.531 - ETA: 9s - loss: 11.7228 - acc: 0.520 - ETA: 7s - loss: 8.9647 - acc: 0.5625 - ETA: 6s - loss: 7.3154 - acc: 0.562 - ETA: 5s - loss: 6.2030 - acc: 0.562 - ETA: 5s - loss: 5.4188 - acc: 0.549 - ETA: 4s - loss: 5.1898 - acc: 0.554 - ETA: 4s - loss: 4.6967 - acc: 0.559 - ETA: 4s - loss: 4.2958 - acc: 0.590 - ETA: 3s - loss: 3.9676 - acc: 0.613 - ETA: 3s - loss: 3.6934 - acc: 0.632 - ETA: 3s - loss: 3.4532 - acc: 0.637 - ETA: 3s - loss: 3.4131 - acc: 0.629 - ETA: 2s - loss: 3.2338 - acc: 0.604 - ETA: 2s - loss: 3.0742 - acc: 0.621 - ETA: 2s - loss: 3.0286 - acc: 0.612 - ETA: 2s - loss: 2.9067 - acc: 0.599 - ETA: 1s - loss: 2.7941 - acc: 0.600 - ETA: 1s - loss: 2.6932 - acc: 0.605 - ETA: 1s - loss: 2.6010 - acc: 0.603 - ETA: 1s - loss: 2.5159 - acc: 0.604 - ETA: 1s - loss: 2.4351 - acc: 0.613 - ETA: 1s - loss: 2.3656 - acc: 0.610 - ETA: 0s - loss: 2.3003 - acc: 0.602 - ETA: 0s - loss: 2.2370 - acc: 0.613 - ETA: 0s - loss: 2.1779 - acc: 0.620 - ETA: 0s - loss: 2.1349 - acc: 0.620 - ETA: 0s - loss: 2.0845 - acc: 0.615 - ETA: 0s - loss: 2.0369 - acc: 0.619 - ETA: 0s - loss: 1.9948 - acc: 0.615 - 5s 156ms/step - loss: 1.9524 - acc: 0.6203 - val_loss: 0.8817 - val_acc: 0.5234\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.5831 - acc: 0.562 - ETA: 4s - loss: 0.5671 - acc: 0.750 - ETA: 4s - loss: 0.4731 - acc: 0.791 - ETA: 4s - loss: 0.3876 - acc: 0.835 - ETA: 3s - loss: 1.3581 - acc: 0.775 - ETA: 3s - loss: 1.5336 - acc: 0.724 - ETA: 3s - loss: 1.4167 - acc: 0.696 - ETA: 3s - loss: 1.3268 - acc: 0.668 - ETA: 3s - loss: 1.2493 - acc: 0.697 - ETA: 2s - loss: 1.1846 - acc: 0.721 - ETA: 2s - loss: 1.1189 - acc: 0.738 - ETA: 2s - loss: 1.0488 - acc: 0.757 - ETA: 2s - loss: 1.0351 - acc: 0.747 - ETA: 2s - loss: 1.7651 - acc: 0.725 - ETA: 2s - loss: 1.7061 - acc: 0.700 - ETA: 2s - loss: 1.6334 - acc: 0.712 - ETA: 2s - loss: 1.5676 - acc: 0.724 - ETA: 1s - loss: 1.5037 - acc: 0.736 - ETA: 1s - loss: 1.4578 - acc: 0.730 - ETA: 1s - loss: 1.4026 - acc: 0.742 - ETA: 1s - loss: 1.2996 - acc: 0.754 - ETA: 1s - loss: 1.2622 - acc: 0.762 - ETA: 1s - loss: 1.2206 - acc: 0.768 - ETA: 0s - loss: 1.1842 - acc: 0.773 - ETA: 0s - loss: 1.1677 - acc: 0.770 - ETA: 0s - loss: 1.1361 - acc: 0.770 - ETA: 0s - loss: 1.1098 - acc: 0.771 - ETA: 0s - loss: 1.0818 - acc: 0.774 - ETA: 0s - loss: 1.0533 - acc: 0.778 - ETA: 0s - loss: 1.0236 - acc: 0.785 - ETA: 0s - loss: 0.9980 - acc: 0.791 - 5s 142ms/step - loss: 0.9808 - acc: 0.7936 - val_loss: 1.9484 - val_acc: 0.6797\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 288</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6796875</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 160)               13642400  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 13,645,329\n",
      "Trainable params: 13,645,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/2\n",
      "33/33 [==============================] - ETA: 18s - loss: 0.6985 - acc: 0.46 - ETA: 10s - loss: 10.0584 - acc: 0.500 - ETA: 8s - loss: 9.9619 - acc: 0.5521  - ETA: 6s - loss: 8.3389 - acc: 0.531 - ETA: 5s - loss: 7.3095 - acc: 0.506 - ETA: 5s - loss: 6.3028 - acc: 0.489 - ETA: 4s - loss: 5.4671 - acc: 0.526 - ETA: 4s - loss: 4.8329 - acc: 0.578 - ETA: 4s - loss: 4.3747 - acc: 0.569 - ETA: 3s - loss: 3.9868 - acc: 0.590 - ETA: 3s - loss: 3.3878 - acc: 0.611 - ETA: 2s - loss: 3.1511 - acc: 0.635 - ETA: 2s - loss: 2.9437 - acc: 0.656 - ETA: 2s - loss: 2.7565 - acc: 0.680 - ETA: 2s - loss: 2.6009 - acc: 0.691 - ETA: 2s - loss: 2.4589 - acc: 0.708 - ETA: 2s - loss: 2.3319 - acc: 0.720 - ETA: 1s - loss: 2.2193 - acc: 0.732 - ETA: 1s - loss: 2.1140 - acc: 0.744 - ETA: 1s - loss: 2.0175 - acc: 0.755 - ETA: 1s - loss: 1.9297 - acc: 0.765 - ETA: 1s - loss: 1.8495 - acc: 0.775 - ETA: 1s - loss: 1.7761 - acc: 0.783 - ETA: 1s - loss: 1.7143 - acc: 0.789 - ETA: 0s - loss: 1.6540 - acc: 0.793 - ETA: 0s - loss: 1.6008 - acc: 0.796 - ETA: 0s - loss: 1.5574 - acc: 0.797 - ETA: 0s - loss: 1.5212 - acc: 0.797 - ETA: 0s - loss: 1.4804 - acc: 0.800 - ETA: 0s - loss: 1.4360 - acc: 0.806 - ETA: 0s - loss: 1.3934 - acc: 0.812 - 5s 156ms/step - loss: 1.3547 - acc: 0.8179 - val_loss: 1.5908 - val_acc: 0.7227\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0041 - acc: 1.000 - ETA: 2s - loss: 0.0438 - acc: 0.971 - ETA: 2s - loss: 0.0429 - acc: 0.985 - ETA: 3s - loss: 0.0471 - acc: 0.989 - ETA: 3s - loss: 0.0500 - acc: 0.992 - ETA: 2s - loss: 0.0440 - acc: 0.993 - ETA: 2s - loss: 0.0398 - acc: 0.994 - ETA: 2s - loss: 0.0371 - acc: 0.995 - ETA: 2s - loss: 0.0346 - acc: 0.996 - ETA: 2s - loss: 0.0316 - acc: 0.996 - ETA: 2s - loss: 0.0295 - acc: 0.996 - ETA: 2s - loss: 0.0361 - acc: 0.991 - ETA: 2s - loss: 0.0365 - acc: 0.992 - ETA: 2s - loss: 0.0348 - acc: 0.992 - ETA: 2s - loss: 0.0351 - acc: 0.993 - ETA: 1s - loss: 0.0363 - acc: 0.991 - ETA: 1s - loss: 0.0367 - acc: 0.990 - ETA: 1s - loss: 0.0433 - acc: 0.985 - ETA: 1s - loss: 0.0521 - acc: 0.981 - ETA: 1s - loss: 0.0516 - acc: 0.982 - ETA: 1s - loss: 0.0524 - acc: 0.982 - ETA: 1s - loss: 0.0519 - acc: 0.983 - ETA: 1s - loss: 0.0509 - acc: 0.984 - ETA: 1s - loss: 0.0497 - acc: 0.985 - ETA: 0s - loss: 0.0506 - acc: 0.983 - ETA: 0s - loss: 0.0490 - acc: 0.983 - ETA: 0s - loss: 0.0476 - acc: 0.984 - ETA: 0s - loss: 0.0471 - acc: 0.985 - ETA: 0s - loss: 0.0473 - acc: 0.984 - ETA: 0s - loss: 0.0460 - acc: 0.985 - ETA: 0s - loss: 0.0453 - acc: 0.985 - ETA: 0s - loss: 0.0445 - acc: 0.985 - 5s 143ms/step - loss: 0.0434 - acc: 0.9864 - val_loss: 1.5331 - val_acc: 0.8203\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 160</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8203125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 448)               1835456   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 449       \n",
      "=================================================================\n",
      "Total params: 1,851,569\n",
      "Trainable params: 1,851,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 23s - loss: 0.6903 - acc: 0.75 - ETA: 13s - loss: 2.2415 - acc: 0.64 - ETA: 9s - loss: 1.7246 - acc: 0.6042 - ETA: 7s - loss: 1.4656 - acc: 0.648 - ETA: 6s - loss: 1.3057 - acc: 0.637 - ETA: 5s - loss: 1.2476 - acc: 0.588 - ETA: 5s - loss: 1.1661 - acc: 0.584 - ETA: 4s - loss: 1.1061 - acc: 0.570 - ETA: 4s - loss: 1.0570 - acc: 0.586 - ETA: 4s - loss: 1.0125 - acc: 0.590 - ETA: 3s - loss: 0.9817 - acc: 0.588 - ETA: 3s - loss: 0.9549 - acc: 0.585 - ETA: 3s - loss: 0.9283 - acc: 0.605 - ETA: 3s - loss: 0.9037 - acc: 0.622 - ETA: 2s - loss: 0.8784 - acc: 0.633 - ETA: 2s - loss: 0.8593 - acc: 0.627 - ETA: 2s - loss: 0.8386 - acc: 0.645 - ETA: 2s - loss: 0.8293 - acc: 0.642 - ETA: 2s - loss: 0.8316 - acc: 0.629 - ETA: 1s - loss: 0.8209 - acc: 0.634 - ETA: 1s - loss: 0.8082 - acc: 0.641 - ETA: 1s - loss: 0.7935 - acc: 0.646 - ETA: 1s - loss: 0.7829 - acc: 0.646 - ETA: 1s - loss: 0.7671 - acc: 0.651 - ETA: 1s - loss: 0.7456 - acc: 0.661 - ETA: 1s - loss: 0.7389 - acc: 0.661 - ETA: 0s - loss: 0.7271 - acc: 0.662 - ETA: 0s - loss: 0.7172 - acc: 0.667 - ETA: 0s - loss: 0.7080 - acc: 0.670 - ETA: 0s - loss: 0.7162 - acc: 0.663 - ETA: 0s - loss: 0.7081 - acc: 0.670 - 5s 159ms/step - loss: 0.6981 - acc: 0.6787 - val_loss: 0.4081 - val_acc: 0.8789\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.2407 - acc: 0.968 - ETA: 4s - loss: 0.4356 - acc: 0.765 - ETA: 4s - loss: 0.3961 - acc: 0.781 - ETA: 4s - loss: 0.4606 - acc: 0.742 - ETA: 3s - loss: 0.4281 - acc: 0.787 - ETA: 3s - loss: 0.4010 - acc: 0.817 - ETA: 3s - loss: 0.3770 - acc: 0.834 - ETA: 3s - loss: 0.3589 - acc: 0.843 - ETA: 3s - loss: 0.3304 - acc: 0.861 - ETA: 2s - loss: 0.3080 - acc: 0.868 - ETA: 2s - loss: 0.2918 - acc: 0.877 - ETA: 2s - loss: 0.2713 - acc: 0.888 - ETA: 2s - loss: 0.2751 - acc: 0.889 - ETA: 2s - loss: 1.6090 - acc: 0.857 - ETA: 2s - loss: 1.5346 - acc: 0.854 - ETA: 2s - loss: 1.4500 - acc: 0.861 - ETA: 2s - loss: 1.3743 - acc: 0.867 - ETA: 1s - loss: 1.3081 - acc: 0.875 - ETA: 1s - loss: 1.1945 - acc: 0.877 - ETA: 1s - loss: 1.1432 - acc: 0.881 - ETA: 1s - loss: 1.0987 - acc: 0.884 - ETA: 1s - loss: 1.0592 - acc: 0.885 - ETA: 1s - loss: 1.0194 - acc: 0.889 - ETA: 0s - loss: 0.9904 - acc: 0.885 - ETA: 0s - loss: 0.9664 - acc: 0.882 - ETA: 0s - loss: 0.9375 - acc: 0.883 - ETA: 0s - loss: 0.9066 - acc: 0.888 - ETA: 0s - loss: 0.8785 - acc: 0.892 - ETA: 0s - loss: 0.8533 - acc: 0.894 - ETA: 0s - loss: 0.8284 - acc: 0.898 - ETA: 0s - loss: 0.8112 - acc: 0.896 - 5s 137ms/step - loss: 0.7944 - acc: 0.8978 - val_loss: 0.8910 - val_acc: 0.8516\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.1823 - acc: 0.906 - ETA: 4s - loss: 0.1129 - acc: 0.953 - ETA: 4s - loss: 0.0862 - acc: 0.968 - ETA: 3s - loss: 0.0863 - acc: 0.960 - ETA: 3s - loss: 0.0830 - acc: 0.968 - ETA: 3s - loss: 0.0722 - acc: 0.974 - ETA: 3s - loss: 0.0675 - acc: 0.977 - ETA: 3s - loss: 0.0783 - acc: 0.972 - ETA: 3s - loss: 0.1089 - acc: 0.954 - ETA: 2s - loss: 0.1149 - acc: 0.956 - ETA: 2s - loss: 0.1197 - acc: 0.957 - ETA: 2s - loss: 0.1294 - acc: 0.947 - ETA: 2s - loss: 0.1454 - acc: 0.939 - ETA: 2s - loss: 0.1402 - acc: 0.944 - ETA: 2s - loss: 0.1368 - acc: 0.945 - ETA: 2s - loss: 0.1376 - acc: 0.945 - ETA: 2s - loss: 0.1332 - acc: 0.946 - ETA: 1s - loss: 0.1299 - acc: 0.949 - ETA: 1s - loss: 0.1273 - acc: 0.950 - ETA: 1s - loss: 0.1229 - acc: 0.953 - ETA: 1s - loss: 0.1226 - acc: 0.950 - ETA: 1s - loss: 0.1395 - acc: 0.950 - ETA: 1s - loss: 0.1400 - acc: 0.951 - ETA: 1s - loss: 0.1390 - acc: 0.951 - ETA: 0s - loss: 0.1393 - acc: 0.952 - ETA: 0s - loss: 0.1295 - acc: 0.954 - ETA: 0s - loss: 0.1256 - acc: 0.956 - ETA: 0s - loss: 0.1248 - acc: 0.956 - ETA: 0s - loss: 0.1247 - acc: 0.956 - ETA: 0s - loss: 0.1248 - acc: 0.955 - ETA: 0s - loss: 0.1242 - acc: 0.954 - 5s 137ms/step - loss: 0.1330 - acc: 0.9494 - val_loss: 2.1245 - val_acc: 0.7383\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/trial_id: 3cb6fe25d531d22c0db71e1ae7f1c856</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.87890625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 288)               22579488  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 289       \n",
      "=================================================================\n",
      "Total params: 22,655,425\n",
      "Trainable params: 22,655,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 21s - loss: 0.7010 - acc: 0.43 - ETA: 12s - loss: 8.2861 - acc: 0.50 - ETA: 9s - loss: 5.9651 - acc: 0.5521 - ETA: 7s - loss: 4.6581 - acc: 0.546 - ETA: 6s - loss: 3.8672 - acc: 0.550 - ETA: 5s - loss: 3.3412 - acc: 0.531 - ETA: 5s - loss: 2.9587 - acc: 0.558 - ETA: 4s - loss: 2.9350 - acc: 0.554 - ETA: 4s - loss: 2.6830 - acc: 0.552 - ETA: 4s - loss: 2.4793 - acc: 0.556 - ETA: 3s - loss: 2.3200 - acc: 0.536 - ETA: 3s - loss: 2.2663 - acc: 0.541 - ETA: 3s - loss: 2.1438 - acc: 0.540 - ETA: 3s - loss: 2.0354 - acc: 0.555 - ETA: 2s - loss: 2.2614 - acc: 0.548 - ETA: 2s - loss: 2.2785 - acc: 0.543 - ETA: 2s - loss: 2.1943 - acc: 0.537 - ETA: 2s - loss: 2.1142 - acc: 0.549 - ETA: 1s - loss: 2.0415 - acc: 0.558 - ETA: 1s - loss: 1.9764 - acc: 0.550 - ETA: 1s - loss: 1.9154 - acc: 0.565 - ETA: 1s - loss: 1.8607 - acc: 0.562 - ETA: 1s - loss: 1.8304 - acc: 0.558 - ETA: 1s - loss: 1.7806 - acc: 0.569 - ETA: 0s - loss: 1.7287 - acc: 0.577 - ETA: 0s - loss: 1.8513 - acc: 0.570 - ETA: 0s - loss: 1.8669 - acc: 0.570 - ETA: 0s - loss: 1.8272 - acc: 0.567 - ETA: 0s - loss: 1.7846 - acc: 0.570 - ETA: 0s - loss: 1.7459 - acc: 0.572 - ETA: 0s - loss: 1.7090 - acc: 0.580 - 5s 164ms/step - loss: 1.6762 - acc: 0.5803 - val_loss: 1.0622 - val_acc: 0.5664\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.4205 - acc: 0.750 - ETA: 5s - loss: 0.3515 - acc: 0.843 - ETA: 4s - loss: 1.9195 - acc: 0.687 - ETA: 4s - loss: 1.7849 - acc: 0.632 - ETA: 3s - loss: 1.5081 - acc: 0.693 - ETA: 3s - loss: 1.3289 - acc: 0.713 - ETA: 3s - loss: 1.1916 - acc: 0.745 - ETA: 3s - loss: 1.0810 - acc: 0.753 - ETA: 3s - loss: 1.0277 - acc: 0.750 - ETA: 3s - loss: 0.9562 - acc: 0.756 - ETA: 2s - loss: 0.8871 - acc: 0.769 - ETA: 2s - loss: 0.8428 - acc: 0.778 - ETA: 2s - loss: 0.9085 - acc: 0.764 - ETA: 2s - loss: 0.8382 - acc: 0.769 - ETA: 2s - loss: 0.8047 - acc: 0.776 - ETA: 1s - loss: 0.7963 - acc: 0.774 - ETA: 1s - loss: 0.7731 - acc: 0.775 - ETA: 1s - loss: 0.7548 - acc: 0.780 - ETA: 1s - loss: 0.7304 - acc: 0.790 - ETA: 1s - loss: 0.7036 - acc: 0.797 - ETA: 1s - loss: 0.6808 - acc: 0.805 - ETA: 1s - loss: 0.6674 - acc: 0.809 - ETA: 1s - loss: 0.6522 - acc: 0.813 - ETA: 0s - loss: 0.6354 - acc: 0.817 - ETA: 0s - loss: 0.6199 - acc: 0.821 - ETA: 0s - loss: 0.6010 - acc: 0.826 - ETA: 0s - loss: 0.5854 - acc: 0.829 - ETA: 0s - loss: 0.5671 - acc: 0.834 - ETA: 0s - loss: 0.5507 - acc: 0.838 - ETA: 0s - loss: 0.5353 - acc: 0.843 - ETA: 0s - loss: 0.5235 - acc: 0.846 - 5s 149ms/step - loss: 0.5108 - acc: 0.8491 - val_loss: 2.8096 - val_acc: 0.6992\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.1763 - acc: 0.906 - ETA: 5s - loss: 0.1577 - acc: 0.890 - ETA: 4s - loss: 0.1276 - acc: 0.927 - ETA: 4s - loss: 0.1174 - acc: 0.937 - ETA: 3s - loss: 0.1102 - acc: 0.943 - ETA: 3s - loss: 0.1029 - acc: 0.947 - ETA: 3s - loss: 0.0937 - acc: 0.955 - ETA: 3s - loss: 0.0838 - acc: 0.960 - ETA: 3s - loss: 0.0749 - acc: 0.965 - ETA: 2s - loss: 0.0616 - acc: 0.969 - ETA: 2s - loss: 0.0607 - acc: 0.969 - ETA: 2s - loss: 0.0579 - acc: 0.971 - ETA: 2s - loss: 0.0794 - acc: 0.969 - ETA: 2s - loss: 0.1417 - acc: 0.951 - ETA: 2s - loss: 0.1642 - acc: 0.944 - ETA: 1s - loss: 0.1840 - acc: 0.934 - ETA: 1s - loss: 0.1952 - acc: 0.926 - ETA: 1s - loss: 0.2024 - acc: 0.918 - ETA: 1s - loss: 0.2095 - acc: 0.913 - ETA: 1s - loss: 0.2045 - acc: 0.916 - ETA: 1s - loss: 0.2025 - acc: 0.917 - ETA: 1s - loss: 0.1941 - acc: 0.920 - ETA: 1s - loss: 0.1900 - acc: 0.922 - ETA: 0s - loss: 0.1919 - acc: 0.923 - ETA: 0s - loss: 0.1896 - acc: 0.924 - ETA: 0s - loss: 0.1873 - acc: 0.924 - ETA: 0s - loss: 0.1858 - acc: 0.925 - ETA: 0s - loss: 0.1809 - acc: 0.926 - ETA: 0s - loss: 0.1761 - acc: 0.929 - ETA: 0s - loss: 0.1709 - acc: 0.931 - ETA: 0s - loss: 0.1661 - acc: 0.933 - 5s 147ms/step - loss: 0.1688 - acc: 0.9348 - val_loss: 1.1545 - val_acc: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 288</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/trial_id: 4fd38579c2076231a98d6e605a8e1549</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.84375</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               10913920  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,916,817\n",
      "Trainable params: 10,916,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 18s - loss: 0.6876 - acc: 0.53 - ETA: 10s - loss: 8.1075 - acc: 0.51 - ETA: 8s - loss: 32.4225 - acc: 0.44 - ETA: 6s - loss: 28.6962 - acc: 0.42 - ETA: 5s - loss: 23.2306 - acc: 0.45 - ETA: 5s - loss: 19.8539 - acc: 0.45 - ETA: 4s - loss: 17.4115 - acc: 0.45 - ETA: 4s - loss: 15.3437 - acc: 0.44 - ETA: 4s - loss: 13.8110 - acc: 0.45 - ETA: 3s - loss: 12.4662 - acc: 0.49 - ETA: 3s - loss: 11.3741 - acc: 0.51 - ETA: 3s - loss: 10.4566 - acc: 0.54 - ETA: 3s - loss: 9.6858 - acc: 0.5673 - ETA: 2s - loss: 8.6471 - acc: 0.558 - ETA: 2s - loss: 8.1282 - acc: 0.575 - ETA: 2s - loss: 7.6688 - acc: 0.598 - ETA: 2s - loss: 7.2604 - acc: 0.614 - ETA: 1s - loss: 6.8882 - acc: 0.633 - ETA: 1s - loss: 6.5555 - acc: 0.649 - ETA: 1s - loss: 6.2752 - acc: 0.657 - ETA: 1s - loss: 6.0191 - acc: 0.659 - ETA: 1s - loss: 5.7857 - acc: 0.663 - ETA: 1s - loss: 5.5584 - acc: 0.669 - ETA: 1s - loss: 5.3463 - acc: 0.679 - ETA: 0s - loss: 5.1460 - acc: 0.692 - ETA: 0s - loss: 4.9594 - acc: 0.704 - ETA: 0s - loss: 4.7883 - acc: 0.712 - ETA: 0s - loss: 4.6259 - acc: 0.721 - ETA: 0s - loss: 4.4752 - acc: 0.731 - ETA: 0s - loss: 4.3355 - acc: 0.737 - ETA: 0s - loss: 4.2044 - acc: 0.744 - 5s 156ms/step - loss: 4.0874 - acc: 0.7488 - val_loss: 1.8797 - val_acc: 0.5273\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.2360 - acc: 0.812 - ETA: 4s - loss: 0.1716 - acc: 0.906 - ETA: 3s - loss: 0.1757 - acc: 0.927 - ETA: 3s - loss: 0.1629 - acc: 0.929 - ETA: 3s - loss: 0.1381 - acc: 0.943 - ETA: 2s - loss: 0.1063 - acc: 0.953 - ETA: 2s - loss: 0.0975 - acc: 0.960 - ETA: 2s - loss: 0.0887 - acc: 0.965 - ETA: 2s - loss: 0.0851 - acc: 0.969 - ETA: 2s - loss: 0.0871 - acc: 0.969 - ETA: 2s - loss: 0.0852 - acc: 0.969 - ETA: 2s - loss: 0.0865 - acc: 0.969 - ETA: 2s - loss: 0.0864 - acc: 0.969 - ETA: 2s - loss: 0.0905 - acc: 0.969 - ETA: 2s - loss: 0.0941 - acc: 0.964 - ETA: 1s - loss: 0.1149 - acc: 0.951 - ETA: 1s - loss: 0.1537 - acc: 0.936 - ETA: 1s - loss: 0.1693 - acc: 0.925 - ETA: 1s - loss: 0.1681 - acc: 0.926 - ETA: 1s - loss: 0.1623 - acc: 0.930 - ETA: 1s - loss: 0.1591 - acc: 0.931 - ETA: 1s - loss: 0.1566 - acc: 0.932 - ETA: 1s - loss: 0.1531 - acc: 0.933 - ETA: 0s - loss: 0.1520 - acc: 0.933 - ETA: 0s - loss: 0.1486 - acc: 0.936 - ETA: 0s - loss: 0.1444 - acc: 0.938 - ETA: 0s - loss: 0.1409 - acc: 0.941 - ETA: 0s - loss: 0.1373 - acc: 0.943 - ETA: 0s - loss: 0.1339 - acc: 0.945 - ETA: 0s - loss: 0.1312 - acc: 0.947 - ETA: 0s - loss: 0.1294 - acc: 0.948 - 5s 141ms/step - loss: 0.1282 - acc: 0.9484 - val_loss: 1.3767 - val_acc: 0.7422\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0312 - acc: 1.000 - ETA: 4s - loss: 0.0315 - acc: 1.000 - ETA: 3s - loss: 0.0231 - acc: 1.000 - ETA: 3s - loss: 0.0233 - acc: 1.000 - ETA: 3s - loss: 0.0205 - acc: 1.000 - ETA: 3s - loss: 0.0272 - acc: 0.989 - ETA: 3s - loss: 0.0338 - acc: 0.986 - ETA: 3s - loss: 0.0307 - acc: 0.988 - ETA: 2s - loss: 0.0297 - acc: 0.989 - ETA: 2s - loss: 0.0272 - acc: 0.990 - ETA: 2s - loss: 0.0270 - acc: 0.991 - ETA: 2s - loss: 0.0250 - acc: 0.992 - ETA: 2s - loss: 0.0236 - acc: 0.992 - ETA: 2s - loss: 0.0223 - acc: 0.993 - ETA: 2s - loss: 0.0228 - acc: 0.993 - ETA: 2s - loss: 0.0531 - acc: 0.988 - ETA: 1s - loss: 0.1066 - acc: 0.970 - ETA: 1s - loss: 0.1546 - acc: 0.951 - ETA: 1s - loss: 0.1569 - acc: 0.950 - ETA: 1s - loss: 0.1531 - acc: 0.953 - ETA: 1s - loss: 0.1484 - acc: 0.955 - ETA: 1s - loss: 0.1434 - acc: 0.957 - ETA: 1s - loss: 0.1380 - acc: 0.959 - ETA: 1s - loss: 0.1338 - acc: 0.960 - ETA: 0s - loss: 0.1303 - acc: 0.962 - ETA: 0s - loss: 0.1259 - acc: 0.963 - ETA: 0s - loss: 0.1218 - acc: 0.965 - ETA: 0s - loss: 0.1181 - acc: 0.966 - ETA: 0s - loss: 0.1156 - acc: 0.967 - ETA: 0s - loss: 0.1086 - acc: 0.968 - ETA: 0s - loss: 0.1055 - acc: 0.969 - 5s 140ms/step - loss: 0.1027 - acc: 0.9708 - val_loss: 1.4617 - val_acc: 0.7617\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/trial_id: 950d7c996a7a1c65da3b0ff4f44ce271</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.76171875</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 341056)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 416)               141879712 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 417       \n",
      "=================================================================\n",
      "Total params: 141,918,849\n",
      "Trainable params: 141,918,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 20s - loss: 0.6990 - acc: 0.50 - ETA: 11s - loss: 168.5954 - acc: 0.46 - ETA: 8s - loss: 120.7715 - acc: 0.5000 - ETA: 5s - loss: 78.6267 - acc: 0.511 - ETA: 5s - loss: 67.9975 - acc: 0.52 - ETA: 4s - loss: 58.9585 - acc: 0.52 - ETA: 4s - loss: 51.6927 - acc: 0.51 - ETA: 4s - loss: 46.4183 - acc: 0.49 - ETA: 3s - loss: 41.9862 - acc: 0.47 - ETA: 3s - loss: 38.2084 - acc: 0.50 - ETA: 3s - loss: 35.0769 - acc: 0.52 - ETA: 3s - loss: 32.4281 - acc: 0.53 - ETA: 2s - loss: 30.5236 - acc: 0.52 - ETA: 2s - loss: 28.5601 - acc: 0.51 - ETA: 2s - loss: 26.8111 - acc: 0.52 - ETA: 2s - loss: 25.2566 - acc: 0.53 - ETA: 2s - loss: 23.8810 - acc: 0.55 - ETA: 2s - loss: 22.6478 - acc: 0.56 - ETA: 1s - loss: 21.5282 - acc: 0.58 - ETA: 1s - loss: 20.5191 - acc: 0.59 - ETA: 1s - loss: 19.5978 - acc: 0.61 - ETA: 1s - loss: 18.8153 - acc: 0.60 - ETA: 1s - loss: 18.1172 - acc: 0.60 - ETA: 1s - loss: 17.4245 - acc: 0.61 - ETA: 0s - loss: 16.7674 - acc: 0.62 - ETA: 0s - loss: 16.1601 - acc: 0.63 - ETA: 0s - loss: 15.5927 - acc: 0.64 - ETA: 0s - loss: 15.0631 - acc: 0.65 - ETA: 0s - loss: 14.5667 - acc: 0.66 - ETA: 0s - loss: 14.1321 - acc: 0.66 - ETA: 0s - loss: 13.7649 - acc: 0.65 - 7s 210ms/step - loss: 13.5279 - acc: 0.6485 - val_loss: 2.6605 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 7s - loss: 0.6378 - acc: 0.625 - ETA: 5s - loss: 0.4368 - acc: 0.765 - ETA: 4s - loss: 0.5537 - acc: 0.760 - ETA: 4s - loss: 0.5934 - acc: 0.703 - ETA: 3s - loss: 0.4853 - acc: 0.742 - ETA: 3s - loss: 0.4301 - acc: 0.784 - ETA: 3s - loss: 0.3885 - acc: 0.810 - ETA: 2s - loss: 0.3516 - acc: 0.834 - ETA: 2s - loss: 0.3269 - acc: 0.848 - ETA: 2s - loss: 0.3099 - acc: 0.860 - ETA: 2s - loss: 0.3005 - acc: 0.864 - ETA: 2s - loss: 0.3042 - acc: 0.857 - ETA: 2s - loss: 0.2912 - acc: 0.861 - ETA: 2s - loss: 0.2783 - acc: 0.869 - ETA: 2s - loss: 0.2638 - acc: 0.877 - ETA: 1s - loss: 0.2547 - acc: 0.883 - ETA: 1s - loss: 0.2576 - acc: 0.879 - ETA: 1s - loss: 0.2496 - acc: 0.884 - ETA: 1s - loss: 0.2424 - acc: 0.890 - ETA: 1s - loss: 0.2357 - acc: 0.894 - ETA: 1s - loss: 0.2271 - acc: 0.899 - ETA: 1s - loss: 0.2216 - acc: 0.901 - ETA: 1s - loss: 0.2166 - acc: 0.905 - ETA: 0s - loss: 0.2095 - acc: 0.909 - ETA: 0s - loss: 0.2048 - acc: 0.911 - ETA: 0s - loss: 0.2003 - acc: 0.915 - ETA: 0s - loss: 0.1958 - acc: 0.918 - ETA: 0s - loss: 0.1934 - acc: 0.918 - ETA: 0s - loss: 0.2168 - acc: 0.910 - ETA: 0s - loss: 0.2353 - acc: 0.902 - ETA: 0s - loss: 0.6548 - acc: 0.890 - 6s 193ms/step - loss: 0.6582 - acc: 0.8832 - val_loss: 0.5392 - val_acc: 0.8242\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 7s - loss: 0.1749 - acc: 0.906 - ETA: 5s - loss: 0.2199 - acc: 0.906 - ETA: 5s - loss: 0.2598 - acc: 0.864 - ETA: 4s - loss: 0.2107 - acc: 0.898 - ETA: 4s - loss: 0.1850 - acc: 0.912 - ETA: 3s - loss: 0.1664 - acc: 0.921 - ETA: 3s - loss: 0.1707 - acc: 0.924 - ETA: 3s - loss: 0.1558 - acc: 0.933 - ETA: 3s - loss: 0.1432 - acc: 0.941 - ETA: 3s - loss: 0.1356 - acc: 0.946 - ETA: 2s - loss: 0.1250 - acc: 0.951 - ETA: 2s - loss: 0.1189 - acc: 0.953 - ETA: 2s - loss: 0.1136 - acc: 0.954 - ETA: 2s - loss: 0.1109 - acc: 0.955 - ETA: 2s - loss: 0.1058 - acc: 0.958 - ETA: 2s - loss: 0.1003 - acc: 0.960 - ETA: 2s - loss: 0.0951 - acc: 0.963 - ETA: 1s - loss: 0.0902 - acc: 0.965 - ETA: 1s - loss: 0.0861 - acc: 0.967 - ETA: 1s - loss: 0.0822 - acc: 0.968 - ETA: 1s - loss: 0.0784 - acc: 0.970 - ETA: 1s - loss: 0.0750 - acc: 0.971 - ETA: 1s - loss: 0.0752 - acc: 0.971 - ETA: 1s - loss: 0.0741 - acc: 0.972 - ETA: 1s - loss: 0.0752 - acc: 0.972 - ETA: 0s - loss: 0.0758 - acc: 0.972 - ETA: 0s - loss: 0.0831 - acc: 0.969 - ETA: 0s - loss: 0.3781 - acc: 0.953 - ETA: 0s - loss: 0.4637 - acc: 0.937 - ETA: 0s - loss: 0.4544 - acc: 0.935 - ETA: 0s - loss: 0.4421 - acc: 0.937 - 6s 195ms/step - loss: 0.4303 - acc: 0.9387 - val_loss: 0.5535 - val_acc: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_layer0: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_conv_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/initial_epoch: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/round: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/trial_id: 50af8c90f4c80da635f5922fa3ffc8ae</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.87109375</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 448)               1835456   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 449       \n",
      "=================================================================\n",
      "Total params: 1,851,569\n",
      "Trainable params: 1,851,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - ETA: 22s - loss: 0.6839 - acc: 0.56 - ETA: 12s - loss: 1.9440 - acc: 0.56 - ETA: 9s - loss: 1.5699 - acc: 0.5417 - ETA: 7s - loss: 1.3464 - acc: 0.570 - ETA: 5s - loss: 1.4696 - acc: 0.558 - ETA: 4s - loss: 1.3629 - acc: 0.543 - ETA: 4s - loss: 1.2790 - acc: 0.537 - ETA: 4s - loss: 1.2120 - acc: 0.536 - ETA: 3s - loss: 1.1549 - acc: 0.560 - ETA: 3s - loss: 1.1158 - acc: 0.551 - ETA: 3s - loss: 1.0777 - acc: 0.549 - ETA: 3s - loss: 1.0466 - acc: 0.537 - ETA: 2s - loss: 1.0176 - acc: 0.556 - ETA: 2s - loss: 0.9963 - acc: 0.547 - ETA: 2s - loss: 0.9720 - acc: 0.567 - ETA: 2s - loss: 0.9468 - acc: 0.588 - ETA: 2s - loss: 0.9195 - acc: 0.606 - ETA: 2s - loss: 0.8932 - acc: 0.620 - ETA: 1s - loss: 0.9189 - acc: 0.612 - ETA: 1s - loss: 0.9018 - acc: 0.617 - ETA: 1s - loss: 0.8850 - acc: 0.631 - ETA: 1s - loss: 0.8666 - acc: 0.646 - ETA: 1s - loss: 0.8489 - acc: 0.648 - ETA: 1s - loss: 0.8360 - acc: 0.656 - ETA: 0s - loss: 0.8368 - acc: 0.643 - ETA: 0s - loss: 0.8395 - acc: 0.637 - ETA: 0s - loss: 0.8225 - acc: 0.649 - ETA: 0s - loss: 0.8058 - acc: 0.657 - ETA: 0s - loss: 0.8111 - acc: 0.656 - ETA: 0s - loss: 0.8142 - acc: 0.649 - ETA: 0s - loss: 0.8025 - acc: 0.657 - 5s 156ms/step - loss: 0.7948 - acc: 0.6602 - val_loss: 0.5226 - val_acc: 0.7500\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.3690 - acc: 0.968 - ETA: 4s - loss: 0.3330 - acc: 0.968 - ETA: 4s - loss: 0.3242 - acc: 0.937 - ETA: 4s - loss: 0.3076 - acc: 0.929 - ETA: 3s - loss: 0.2692 - acc: 0.938 - ETA: 3s - loss: 0.2755 - acc: 0.923 - ETA: 2s - loss: 0.2689 - acc: 0.929 - ETA: 2s - loss: 0.2575 - acc: 0.930 - ETA: 2s - loss: 0.2591 - acc: 0.921 - ETA: 2s - loss: 0.2728 - acc: 0.913 - ETA: 2s - loss: 0.2782 - acc: 0.909 - ETA: 2s - loss: 0.2749 - acc: 0.914 - ETA: 2s - loss: 0.2771 - acc: 0.914 - ETA: 2s - loss: 0.2724 - acc: 0.915 - ETA: 2s - loss: 0.2705 - acc: 0.913 - ETA: 1s - loss: 0.2889 - acc: 0.906 - ETA: 1s - loss: 0.2874 - acc: 0.906 - ETA: 1s - loss: 0.2856 - acc: 0.906 - ETA: 1s - loss: 0.2814 - acc: 0.908 - ETA: 1s - loss: 0.2757 - acc: 0.908 - ETA: 1s - loss: 0.2705 - acc: 0.909 - ETA: 1s - loss: 0.2621 - acc: 0.912 - ETA: 1s - loss: 0.2583 - acc: 0.913 - ETA: 0s - loss: 0.2538 - acc: 0.914 - ETA: 0s - loss: 0.2497 - acc: 0.914 - ETA: 0s - loss: 0.2465 - acc: 0.915 - ETA: 0s - loss: 0.2501 - acc: 0.911 - ETA: 0s - loss: 0.2564 - acc: 0.905 - ETA: 0s - loss: 0.2555 - acc: 0.903 - ETA: 0s - loss: 0.2603 - acc: 0.900 - ETA: 0s - loss: 0.2625 - acc: 0.898 - 5s 138ms/step - loss: 0.2594 - acc: 0.9017 - val_loss: 0.9629 - val_acc: 0.7852\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.1958 - acc: 0.906 - ETA: 4s - loss: 0.1721 - acc: 0.921 - ETA: 3s - loss: 0.1256 - acc: 0.919 - ETA: 3s - loss: 0.1150 - acc: 0.931 - ETA: 3s - loss: 0.0992 - acc: 0.944 - ETA: 2s - loss: 0.1061 - acc: 0.943 - ETA: 2s - loss: 0.1034 - acc: 0.942 - ETA: 2s - loss: 0.0971 - acc: 0.945 - ETA: 2s - loss: 0.0925 - acc: 0.948 - ETA: 2s - loss: 0.0930 - acc: 0.947 - ETA: 2s - loss: 0.0945 - acc: 0.949 - ETA: 2s - loss: 0.1008 - acc: 0.948 - ETA: 2s - loss: 0.1080 - acc: 0.940 - ETA: 2s - loss: 0.1136 - acc: 0.937 - ETA: 2s - loss: 0.1451 - acc: 0.933 - ETA: 1s - loss: 0.1417 - acc: 0.937 - ETA: 1s - loss: 0.1404 - acc: 0.937 - ETA: 1s - loss: 0.1422 - acc: 0.936 - ETA: 1s - loss: 0.1416 - acc: 0.936 - ETA: 1s - loss: 0.1358 - acc: 0.939 - ETA: 1s - loss: 0.1330 - acc: 0.940 - ETA: 1s - loss: 0.1426 - acc: 0.937 - ETA: 1s - loss: 0.1476 - acc: 0.936 - ETA: 0s - loss: 0.1533 - acc: 0.935 - ETA: 0s - loss: 0.1552 - acc: 0.934 - ETA: 0s - loss: 0.1559 - acc: 0.934 - ETA: 0s - loss: 0.1643 - acc: 0.933 - ETA: 0s - loss: 0.1660 - acc: 0.932 - ETA: 0s - loss: 0.1655 - acc: 0.931 - ETA: 0s - loss: 0.1633 - acc: 0.932 - ETA: 0s - loss: 0.1594 - acc: 0.934 - 5s 136ms/step - loss: 0.1554 - acc: 0.9367 - val_loss: 1.5865 - val_acc: 0.8047\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0408 - acc: 1.000 - ETA: 4s - loss: 0.0360 - acc: 1.000 - ETA: 4s - loss: 0.0531 - acc: 0.989 - ETA: 4s - loss: 0.0477 - acc: 0.992 - ETA: 3s - loss: 0.0500 - acc: 0.987 - ETA: 2s - loss: 0.0519 - acc: 0.979 - ETA: 2s - loss: 0.0827 - acc: 0.960 - ETA: 2s - loss: 0.0866 - acc: 0.957 - ETA: 2s - loss: 0.0938 - acc: 0.958 - ETA: 2s - loss: 0.1831 - acc: 0.935 - ETA: 2s - loss: 0.2060 - acc: 0.929 - ETA: 2s - loss: 0.3804 - acc: 0.894 - ETA: 2s - loss: 0.3718 - acc: 0.890 - ETA: 2s - loss: 0.3823 - acc: 0.880 - ETA: 1s - loss: 0.3725 - acc: 0.884 - ETA: 1s - loss: 0.3560 - acc: 0.891 - ETA: 1s - loss: 0.3409 - acc: 0.897 - ETA: 1s - loss: 0.3265 - acc: 0.903 - ETA: 1s - loss: 0.3130 - acc: 0.908 - ETA: 1s - loss: 0.3005 - acc: 0.912 - ETA: 1s - loss: 0.2903 - acc: 0.915 - ETA: 1s - loss: 0.2820 - acc: 0.918 - ETA: 1s - loss: 0.2708 - acc: 0.921 - ETA: 0s - loss: 0.2637 - acc: 0.922 - ETA: 0s - loss: 0.2592 - acc: 0.922 - ETA: 0s - loss: 0.2530 - acc: 0.924 - ETA: 0s - loss: 0.2457 - acc: 0.927 - ETA: 0s - loss: 0.2379 - acc: 0.929 - ETA: 0s - loss: 0.2322 - acc: 0.931 - ETA: 0s - loss: 0.2265 - acc: 0.932 - ETA: 0s - loss: 0.2205 - acc: 0.934 - 5s 137ms/step - loss: 0.2189 - acc: 0.9348 - val_loss: 0.8485 - val_acc: 0.8711\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.2578 - acc: 0.937 - ETA: 4s - loss: 0.2387 - acc: 0.921 - ETA: 4s - loss: 0.1763 - acc: 0.947 - ETA: 3s - loss: 0.1466 - acc: 0.960 - ETA: 3s - loss: 0.1186 - acc: 0.968 - ETA: 3s - loss: 0.1085 - acc: 0.968 - ETA: 3s - loss: 0.0951 - acc: 0.973 - ETA: 3s - loss: 0.0845 - acc: 0.976 - ETA: 2s - loss: 0.0682 - acc: 0.979 - ETA: 2s - loss: 0.0699 - acc: 0.975 - ETA: 2s - loss: 0.0672 - acc: 0.974 - ETA: 2s - loss: 0.0670 - acc: 0.974 - ETA: 2s - loss: 0.0652 - acc: 0.973 - ETA: 2s - loss: 0.0616 - acc: 0.975 - ETA: 1s - loss: 0.0583 - acc: 0.977 - ETA: 1s - loss: 0.0558 - acc: 0.978 - ETA: 1s - loss: 0.0538 - acc: 0.979 - ETA: 1s - loss: 0.0520 - acc: 0.981 - ETA: 1s - loss: 0.0501 - acc: 0.982 - ETA: 1s - loss: 0.0511 - acc: 0.981 - ETA: 1s - loss: 0.0500 - acc: 0.982 - ETA: 1s - loss: 0.0492 - acc: 0.983 - ETA: 1s - loss: 0.0480 - acc: 0.983 - ETA: 0s - loss: 0.0468 - acc: 0.984 - ETA: 0s - loss: 0.0453 - acc: 0.985 - ETA: 0s - loss: 0.0437 - acc: 0.985 - ETA: 0s - loss: 0.0426 - acc: 0.986 - ETA: 0s - loss: 0.0412 - acc: 0.986 - ETA: 0s - loss: 0.0399 - acc: 0.987 - ETA: 0s - loss: 0.0386 - acc: 0.987 - ETA: 0s - loss: 0.0412 - acc: 0.985 - 4s 134ms/step - loss: 0.0921 - acc: 0.9747 - val_loss: 7.4767 - val_acc: 0.6055\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 1.1328 - acc: 0.656 - ETA: 4s - loss: 0.6603 - acc: 0.765 - ETA: 4s - loss: 0.4521 - acc: 0.843 - ETA: 3s - loss: 0.3458 - acc: 0.882 - ETA: 3s - loss: 0.2844 - acc: 0.906 - ETA: 3s - loss: 0.2390 - acc: 0.921 - ETA: 3s - loss: 0.2068 - acc: 0.933 - ETA: 3s - loss: 0.1825 - acc: 0.941 - ETA: 3s - loss: 0.1640 - acc: 0.947 - ETA: 2s - loss: 0.1502 - acc: 0.953 - ETA: 2s - loss: 0.1383 - acc: 0.957 - ETA: 2s - loss: 0.1271 - acc: 0.960 - ETA: 2s - loss: 0.1179 - acc: 0.963 - ETA: 2s - loss: 0.1117 - acc: 0.964 - ETA: 2s - loss: 0.1081 - acc: 0.966 - ETA: 2s - loss: 0.1027 - acc: 0.968 - ETA: 1s - loss: 0.0975 - acc: 0.970 - ETA: 1s - loss: 0.0927 - acc: 0.972 - ETA: 1s - loss: 0.0899 - acc: 0.972 - ETA: 1s - loss: 0.0862 - acc: 0.973 - ETA: 1s - loss: 0.0828 - acc: 0.974 - ETA: 1s - loss: 0.0791 - acc: 0.975 - ETA: 1s - loss: 0.0727 - acc: 0.977 - ETA: 0s - loss: 0.0698 - acc: 0.978 - ETA: 0s - loss: 0.0681 - acc: 0.977 - ETA: 0s - loss: 0.0723 - acc: 0.976 - ETA: 0s - loss: 0.0752 - acc: 0.974 - ETA: 0s - loss: 0.0736 - acc: 0.975 - ETA: 0s - loss: 0.0722 - acc: 0.975 - ETA: 0s - loss: 0.0712 - acc: 0.976 - ETA: 0s - loss: 0.0696 - acc: 0.976 - 4s 134ms/step - loss: 0.0677 - acc: 0.9776 - val_loss: 1.9539 - val_acc: 0.8203\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0074 - acc: 1.000 - ETA: 4s - loss: 0.0083 - acc: 1.000 - ETA: 4s - loss: 0.0091 - acc: 1.000 - ETA: 3s - loss: 0.0069 - acc: 1.000 - ETA: 3s - loss: 0.0062 - acc: 1.000 - ETA: 3s - loss: 0.0073 - acc: 1.000 - ETA: 3s - loss: 0.0092 - acc: 1.000 - ETA: 3s - loss: 0.0116 - acc: 1.000 - ETA: 3s - loss: 0.0115 - acc: 1.000 - ETA: 2s - loss: 0.0111 - acc: 1.000 - ETA: 2s - loss: 0.0107 - acc: 1.000 - ETA: 2s - loss: 0.0099 - acc: 1.000 - ETA: 2s - loss: 0.0094 - acc: 1.000 - ETA: 2s - loss: 0.0087 - acc: 1.000 - ETA: 2s - loss: 0.0082 - acc: 1.000 - ETA: 2s - loss: 0.0077 - acc: 1.000 - ETA: 1s - loss: 0.0072 - acc: 1.000 - ETA: 1s - loss: 0.0069 - acc: 1.000 - ETA: 1s - loss: 0.0066 - acc: 1.000 - ETA: 1s - loss: 0.0076 - acc: 0.998 - ETA: 1s - loss: 0.0159 - acc: 0.991 - ETA: 1s - loss: 0.0220 - acc: 0.988 - ETA: 1s - loss: 0.0919 - acc: 0.975 - ETA: 1s - loss: 0.0947 - acc: 0.975 - ETA: 0s - loss: 0.0963 - acc: 0.975 - ETA: 0s - loss: 0.0952 - acc: 0.976 - ETA: 0s - loss: 0.0906 - acc: 0.976 - ETA: 0s - loss: 0.0884 - acc: 0.977 - ETA: 0s - loss: 0.0902 - acc: 0.977 - ETA: 0s - loss: 0.0887 - acc: 0.978 - ETA: 0s - loss: 0.0885 - acc: 0.977 - 4s 134ms/step - loss: 0.0873 - acc: 0.9786 - val_loss: 1.6395 - val_acc: 0.7930\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0646 - acc: 0.968 - ETA: 4s - loss: 0.0352 - acc: 0.984 - ETA: 4s - loss: 0.0288 - acc: 0.989 - ETA: 3s - loss: 0.0238 - acc: 0.992 - ETA: 3s - loss: 0.0290 - acc: 0.987 - ETA: 3s - loss: 0.0256 - acc: 0.989 - ETA: 3s - loss: 0.0225 - acc: 0.991 - ETA: 3s - loss: 0.0198 - acc: 0.992 - ETA: 3s - loss: 0.0180 - acc: 0.993 - ETA: 2s - loss: 0.0201 - acc: 0.990 - ETA: 2s - loss: 0.0188 - acc: 0.991 - ETA: 2s - loss: 0.0178 - acc: 0.992 - ETA: 2s - loss: 0.0167 - acc: 0.992 - ETA: 2s - loss: 0.0160 - acc: 0.993 - ETA: 2s - loss: 0.0157 - acc: 0.993 - ETA: 2s - loss: 0.0148 - acc: 0.994 - ETA: 1s - loss: 0.0167 - acc: 0.992 - ETA: 1s - loss: 0.0689 - acc: 0.979 - ETA: 1s - loss: 0.1329 - acc: 0.972 - ETA: 1s - loss: 0.1317 - acc: 0.970 - ETA: 1s - loss: 0.1258 - acc: 0.971 - ETA: 1s - loss: 0.1204 - acc: 0.973 - ETA: 1s - loss: 0.1186 - acc: 0.972 - ETA: 1s - loss: 0.1139 - acc: 0.974 - ETA: 0s - loss: 0.1098 - acc: 0.975 - ETA: 0s - loss: 0.1056 - acc: 0.976 - ETA: 0s - loss: 0.1018 - acc: 0.976 - ETA: 0s - loss: 0.0982 - acc: 0.977 - ETA: 0s - loss: 0.0925 - acc: 0.978 - ETA: 0s - loss: 0.0896 - acc: 0.979 - ETA: 0s - loss: 0.0869 - acc: 0.979 - 4s 134ms/step - loss: 0.0849 - acc: 0.9805 - val_loss: 1.5616 - val_acc: 0.8516\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0059 - acc: 1.000 - ETA: 4s - loss: 0.0049 - acc: 1.000 - ETA: 4s - loss: 0.0035 - acc: 1.000 - ETA: 4s - loss: 0.0027 - acc: 1.000 - ETA: 3s - loss: 0.0026 - acc: 1.000 - ETA: 3s - loss: 0.0027 - acc: 1.000 - ETA: 3s - loss: 0.0024 - acc: 1.000 - ETA: 3s - loss: 0.0033 - acc: 1.000 - ETA: 3s - loss: 0.0039 - acc: 1.000 - ETA: 2s - loss: 0.0041 - acc: 1.000 - ETA: 2s - loss: 0.0038 - acc: 1.000 - ETA: 2s - loss: 0.0035 - acc: 1.000 - ETA: 2s - loss: 0.0030 - acc: 1.000 - ETA: 2s - loss: 0.0029 - acc: 1.000 - ETA: 1s - loss: 0.0030 - acc: 1.000 - ETA: 1s - loss: 0.0029 - acc: 1.000 - ETA: 1s - loss: 0.0028 - acc: 1.000 - ETA: 1s - loss: 0.0026 - acc: 1.000 - ETA: 1s - loss: 0.0026 - acc: 1.000 - ETA: 1s - loss: 0.0038 - acc: 0.998 - ETA: 1s - loss: 0.0040 - acc: 0.998 - ETA: 1s - loss: 0.0052 - acc: 0.997 - ETA: 1s - loss: 0.0067 - acc: 0.997 - ETA: 0s - loss: 0.0065 - acc: 0.997 - ETA: 0s - loss: 0.0074 - acc: 0.996 - ETA: 0s - loss: 0.0077 - acc: 0.996 - ETA: 0s - loss: 0.0100 - acc: 0.996 - ETA: 0s - loss: 0.0097 - acc: 0.996 - ETA: 0s - loss: 0.0112 - acc: 0.995 - ETA: 0s - loss: 0.0110 - acc: 0.995 - ETA: 0s - loss: 0.0159 - acc: 0.994 - 4s 134ms/step - loss: 0.0178 - acc: 0.9922 - val_loss: 3.4140 - val_acc: 0.6875\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0433 - acc: 1.000 - ETA: 4s - loss: 0.0239 - acc: 1.000 - ETA: 4s - loss: 0.0171 - acc: 1.000 - ETA: 3s - loss: 0.0130 - acc: 1.000 - ETA: 3s - loss: 0.0107 - acc: 1.000 - ETA: 3s - loss: 0.0093 - acc: 1.000 - ETA: 3s - loss: 0.0080 - acc: 1.000 - ETA: 3s - loss: 0.0071 - acc: 1.000 - ETA: 3s - loss: 0.0063 - acc: 1.000 - ETA: 2s - loss: 0.0057 - acc: 1.000 - ETA: 2s - loss: 0.0053 - acc: 1.000 - ETA: 2s - loss: 0.0049 - acc: 1.000 - ETA: 2s - loss: 0.0045 - acc: 1.000 - ETA: 2s - loss: 0.0045 - acc: 1.000 - ETA: 2s - loss: 0.0043 - acc: 1.000 - ETA: 2s - loss: 0.0042 - acc: 1.000 - ETA: 1s - loss: 0.0040 - acc: 1.000 - ETA: 1s - loss: 0.0039 - acc: 1.000 - ETA: 1s - loss: 0.0048 - acc: 1.000 - ETA: 1s - loss: 0.0048 - acc: 1.000 - ETA: 1s - loss: 0.0222 - acc: 0.995 - ETA: 1s - loss: 0.0500 - acc: 0.987 - ETA: 1s - loss: 0.0504 - acc: 0.987 - ETA: 1s - loss: 0.0499 - acc: 0.988 - ETA: 0s - loss: 0.0505 - acc: 0.987 - ETA: 0s - loss: 0.0508 - acc: 0.988 - ETA: 0s - loss: 0.0526 - acc: 0.987 - ETA: 0s - loss: 0.0513 - acc: 0.987 - ETA: 0s - loss: 0.0497 - acc: 0.988 - ETA: 0s - loss: 0.0481 - acc: 0.988 - ETA: 0s - loss: 0.0452 - acc: 0.988 - 4s 134ms/step - loss: 0.0443 - acc: 0.9893 - val_loss: 2.4499 - val_acc: 0.7734\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 15</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/trial_id: 6a38b079fa13248ce48444102a22e1ed</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.87109375</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 341056)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 416)               141879712 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 417       \n",
      "=================================================================\n",
      "Total params: 141,918,849\n",
      "Trainable params: 141,918,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - ETA: 20s - loss: 0.6899 - acc: 0.53 - ETA: 11s - loss: 8.9209 - acc: 0.59 - ETA: 8s - loss: 42.4200 - acc: 0.57 - ETA: 7s - loss: 34.0005 - acc: 0.54 - ETA: 6s - loss: 28.8477 - acc: 0.51 - ETA: 5s - loss: 24.4998 - acc: 0.51 - ETA: 4s - loss: 21.0792 - acc: 0.57 - ETA: 4s - loss: 18.5879 - acc: 0.54 - ETA: 4s - loss: 16.5810 - acc: 0.56 - ETA: 3s - loss: 14.9817 - acc: 0.58 - ETA: 3s - loss: 13.6602 - acc: 0.61 - ETA: 3s - loss: 12.5665 - acc: 0.62 - ETA: 3s - loss: 11.6328 - acc: 0.64 - ETA: 2s - loss: 11.1858 - acc: 0.62 - ETA: 2s - loss: 10.4768 - acc: 0.62 - ETA: 2s - loss: 10.4784 - acc: 0.61 - ETA: 2s - loss: 9.9032 - acc: 0.6029 - ETA: 2s - loss: 9.4011 - acc: 0.604 - ETA: 2s - loss: 8.9266 - acc: 0.618 - ETA: 1s - loss: 8.4913 - acc: 0.635 - ETA: 1s - loss: 8.1025 - acc: 0.645 - ETA: 1s - loss: 7.7433 - acc: 0.659 - ETA: 1s - loss: 7.9500 - acc: 0.645 - ETA: 1s - loss: 7.7154 - acc: 0.649 - ETA: 1s - loss: 7.4315 - acc: 0.646 - ETA: 0s - loss: 7.1753 - acc: 0.646 - ETA: 0s - loss: 6.9239 - acc: 0.650 - ETA: 0s - loss: 6.6856 - acc: 0.660 - ETA: 0s - loss: 6.4634 - acc: 0.670 - ETA: 0s - loss: 6.2751 - acc: 0.667 - ETA: 0s - loss: 6.0880 - acc: 0.667 - ETA: 0s - loss: 5.9029 - acc: 0.676 - 7s 206ms/step - loss: 5.7297 - acc: 0.6777 - val_loss: 7.8874 - val_acc: 0.5000\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - ETA: 7s - loss: 7.8996 - acc: 0.437 - ETA: 5s - loss: 4.2117 - acc: 0.625 - ETA: 4s - loss: 2.8770 - acc: 0.739 - ETA: 4s - loss: 2.2129 - acc: 0.796 - ETA: 4s - loss: 1.8023 - acc: 0.825 - ETA: 3s - loss: 1.5209 - acc: 0.849 - ETA: 3s - loss: 1.3547 - acc: 0.834 - ETA: 3s - loss: 1.2016 - acc: 0.847 - ETA: 3s - loss: 1.0964 - acc: 0.850 - ETA: 3s - loss: 0.9944 - acc: 0.865 - ETA: 2s - loss: 0.9139 - acc: 0.875 - ETA: 2s - loss: 0.8450 - acc: 0.880 - ETA: 2s - loss: 0.7824 - acc: 0.889 - ETA: 2s - loss: 0.7313 - acc: 0.895 - ETA: 2s - loss: 0.6867 - acc: 0.900 - ETA: 2s - loss: 0.6483 - acc: 0.904 - ETA: 2s - loss: 0.6830 - acc: 0.889 - ETA: 1s - loss: 0.7379 - acc: 0.871 - ETA: 1s - loss: 0.7065 - acc: 0.876 - ETA: 1s - loss: 0.7334 - acc: 0.871 - ETA: 1s - loss: 0.7083 - acc: 0.873 - ETA: 1s - loss: 0.6844 - acc: 0.876 - ETA: 1s - loss: 0.6625 - acc: 0.876 - ETA: 1s - loss: 0.6381 - acc: 0.881 - ETA: 1s - loss: 0.6141 - acc: 0.886 - ETA: 0s - loss: 0.5949 - acc: 0.888 - ETA: 0s - loss: 0.5737 - acc: 0.892 - ETA: 0s - loss: 0.5541 - acc: 0.896 - ETA: 0s - loss: 0.5365 - acc: 0.898 - ETA: 0s - loss: 0.5201 - acc: 0.902 - ETA: 0s - loss: 0.5052 - acc: 0.904 - 6s 194ms/step - loss: 0.4776 - acc: 0.9065 - val_loss: 1.2510 - val_acc: 0.8203\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - ETA: 7s - loss: 0.0576 - acc: 1.000 - ETA: 5s - loss: 0.0507 - acc: 1.000 - ETA: 4s - loss: 0.0501 - acc: 0.989 - ETA: 4s - loss: 0.0424 - acc: 0.992 - ETA: 4s - loss: 0.0372 - acc: 0.993 - ETA: 3s - loss: 0.0373 - acc: 0.989 - ETA: 3s - loss: 0.0344 - acc: 0.991 - ETA: 3s - loss: 0.0309 - acc: 0.992 - ETA: 3s - loss: 0.0286 - acc: 0.993 - ETA: 3s - loss: 0.0262 - acc: 0.993 - ETA: 2s - loss: 0.0246 - acc: 0.994 - ETA: 2s - loss: 0.0235 - acc: 0.994 - ETA: 2s - loss: 0.0222 - acc: 0.995 - ETA: 2s - loss: 0.0194 - acc: 0.995 - ETA: 2s - loss: 0.0183 - acc: 0.995 - ETA: 1s - loss: 0.0173 - acc: 0.996 - ETA: 1s - loss: 0.0166 - acc: 0.996 - ETA: 1s - loss: 0.0159 - acc: 0.996 - ETA: 1s - loss: 0.0151 - acc: 0.996 - ETA: 1s - loss: 0.0155 - acc: 0.996 - ETA: 1s - loss: 0.0519 - acc: 0.985 - ETA: 1s - loss: 0.1517 - acc: 0.966 - ETA: 1s - loss: 0.1686 - acc: 0.962 - ETA: 0s - loss: 0.4165 - acc: 0.948 - ETA: 0s - loss: 0.4445 - acc: 0.941 - ETA: 0s - loss: 1.4659 - acc: 0.922 - ETA: 0s - loss: 1.4479 - acc: 0.911 - ETA: 0s - loss: 1.3999 - acc: 0.914 - ETA: 0s - loss: 1.3559 - acc: 0.916 - ETA: 0s - loss: 1.3140 - acc: 0.918 - ETA: 0s - loss: 1.2774 - acc: 0.917 - 5s 137ms/step - loss: 1.2416 - acc: 0.9192 - val_loss: 2.3963 - val_acc: 0.7188\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - ETA: 7s - loss: 0.0124 - acc: 1.000 - ETA: 5s - loss: 0.0487 - acc: 0.984 - ETA: 4s - loss: 0.0408 - acc: 0.989 - ETA: 4s - loss: 0.0326 - acc: 0.992 - ETA: 3s - loss: 0.0311 - acc: 0.993 - ETA: 3s - loss: 0.0355 - acc: 0.994 - ETA: 3s - loss: 0.0325 - acc: 0.995 - ETA: 3s - loss: 0.0296 - acc: 0.996 - ETA: 3s - loss: 0.0287 - acc: 0.996 - ETA: 2s - loss: 0.0267 - acc: 0.996 - ETA: 2s - loss: 0.0257 - acc: 0.997 - ETA: 2s - loss: 0.0247 - acc: 0.997 - ETA: 2s - loss: 0.0256 - acc: 0.997 - ETA: 2s - loss: 0.0243 - acc: 0.997 - ETA: 2s - loss: 0.0229 - acc: 0.997 - ETA: 2s - loss: 0.0216 - acc: 0.998 - ETA: 2s - loss: 0.0204 - acc: 0.998 - ETA: 1s - loss: 0.0194 - acc: 0.998 - ETA: 1s - loss: 0.0185 - acc: 0.998 - ETA: 1s - loss: 0.0177 - acc: 0.998 - ETA: 1s - loss: 0.0170 - acc: 0.998 - ETA: 1s - loss: 0.0162 - acc: 0.998 - ETA: 1s - loss: 0.0155 - acc: 0.998 - ETA: 1s - loss: 0.0149 - acc: 0.998 - ETA: 0s - loss: 0.0144 - acc: 0.998 - ETA: 0s - loss: 0.0138 - acc: 0.998 - ETA: 0s - loss: 0.0134 - acc: 0.998 - ETA: 0s - loss: 0.0129 - acc: 0.998 - ETA: 0s - loss: 0.0121 - acc: 0.998 - ETA: 0s - loss: 0.0118 - acc: 0.999 - ETA: 0s - loss: 0.0156 - acc: 0.998 - 6s 191ms/step - loss: 0.0345 - acc: 0.9883 - val_loss: 0.5271 - val_acc: 0.8945\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - ETA: 7s - loss: 0.6949 - acc: 0.781 - ETA: 5s - loss: 0.5767 - acc: 0.796 - ETA: 4s - loss: 0.4006 - acc: 0.864 - ETA: 4s - loss: 0.3017 - acc: 0.898 - ETA: 4s - loss: 0.2417 - acc: 0.918 - ETA: 3s - loss: 0.2019 - acc: 0.932 - ETA: 3s - loss: 0.1783 - acc: 0.937 - ETA: 3s - loss: 0.1631 - acc: 0.941 - ETA: 3s - loss: 0.1475 - acc: 0.947 - ETA: 3s - loss: 0.1328 - acc: 0.953 - ETA: 2s - loss: 0.1275 - acc: 0.954 - ETA: 2s - loss: 0.1183 - acc: 0.958 - ETA: 2s - loss: 0.1186 - acc: 0.959 - ETA: 2s - loss: 0.1115 - acc: 0.962 - ETA: 2s - loss: 0.1054 - acc: 0.964 - ETA: 2s - loss: 0.1049 - acc: 0.964 - ETA: 2s - loss: 0.1008 - acc: 0.966 - ETA: 1s - loss: 0.0962 - acc: 0.968 - ETA: 1s - loss: 0.0911 - acc: 0.970 - ETA: 1s - loss: 0.0866 - acc: 0.971 - ETA: 1s - loss: 0.0829 - acc: 0.973 - ETA: 1s - loss: 0.0792 - acc: 0.974 - ETA: 1s - loss: 0.0758 - acc: 0.975 - ETA: 1s - loss: 0.0727 - acc: 0.976 - ETA: 1s - loss: 0.0699 - acc: 0.977 - ETA: 0s - loss: 0.0673 - acc: 0.978 - ETA: 0s - loss: 0.0648 - acc: 0.979 - ETA: 0s - loss: 0.0625 - acc: 0.979 - ETA: 0s - loss: 0.0604 - acc: 0.980 - ETA: 0s - loss: 0.0584 - acc: 0.981 - ETA: 0s - loss: 0.0550 - acc: 0.981 - 5s 137ms/step - loss: 0.0534 - acc: 0.9825 - val_loss: 3.9625 - val_acc: 0.7578\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - ETA: 7s - loss: 0.0577 - acc: 0.968 - ETA: 5s - loss: 0.3781 - acc: 0.906 - ETA: 4s - loss: 0.2537 - acc: 0.937 - ETA: 4s - loss: 0.3016 - acc: 0.929 - ETA: 4s - loss: 3.1460 - acc: 0.837 - ETA: 3s - loss: 2.7959 - acc: 0.812 - ETA: 3s - loss: 2.4109 - acc: 0.834 - ETA: 3s - loss: 2.1276 - acc: 0.843 - ETA: 3s - loss: 1.9065 - acc: 0.857 - ETA: 3s - loss: 1.7204 - acc: 0.871 - ETA: 2s - loss: 1.5673 - acc: 0.883 - ETA: 2s - loss: 1.4395 - acc: 0.893 - ETA: 2s - loss: 1.3302 - acc: 0.901 - ETA: 2s - loss: 1.2417 - acc: 0.906 - ETA: 2s - loss: 1.1632 - acc: 0.912 - ETA: 2s - loss: 1.0936 - acc: 0.918 - ETA: 2s - loss: 1.0344 - acc: 0.919 - ETA: 1s - loss: 0.9773 - acc: 0.923 - ETA: 1s - loss: 0.9264 - acc: 0.927 - ETA: 1s - loss: 0.8804 - acc: 0.931 - ETA: 1s - loss: 0.8405 - acc: 0.933 - ETA: 1s - loss: 0.8028 - acc: 0.936 - ETA: 1s - loss: 0.7682 - acc: 0.938 - ETA: 1s - loss: 0.7411 - acc: 0.938 - ETA: 0s - loss: 0.7120 - acc: 0.941 - ETA: 0s - loss: 0.6601 - acc: 0.943 - ETA: 0s - loss: 0.6367 - acc: 0.945 - ETA: 0s - loss: 0.6147 - acc: 0.947 - ETA: 0s - loss: 0.5946 - acc: 0.949 - ETA: 0s - loss: 0.5754 - acc: 0.951 - ETA: 0s - loss: 0.5576 - acc: 0.952 - 4s 136ms/step - loss: 0.5412 - acc: 0.9542 - val_loss: 2.4017 - val_acc: 0.8320\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - ETA: 7s - loss: 5.5745e-04 - acc: 1.000 - ETA: 5s - loss: 0.0027 - acc: 1.0000    - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0018 - acc: 1.000 - ETA: 3s - loss: 0.0018 - acc: 1.000 - ETA: 3s - loss: 0.0017 - acc: 1.000 - ETA: 3s - loss: 0.0016 - acc: 1.000 - ETA: 3s - loss: 0.0014 - acc: 1.000 - ETA: 3s - loss: 0.0014 - acc: 1.000 - ETA: 2s - loss: 0.0013 - acc: 1.000 - ETA: 2s - loss: 0.0013 - acc: 1.000 - ETA: 2s - loss: 0.0014 - acc: 1.000 - ETA: 2s - loss: 0.0014 - acc: 1.000 - ETA: 2s - loss: 0.0013 - acc: 1.000 - ETA: 2s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0012 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0010 - acc: 1.000 - ETA: 1s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 0.997 - ETA: 0s - loss: 0.0046 - acc: 0.996 - ETA: 0s - loss: 0.0742 - acc: 0.982 - ETA: 0s - loss: 0.0719 - acc: 0.983 - ETA: 0s - loss: 2.8706 - acc: 0.964 - ETA: 0s - loss: 3.3061 - acc: 0.940 - ETA: 0s - loss: 3.2145 - acc: 0.937 - 4s 136ms/step - loss: 3.1275 - acc: 0.9348 - val_loss: 8.3868 - val_acc: 0.5859\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - ETA: 7s - loss: 0.3369 - acc: 0.781 - ETA: 5s - loss: 0.2059 - acc: 0.875 - ETA: 4s - loss: 0.1387 - acc: 0.916 - ETA: 4s - loss: 0.1204 - acc: 0.929 - ETA: 3s - loss: 0.1025 - acc: 0.943 - ETA: 3s - loss: 0.1075 - acc: 0.942 - ETA: 3s - loss: 0.0954 - acc: 0.950 - ETA: 3s - loss: 0.0855 - acc: 0.957 - ETA: 3s - loss: 0.0780 - acc: 0.961 - ETA: 3s - loss: 0.0744 - acc: 0.965 - ETA: 2s - loss: 0.0679 - acc: 0.968 - ETA: 2s - loss: 0.0632 - acc: 0.971 - ETA: 2s - loss: 0.0612 - acc: 0.971 - ETA: 2s - loss: 0.0569 - acc: 0.973 - ETA: 2s - loss: 0.0540 - acc: 0.975 - ETA: 2s - loss: 0.0508 - acc: 0.976 - ETA: 2s - loss: 0.0479 - acc: 0.977 - ETA: 1s - loss: 0.0453 - acc: 0.979 - ETA: 1s - loss: 0.0437 - acc: 0.980 - ETA: 1s - loss: 0.0415 - acc: 0.981 - ETA: 1s - loss: 0.0396 - acc: 0.982 - ETA: 1s - loss: 0.0378 - acc: 0.983 - ETA: 1s - loss: 0.0362 - acc: 0.983 - ETA: 1s - loss: 0.0348 - acc: 0.984 - ETA: 0s - loss: 0.0335 - acc: 0.985 - ETA: 0s - loss: 0.0311 - acc: 0.985 - ETA: 0s - loss: 0.0300 - acc: 0.986 - ETA: 0s - loss: 0.0290 - acc: 0.986 - ETA: 0s - loss: 0.0280 - acc: 0.987 - ETA: 0s - loss: 0.0271 - acc: 0.987 - ETA: 0s - loss: 0.0263 - acc: 0.987 - 4s 136ms/step - loss: 0.0255 - acc: 0.9883 - val_loss: 4.1878 - val_acc: 0.7852\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - ETA: 7s - loss: 2.5206e-04 - acc: 1.000 - ETA: 5s - loss: 1.4359e-04 - acc: 1.000 - ETA: 4s - loss: 1.8021e-04 - acc: 1.000 - ETA: 4s - loss: 1.5952e-04 - acc: 1.000 - ETA: 3s - loss: 1.4498e-04 - acc: 1.000 - ETA: 3s - loss: 1.4070e-04 - acc: 1.000 - ETA: 3s - loss: 1.2549e-04 - acc: 1.000 - ETA: 2s - loss: 1.5000e-04 - acc: 1.000 - ETA: 2s - loss: 1.3832e-04 - acc: 1.000 - ETA: 2s - loss: 1.3449e-04 - acc: 1.000 - ETA: 2s - loss: 1.7197e-04 - acc: 1.000 - ETA: 2s - loss: 1.6502e-04 - acc: 1.000 - ETA: 2s - loss: 1.6101e-04 - acc: 1.000 - ETA: 2s - loss: 1.6134e-04 - acc: 1.000 - ETA: 2s - loss: 1.5859e-04 - acc: 1.000 - ETA: 1s - loss: 1.5468e-04 - acc: 1.000 - ETA: 1s - loss: 1.6732e-04 - acc: 1.000 - ETA: 1s - loss: 1.7476e-04 - acc: 1.000 - ETA: 1s - loss: 1.9080e-04 - acc: 1.000 - ETA: 1s - loss: 1.9366e-04 - acc: 1.000 - ETA: 1s - loss: 1.8905e-04 - acc: 1.000 - ETA: 1s - loss: 1.8666e-04 - acc: 1.000 - ETA: 1s - loss: 2.0060e-04 - acc: 1.000 - ETA: 0s - loss: 1.9633e-04 - acc: 1.000 - ETA: 0s - loss: 1.9144e-04 - acc: 1.000 - ETA: 0s - loss: 1.8497e-04 - acc: 1.000 - ETA: 0s - loss: 2.0593e-04 - acc: 1.000 - ETA: 0s - loss: 2.0211e-04 - acc: 1.000 - ETA: 0s - loss: 1.9630e-04 - acc: 1.000 - ETA: 0s - loss: 2.0870e-04 - acc: 1.000 - ETA: 0s - loss: 2.1067e-04 - acc: 1.000 - 4s 136ms/step - loss: 2.0567e-04 - acc: 1.0000 - val_loss: 4.1131 - val_acc: 0.8125\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - ETA: 7s - loss: 3.2915e-05 - acc: 1.000 - ETA: 5s - loss: 2.0252e-05 - acc: 1.000 - ETA: 4s - loss: 2.3819e-05 - acc: 1.000 - ETA: 4s - loss: 2.3126e-05 - acc: 1.000 - ETA: 3s - loss: 3.1678e-05 - acc: 1.000 - ETA: 3s - loss: 2.8441e-05 - acc: 1.000 - ETA: 2s - loss: 3.1866e-05 - acc: 1.000 - ETA: 2s - loss: 3.0491e-05 - acc: 1.000 - ETA: 2s - loss: 3.0256e-05 - acc: 1.000 - ETA: 2s - loss: 2.8108e-05 - acc: 1.000 - ETA: 2s - loss: 2.7323e-05 - acc: 1.000 - ETA: 2s - loss: 2.6239e-05 - acc: 1.000 - ETA: 2s - loss: 2.5734e-05 - acc: 1.000 - ETA: 2s - loss: 2.5501e-05 - acc: 1.000 - ETA: 2s - loss: 2.6854e-05 - acc: 1.000 - ETA: 1s - loss: 2.9693e-05 - acc: 1.000 - ETA: 1s - loss: 2.9436e-05 - acc: 1.000 - ETA: 1s - loss: 3.0339e-05 - acc: 1.000 - ETA: 1s - loss: 3.1197e-05 - acc: 1.000 - ETA: 1s - loss: 3.0209e-05 - acc: 1.000 - ETA: 1s - loss: 2.9280e-05 - acc: 1.000 - ETA: 1s - loss: 2.8707e-05 - acc: 1.000 - ETA: 1s - loss: 2.7960e-05 - acc: 1.000 - ETA: 0s - loss: 3.1652e-05 - acc: 1.000 - ETA: 0s - loss: 3.1204e-05 - acc: 1.000 - ETA: 0s - loss: 3.1561e-05 - acc: 1.000 - ETA: 0s - loss: 3.0767e-05 - acc: 1.000 - ETA: 0s - loss: 3.4690e-05 - acc: 1.000 - ETA: 0s - loss: 9.2417e-05 - acc: 1.000 - ETA: 0s - loss: 0.0102 - acc: 0.9958    - ETA: 0s - loss: 0.0129 - acc: 0.995 - 4s 136ms/step - loss: 0.2631 - acc: 0.9766 - val_loss: 3.6266 - val_acc: 0.6406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_layer0: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_conv_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/bracket: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/epochs: 15</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/initial_epoch: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/round: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/trial_id: 17f7789a17f64f15bdc5d42833680156</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.89453125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               5017856   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,066,065\n",
      "Trainable params: 5,066,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - ETA: 20s - loss: 0.6974 - acc: 0.50 - ETA: 12s - loss: 0.9840 - acc: 0.57 - ETA: 8s - loss: 1.3425 - acc: 0.5833 - ETA: 7s - loss: 1.1786 - acc: 0.578 - ETA: 6s - loss: 1.0868 - acc: 0.568 - ETA: 5s - loss: 1.0198 - acc: 0.572 - ETA: 5s - loss: 0.9722 - acc: 0.584 - ETA: 4s - loss: 0.9339 - acc: 0.621 - ETA: 4s - loss: 0.8874 - acc: 0.649 - ETA: 3s - loss: 1.4730 - acc: 0.631 - ETA: 3s - loss: 1.3994 - acc: 0.622 - ETA: 3s - loss: 1.3327 - acc: 0.632 - ETA: 3s - loss: 1.2752 - acc: 0.632 - ETA: 2s - loss: 1.2196 - acc: 0.645 - ETA: 2s - loss: 1.1686 - acc: 0.650 - ETA: 2s - loss: 1.1216 - acc: 0.662 - ETA: 2s - loss: 1.0695 - acc: 0.678 - ETA: 2s - loss: 1.0442 - acc: 0.680 - ETA: 2s - loss: 1.0821 - acc: 0.671 - ETA: 1s - loss: 1.0517 - acc: 0.676 - ETA: 1s - loss: 1.0209 - acc: 0.684 - ETA: 1s - loss: 1.0302 - acc: 0.674 - ETA: 1s - loss: 1.0085 - acc: 0.675 - ETA: 1s - loss: 0.9806 - acc: 0.684 - ETA: 0s - loss: 0.9523 - acc: 0.694 - ETA: 0s - loss: 0.9211 - acc: 0.706 - ETA: 0s - loss: 0.8925 - acc: 0.715 - ETA: 0s - loss: 0.8638 - acc: 0.725 - ETA: 0s - loss: 0.8371 - acc: 0.734 - ETA: 0s - loss: 0.9241 - acc: 0.727 - ETA: 0s - loss: 0.9414 - acc: 0.714 - 5s 153ms/step - loss: 0.9281 - acc: 0.7137 - val_loss: 0.9462 - val_acc: 0.5469\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.3796 - acc: 0.843 - ETA: 4s - loss: 0.3960 - acc: 0.796 - ETA: 4s - loss: 0.4468 - acc: 0.770 - ETA: 4s - loss: 0.4219 - acc: 0.804 - ETA: 3s - loss: 0.3872 - acc: 0.834 - ETA: 3s - loss: 0.4088 - acc: 0.825 - ETA: 2s - loss: 0.3862 - acc: 0.837 - ETA: 2s - loss: 0.3611 - acc: 0.849 - ETA: 2s - loss: 0.3526 - acc: 0.852 - ETA: 2s - loss: 0.3410 - acc: 0.854 - ETA: 2s - loss: 0.3229 - acc: 0.862 - ETA: 2s - loss: 0.3018 - acc: 0.870 - ETA: 2s - loss: 0.2877 - acc: 0.878 - ETA: 2s - loss: 0.2795 - acc: 0.882 - ETA: 1s - loss: 0.2787 - acc: 0.884 - ETA: 1s - loss: 0.2798 - acc: 0.885 - ETA: 1s - loss: 0.2698 - acc: 0.892 - ETA: 1s - loss: 0.2569 - acc: 0.898 - ETA: 1s - loss: 0.2464 - acc: 0.903 - ETA: 1s - loss: 0.2388 - acc: 0.906 - ETA: 1s - loss: 0.2336 - acc: 0.909 - ETA: 1s - loss: 0.2272 - acc: 0.913 - ETA: 1s - loss: 0.2269 - acc: 0.914 - ETA: 0s - loss: 0.2226 - acc: 0.915 - ETA: 0s - loss: 0.2162 - acc: 0.917 - ETA: 0s - loss: 0.2094 - acc: 0.921 - ETA: 0s - loss: 0.2081 - acc: 0.920 - ETA: 0s - loss: 0.2047 - acc: 0.922 - ETA: 0s - loss: 0.2006 - acc: 0.922 - ETA: 0s - loss: 0.1953 - acc: 0.925 - ETA: 0s - loss: 0.1893 - acc: 0.927 - 5s 138ms/step - loss: 0.1869 - acc: 0.9289 - val_loss: 3.4256 - val_acc: 0.6445\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.0838 - acc: 0.968 - ETA: 4s - loss: 0.0869 - acc: 0.968 - ETA: 4s - loss: 0.0828 - acc: 0.958 - ETA: 3s - loss: 0.1110 - acc: 0.960 - ETA: 3s - loss: 0.1012 - acc: 0.962 - ETA: 3s - loss: 0.1017 - acc: 0.963 - ETA: 3s - loss: 0.0903 - acc: 0.968 - ETA: 3s - loss: 0.0798 - acc: 0.972 - ETA: 3s - loss: 0.0751 - acc: 0.975 - ETA: 2s - loss: 0.0881 - acc: 0.971 - ETA: 2s - loss: 0.0934 - acc: 0.971 - ETA: 2s - loss: 0.0887 - acc: 0.974 - ETA: 2s - loss: 0.0825 - acc: 0.976 - ETA: 2s - loss: 0.0776 - acc: 0.977 - ETA: 2s - loss: 0.0746 - acc: 0.979 - ETA: 2s - loss: 0.0721 - acc: 0.980 - ETA: 1s - loss: 0.0717 - acc: 0.977 - ETA: 1s - loss: 0.0819 - acc: 0.974 - ETA: 1s - loss: 0.0868 - acc: 0.970 - ETA: 1s - loss: 0.1007 - acc: 0.965 - ETA: 1s - loss: 0.1010 - acc: 0.967 - ETA: 1s - loss: 0.1026 - acc: 0.967 - ETA: 1s - loss: 0.1006 - acc: 0.968 - ETA: 1s - loss: 0.0969 - acc: 0.970 - ETA: 0s - loss: 0.0933 - acc: 0.971 - ETA: 0s - loss: 0.0899 - acc: 0.972 - ETA: 0s - loss: 0.0874 - acc: 0.973 - ETA: 0s - loss: 0.0846 - acc: 0.974 - ETA: 0s - loss: 0.0918 - acc: 0.971 - ETA: 0s - loss: 0.1082 - acc: 0.963 - ETA: 0s - loss: 0.1372 - acc: 0.955 - 5s 137ms/step - loss: 0.1433 - acc: 0.9494 - val_loss: 0.9958 - val_acc: 0.7461\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.2888 - acc: 0.937 - ETA: 4s - loss: 0.2101 - acc: 0.968 - ETA: 4s - loss: 0.1759 - acc: 0.968 - ETA: 4s - loss: 0.1531 - acc: 0.976 - ETA: 3s - loss: 0.1269 - acc: 0.981 - ETA: 3s - loss: 0.1115 - acc: 0.984 - ETA: 3s - loss: 0.0965 - acc: 0.986 - ETA: 3s - loss: 0.0958 - acc: 0.984 - ETA: 3s - loss: 0.1195 - acc: 0.968 - ETA: 2s - loss: 0.1160 - acc: 0.968 - ETA: 2s - loss: 0.1105 - acc: 0.968 - ETA: 2s - loss: 0.1071 - acc: 0.968 - ETA: 2s - loss: 0.0991 - acc: 0.971 - ETA: 2s - loss: 0.0922 - acc: 0.973 - ETA: 2s - loss: 0.0863 - acc: 0.975 - ETA: 2s - loss: 0.0813 - acc: 0.976 - ETA: 1s - loss: 0.0900 - acc: 0.976 - ETA: 1s - loss: 0.0854 - acc: 0.977 - ETA: 1s - loss: 0.0809 - acc: 0.978 - ETA: 1s - loss: 0.0750 - acc: 0.978 - ETA: 1s - loss: 0.0716 - acc: 0.979 - ETA: 1s - loss: 0.0686 - acc: 0.980 - ETA: 1s - loss: 0.0658 - acc: 0.981 - ETA: 0s - loss: 0.0640 - acc: 0.981 - ETA: 0s - loss: 0.0618 - acc: 0.982 - ETA: 0s - loss: 0.0597 - acc: 0.983 - ETA: 0s - loss: 0.0576 - acc: 0.983 - ETA: 0s - loss: 0.0557 - acc: 0.984 - ETA: 0s - loss: 0.0538 - acc: 0.985 - ETA: 0s - loss: 0.0521 - acc: 0.985 - ETA: 0s - loss: 0.0505 - acc: 0.985 - 5s 138ms/step - loss: 0.0490 - acc: 0.9864 - val_loss: 3.4851 - val_acc: 0.7656\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 6s - loss: 2.3381e-04 - acc: 1.000 - ETA: 4s - loss: 2.4754e-04 - acc: 1.000 - ETA: 4s - loss: 5.3481e-04 - acc: 1.000 - ETA: 3s - loss: 4.3919e-04 - acc: 1.000 - ETA: 3s - loss: 3.7061e-04 - acc: 1.000 - ETA: 2s - loss: 3.3011e-04 - acc: 1.000 - ETA: 2s - loss: 4.0057e-04 - acc: 1.000 - ETA: 2s - loss: 3.6902e-04 - acc: 1.000 - ETA: 2s - loss: 3.8919e-04 - acc: 1.000 - ETA: 2s - loss: 3.9289e-04 - acc: 1.000 - ETA: 2s - loss: 3.9594e-04 - acc: 1.000 - ETA: 2s - loss: 6.4979e-04 - acc: 1.000 - ETA: 2s - loss: 0.0038 - acc: 0.9976    - ETA: 2s - loss: 0.0373 - acc: 0.986 - ETA: 1s - loss: 0.0390 - acc: 0.987 - ETA: 1s - loss: 0.0788 - acc: 0.980 - ETA: 1s - loss: 0.0937 - acc: 0.972 - ETA: 1s - loss: 0.1226 - acc: 0.963 - ETA: 1s - loss: 0.1202 - acc: 0.965 - ETA: 1s - loss: 0.1167 - acc: 0.965 - ETA: 1s - loss: 0.1126 - acc: 0.967 - ETA: 1s - loss: 0.1161 - acc: 0.967 - ETA: 1s - loss: 0.7351 - acc: 0.949 - ETA: 0s - loss: 0.7120 - acc: 0.948 - ETA: 0s - loss: 0.6891 - acc: 0.948 - ETA: 0s - loss: 0.6720 - acc: 0.948 - ETA: 0s - loss: 0.6570 - acc: 0.948 - ETA: 0s - loss: 0.6376 - acc: 0.948 - ETA: 0s - loss: 0.6165 - acc: 0.950 - ETA: 0s - loss: 0.5977 - acc: 0.951 - ETA: 0s - loss: 0.5795 - acc: 0.952 - 4s 134ms/step - loss: 0.5624 - acc: 0.9542 - val_loss: 4.5689 - val_acc: 0.7539\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.765625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 416)               8154016   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 417       \n",
      "=================================================================\n",
      "Total params: 8,159,521\n",
      "Trainable params: 8,159,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - ETA: 19s - loss: 0.6852 - acc: 0.65 - ETA: 11s - loss: 3.6489 - acc: 0.56 - ETA: 8s - loss: 2.9908 - acc: 0.5521 - ETA: 6s - loss: 2.4099 - acc: 0.562 - ETA: 6s - loss: 2.0444 - acc: 0.587 - ETA: 5s - loss: 1.7955 - acc: 0.614 - ETA: 4s - loss: 1.6302 - acc: 0.607 - ETA: 4s - loss: 1.5048 - acc: 0.605 - ETA: 4s - loss: 1.3972 - acc: 0.628 - ETA: 3s - loss: 1.2995 - acc: 0.659 - ETA: 3s - loss: 1.2106 - acc: 0.684 - ETA: 3s - loss: 1.1812 - acc: 0.677 - ETA: 3s - loss: 1.1263 - acc: 0.687 - ETA: 2s - loss: 1.0858 - acc: 0.689 - ETA: 2s - loss: 1.0635 - acc: 0.683 - ETA: 2s - loss: 1.0169 - acc: 0.695 - ETA: 2s - loss: 0.9791 - acc: 0.707 - ETA: 2s - loss: 0.9403 - acc: 0.722 - ETA: 2s - loss: 0.9039 - acc: 0.735 - ETA: 1s - loss: 0.8732 - acc: 0.745 - ETA: 1s - loss: 0.8516 - acc: 0.747 - ETA: 1s - loss: 0.8203 - acc: 0.755 - ETA: 1s - loss: 0.7931 - acc: 0.763 - ETA: 1s - loss: 0.7684 - acc: 0.770 - ETA: 1s - loss: 0.7632 - acc: 0.772 - ETA: 0s - loss: 0.7465 - acc: 0.776 - ETA: 0s - loss: 0.7288 - acc: 0.782 - ETA: 0s - loss: 0.7108 - acc: 0.785 - ETA: 0s - loss: 0.6916 - acc: 0.792 - ETA: 0s - loss: 0.6736 - acc: 0.797 - ETA: 0s - loss: 0.6565 - acc: 0.803 - ETA: 0s - loss: 0.6431 - acc: 0.806 - 5s 153ms/step - loss: 0.6242 - acc: 0.8072 - val_loss: 0.6373 - val_acc: 0.8594\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.1108 - acc: 0.968 - ETA: 4s - loss: 0.0982 - acc: 0.968 - ETA: 3s - loss: 0.1067 - acc: 0.968 - ETA: 3s - loss: 0.1604 - acc: 0.921 - ETA: 3s - loss: 0.1746 - acc: 0.906 - ETA: 3s - loss: 0.2585 - acc: 0.869 - ETA: 3s - loss: 0.3276 - acc: 0.839 - ETA: 3s - loss: 0.3073 - acc: 0.851 - ETA: 2s - loss: 0.2898 - acc: 0.861 - ETA: 2s - loss: 0.2733 - acc: 0.871 - ETA: 2s - loss: 0.2699 - acc: 0.869 - ETA: 2s - loss: 0.2675 - acc: 0.869 - ETA: 2s - loss: 0.2359 - acc: 0.878 - ETA: 2s - loss: 0.2291 - acc: 0.882 - ETA: 1s - loss: 0.2167 - acc: 0.890 - ETA: 1s - loss: 0.2129 - acc: 0.893 - ETA: 1s - loss: 0.2063 - acc: 0.897 - ETA: 1s - loss: 0.2039 - acc: 0.899 - ETA: 1s - loss: 0.1987 - acc: 0.901 - ETA: 1s - loss: 0.1913 - acc: 0.906 - ETA: 1s - loss: 0.1845 - acc: 0.911 - ETA: 1s - loss: 0.1773 - acc: 0.915 - ETA: 1s - loss: 0.1708 - acc: 0.918 - ETA: 0s - loss: 0.1650 - acc: 0.922 - ETA: 0s - loss: 0.1604 - acc: 0.924 - ETA: 0s - loss: 0.1555 - acc: 0.926 - ETA: 0s - loss: 0.1540 - acc: 0.927 - ETA: 0s - loss: 0.1631 - acc: 0.924 - ETA: 0s - loss: 0.1623 - acc: 0.924 - ETA: 0s - loss: 0.1586 - acc: 0.927 - ETA: 0s - loss: 0.1571 - acc: 0.928 - 4s 133ms/step - loss: 0.1540 - acc: 0.9309 - val_loss: 0.8422 - val_acc: 0.8555\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0821 - acc: 0.968 - ETA: 4s - loss: 0.0843 - acc: 0.968 - ETA: 3s - loss: 0.0679 - acc: 0.979 - ETA: 3s - loss: 0.0575 - acc: 0.984 - ETA: 3s - loss: 0.0522 - acc: 0.981 - ETA: 3s - loss: 0.0468 - acc: 0.984 - ETA: 3s - loss: 0.0495 - acc: 0.982 - ETA: 3s - loss: 0.0475 - acc: 0.984 - ETA: 2s - loss: 0.0442 - acc: 0.986 - ETA: 2s - loss: 0.0410 - acc: 0.987 - ETA: 2s - loss: 0.0464 - acc: 0.983 - ETA: 2s - loss: 0.0462 - acc: 0.984 - ETA: 2s - loss: 0.0432 - acc: 0.985 - ETA: 2s - loss: 0.0403 - acc: 0.986 - ETA: 1s - loss: 0.0356 - acc: 0.987 - ETA: 1s - loss: 0.0344 - acc: 0.988 - ETA: 1s - loss: 0.0330 - acc: 0.989 - ETA: 1s - loss: 0.0433 - acc: 0.986 - ETA: 1s - loss: 0.0903 - acc: 0.967 - ETA: 1s - loss: 0.0965 - acc: 0.965 - ETA: 1s - loss: 0.1184 - acc: 0.955 - ETA: 1s - loss: 0.1670 - acc: 0.946 - ETA: 1s - loss: 0.1620 - acc: 0.947 - ETA: 0s - loss: 0.1557 - acc: 0.949 - ETA: 0s - loss: 0.1502 - acc: 0.951 - ETA: 0s - loss: 0.1491 - acc: 0.952 - ETA: 0s - loss: 0.1453 - acc: 0.953 - ETA: 0s - loss: 0.1405 - acc: 0.955 - ETA: 0s - loss: 0.1364 - acc: 0.957 - ETA: 0s - loss: 0.1322 - acc: 0.958 - ETA: 0s - loss: 0.1285 - acc: 0.959 - 4s 132ms/step - loss: 0.1260 - acc: 0.9601 - val_loss: 1.6143 - val_acc: 0.8086\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0051 - acc: 1.000 - ETA: 4s - loss: 0.0051 - acc: 1.000 - ETA: 4s - loss: 0.0100 - acc: 1.000 - ETA: 3s - loss: 0.0084 - acc: 1.000 - ETA: 3s - loss: 0.0081 - acc: 1.000 - ETA: 3s - loss: 0.0076 - acc: 1.000 - ETA: 3s - loss: 0.0109 - acc: 0.995 - ETA: 2s - loss: 0.0100 - acc: 0.996 - ETA: 2s - loss: 0.0097 - acc: 0.996 - ETA: 2s - loss: 0.0107 - acc: 0.996 - ETA: 2s - loss: 0.0110 - acc: 0.997 - ETA: 2s - loss: 0.0142 - acc: 0.994 - ETA: 2s - loss: 0.0156 - acc: 0.995 - ETA: 2s - loss: 0.0190 - acc: 0.993 - ETA: 1s - loss: 0.0216 - acc: 0.991 - ETA: 1s - loss: 0.0209 - acc: 0.992 - ETA: 1s - loss: 0.0199 - acc: 0.992 - ETA: 1s - loss: 0.0197 - acc: 0.993 - ETA: 1s - loss: 0.0207 - acc: 0.991 - ETA: 1s - loss: 0.0200 - acc: 0.992 - ETA: 1s - loss: 0.0192 - acc: 0.992 - ETA: 1s - loss: 0.0193 - acc: 0.992 - ETA: 1s - loss: 0.0187 - acc: 0.993 - ETA: 0s - loss: 0.0181 - acc: 0.993 - ETA: 0s - loss: 0.0176 - acc: 0.993 - ETA: 0s - loss: 0.0172 - acc: 0.994 - ETA: 0s - loss: 0.0168 - acc: 0.994 - ETA: 0s - loss: 0.0164 - acc: 0.994 - ETA: 0s - loss: 0.0158 - acc: 0.994 - ETA: 0s - loss: 0.0156 - acc: 0.994 - ETA: 0s - loss: 0.0152 - acc: 0.995 - 4s 133ms/step - loss: 0.0148 - acc: 0.9951 - val_loss: 1.7616 - val_acc: 0.8398\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0018 - acc: 1.000 - ETA: 4s - loss: 0.0051 - acc: 1.000 - ETA: 3s - loss: 0.0041 - acc: 1.000 - ETA: 3s - loss: 0.0036 - acc: 1.000 - ETA: 3s - loss: 0.0031 - acc: 1.000 - ETA: 3s - loss: 0.0035 - acc: 1.000 - ETA: 3s - loss: 0.0037 - acc: 1.000 - ETA: 3s - loss: 0.0040 - acc: 1.000 - ETA: 2s - loss: 0.0037 - acc: 1.000 - ETA: 2s - loss: 0.0036 - acc: 1.000 - ETA: 2s - loss: 0.0040 - acc: 1.000 - ETA: 2s - loss: 0.0038 - acc: 1.000 - ETA: 2s - loss: 0.0035 - acc: 1.000 - ETA: 2s - loss: 0.0033 - acc: 1.000 - ETA: 2s - loss: 0.0031 - acc: 1.000 - ETA: 2s - loss: 0.0031 - acc: 1.000 - ETA: 1s - loss: 0.0030 - acc: 1.000 - ETA: 1s - loss: 0.0028 - acc: 1.000 - ETA: 1s - loss: 0.0027 - acc: 1.000 - ETA: 1s - loss: 0.0026 - acc: 1.000 - ETA: 1s - loss: 0.0026 - acc: 1.000 - ETA: 1s - loss: 0.0253 - acc: 0.995 - ETA: 1s - loss: 0.0343 - acc: 0.991 - ETA: 0s - loss: 0.7189 - acc: 0.975 - ETA: 0s - loss: 0.6937 - acc: 0.975 - ETA: 0s - loss: 0.6723 - acc: 0.974 - ETA: 0s - loss: 0.6527 - acc: 0.973 - ETA: 0s - loss: 0.6317 - acc: 0.974 - ETA: 0s - loss: 0.6111 - acc: 0.975 - ETA: 0s - loss: 0.5916 - acc: 0.976 - ETA: 0s - loss: 0.5751 - acc: 0.975 - 4s 132ms/step - loss: 0.5600 - acc: 0.9757 - val_loss: 1.1118 - val_acc: 0.8281\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.859375</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 192)               16370880  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 193       \n",
      "=================================================================\n",
      "Total params: 16,373,841\n",
      "Trainable params: 16,373,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - ETA: 18s - loss: 0.6911 - acc: 0.56 - ETA: 10s - loss: 7.6448 - acc: 0.60 - ETA: 8s - loss: 13.8625 - acc: 0.60 - ETA: 6s - loss: 12.1616 - acc: 0.58 - ETA: 5s - loss: 9.8663 - acc: 0.5938 - ETA: 5s - loss: 8.6862 - acc: 0.578 - ETA: 4s - loss: 7.8403 - acc: 0.562 - ETA: 4s - loss: 7.0387 - acc: 0.566 - ETA: 4s - loss: 6.2982 - acc: 0.590 - ETA: 3s - loss: 5.7140 - acc: 0.618 - ETA: 3s - loss: 5.2305 - acc: 0.630 - ETA: 3s - loss: 4.8340 - acc: 0.640 - ETA: 3s - loss: 4.5165 - acc: 0.639 - ETA: 2s - loss: 4.0060 - acc: 0.638 - ETA: 2s - loss: 3.8158 - acc: 0.627 - ETA: 2s - loss: 3.6848 - acc: 0.611 - ETA: 2s - loss: 3.5667 - acc: 0.596 - ETA: 1s - loss: 3.4031 - acc: 0.607 - ETA: 1s - loss: 3.2556 - acc: 0.613 - ETA: 1s - loss: 3.1156 - acc: 0.629 - ETA: 1s - loss: 2.9862 - acc: 0.644 - ETA: 1s - loss: 2.8672 - acc: 0.656 - ETA: 1s - loss: 2.7591 - acc: 0.667 - ETA: 1s - loss: 2.6556 - acc: 0.679 - ETA: 0s - loss: 2.5609 - acc: 0.689 - ETA: 0s - loss: 2.4740 - acc: 0.699 - ETA: 0s - loss: 2.3924 - acc: 0.709 - ETA: 0s - loss: 2.3183 - acc: 0.717 - ETA: 0s - loss: 2.2484 - acc: 0.725 - ETA: 0s - loss: 2.1844 - acc: 0.729 - ETA: 0s - loss: 2.1219 - acc: 0.735 - 5s 154ms/step - loss: 2.0627 - acc: 0.7429 - val_loss: 0.5877 - val_acc: 0.7852\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0817 - acc: 0.968 - ETA: 4s - loss: 0.0827 - acc: 0.968 - ETA: 4s - loss: 0.0878 - acc: 0.968 - ETA: 3s - loss: 0.0932 - acc: 0.968 - ETA: 3s - loss: 0.0879 - acc: 0.968 - ETA: 2s - loss: 0.0932 - acc: 0.964 - ETA: 2s - loss: 0.1151 - acc: 0.947 - ETA: 2s - loss: 0.1263 - acc: 0.945 - ETA: 2s - loss: 0.1395 - acc: 0.945 - ETA: 2s - loss: 0.1316 - acc: 0.950 - ETA: 2s - loss: 0.1279 - acc: 0.952 - ETA: 2s - loss: 0.1297 - acc: 0.950 - ETA: 2s - loss: 0.1228 - acc: 0.954 - ETA: 2s - loss: 0.1176 - acc: 0.957 - ETA: 1s - loss: 0.1123 - acc: 0.960 - ETA: 1s - loss: 0.1084 - acc: 0.963 - ETA: 1s - loss: 0.1108 - acc: 0.963 - ETA: 1s - loss: 0.1102 - acc: 0.963 - ETA: 1s - loss: 0.1057 - acc: 0.965 - ETA: 1s - loss: 0.1019 - acc: 0.967 - ETA: 1s - loss: 0.0999 - acc: 0.968 - ETA: 1s - loss: 0.0974 - acc: 0.970 - ETA: 1s - loss: 0.0949 - acc: 0.971 - ETA: 0s - loss: 0.0950 - acc: 0.971 - ETA: 0s - loss: 0.0964 - acc: 0.970 - ETA: 0s - loss: 0.0967 - acc: 0.970 - ETA: 0s - loss: 0.0947 - acc: 0.971 - ETA: 0s - loss: 0.0928 - acc: 0.972 - ETA: 0s - loss: 0.0919 - acc: 0.972 - ETA: 0s - loss: 0.1496 - acc: 0.956 - ETA: 0s - loss: 0.2082 - acc: 0.944 - 4s 133ms/step - loss: 0.2043 - acc: 0.9464 - val_loss: 0.8341 - val_acc: 0.7539\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0390 - acc: 1.000 - ETA: 4s - loss: 0.1896 - acc: 0.953 - ETA: 3s - loss: 0.1879 - acc: 0.927 - ETA: 3s - loss: 0.1490 - acc: 0.945 - ETA: 3s - loss: 0.1297 - acc: 0.956 - ETA: 3s - loss: 0.1284 - acc: 0.953 - ETA: 3s - loss: 0.1145 - acc: 0.959 - ETA: 3s - loss: 0.1085 - acc: 0.960 - ETA: 2s - loss: 0.1026 - acc: 0.961 - ETA: 2s - loss: 0.0933 - acc: 0.965 - ETA: 2s - loss: 0.0860 - acc: 0.968 - ETA: 2s - loss: 0.0812 - acc: 0.971 - ETA: 2s - loss: 0.0763 - acc: 0.973 - ETA: 2s - loss: 0.0713 - acc: 0.975 - ETA: 1s - loss: 0.0628 - acc: 0.977 - ETA: 1s - loss: 0.0601 - acc: 0.978 - ETA: 1s - loss: 0.0608 - acc: 0.976 - ETA: 1s - loss: 0.0646 - acc: 0.974 - ETA: 1s - loss: 0.0679 - acc: 0.972 - ETA: 1s - loss: 0.0682 - acc: 0.973 - ETA: 1s - loss: 0.0691 - acc: 0.973 - ETA: 1s - loss: 0.0664 - acc: 0.974 - ETA: 1s - loss: 0.0677 - acc: 0.972 - ETA: 0s - loss: 0.0669 - acc: 0.974 - ETA: 0s - loss: 0.0649 - acc: 0.975 - ETA: 0s - loss: 0.0631 - acc: 0.976 - ETA: 0s - loss: 0.0612 - acc: 0.976 - ETA: 0s - loss: 0.0594 - acc: 0.977 - ETA: 0s - loss: 0.0576 - acc: 0.978 - ETA: 0s - loss: 0.0568 - acc: 0.978 - ETA: 0s - loss: 0.0587 - acc: 0.977 - 4s 132ms/step - loss: 0.0595 - acc: 0.9776 - val_loss: 1.4285 - val_acc: 0.7539\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0183 - acc: 1.000 - ETA: 4s - loss: 0.0197 - acc: 1.000 - ETA: 3s - loss: 0.0171 - acc: 1.000 - ETA: 3s - loss: 0.0142 - acc: 1.000 - ETA: 3s - loss: 0.0123 - acc: 1.000 - ETA: 3s - loss: 0.0109 - acc: 1.000 - ETA: 3s - loss: 0.0122 - acc: 1.000 - ETA: 3s - loss: 0.0122 - acc: 1.000 - ETA: 2s - loss: 0.0117 - acc: 1.000 - ETA: 2s - loss: 0.0107 - acc: 1.000 - ETA: 2s - loss: 0.0098 - acc: 1.000 - ETA: 2s - loss: 0.0097 - acc: 1.000 - ETA: 2s - loss: 0.0097 - acc: 1.000 - ETA: 2s - loss: 0.0103 - acc: 1.000 - ETA: 2s - loss: 0.0535 - acc: 0.981 - ETA: 1s - loss: 0.3040 - acc: 0.961 - ETA: 1s - loss: 0.2903 - acc: 0.963 - ETA: 1s - loss: 0.2770 - acc: 0.965 - ETA: 1s - loss: 0.2640 - acc: 0.967 - ETA: 1s - loss: 0.2528 - acc: 0.968 - ETA: 1s - loss: 0.2432 - acc: 0.970 - ETA: 1s - loss: 0.2334 - acc: 0.971 - ETA: 1s - loss: 0.2249 - acc: 0.972 - ETA: 0s - loss: 0.2161 - acc: 0.974 - ETA: 0s - loss: 0.2082 - acc: 0.975 - ETA: 0s - loss: 0.2008 - acc: 0.976 - ETA: 0s - loss: 0.1939 - acc: 0.976 - ETA: 0s - loss: 0.1876 - acc: 0.977 - ETA: 0s - loss: 0.1815 - acc: 0.978 - ETA: 0s - loss: 0.1760 - acc: 0.979 - ETA: 0s - loss: 0.1710 - acc: 0.979 - 5s 141ms/step - loss: 0.1631 - acc: 0.9805 - val_loss: 1.4144 - val_acc: 0.7969\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0113 - acc: 1.000 - ETA: 4s - loss: 0.0081 - acc: 1.000 - ETA: 3s - loss: 0.0098 - acc: 1.000 - ETA: 3s - loss: 0.0080 - acc: 1.000 - ETA: 3s - loss: 0.0072 - acc: 1.000 - ETA: 3s - loss: 0.0066 - acc: 1.000 - ETA: 3s - loss: 0.0063 - acc: 1.000 - ETA: 3s - loss: 0.0058 - acc: 1.000 - ETA: 2s - loss: 0.0054 - acc: 1.000 - ETA: 2s - loss: 0.0064 - acc: 1.000 - ETA: 2s - loss: 0.0066 - acc: 1.000 - ETA: 2s - loss: 0.0064 - acc: 1.000 - ETA: 2s - loss: 0.0062 - acc: 1.000 - ETA: 2s - loss: 0.0059 - acc: 1.000 - ETA: 2s - loss: 0.0058 - acc: 1.000 - ETA: 2s - loss: 0.0059 - acc: 1.000 - ETA: 1s - loss: 0.0060 - acc: 1.000 - ETA: 1s - loss: 0.0057 - acc: 1.000 - ETA: 1s - loss: 0.0055 - acc: 1.000 - ETA: 1s - loss: 0.0053 - acc: 1.000 - ETA: 1s - loss: 0.0052 - acc: 1.000 - ETA: 1s - loss: 0.0052 - acc: 1.000 - ETA: 1s - loss: 0.0051 - acc: 1.000 - ETA: 1s - loss: 0.0050 - acc: 1.000 - ETA: 0s - loss: 0.0049 - acc: 1.000 - ETA: 0s - loss: 0.0045 - acc: 1.000 - ETA: 0s - loss: 0.0045 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.000 - 4s 134ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.0813 - val_acc: 0.7852\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.796875</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 416)               32614816  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 417       \n",
      "=================================================================\n",
      "Total params: 32,627,281\n",
      "Trainable params: 32,627,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - ETA: 15s - loss: 0.6306 - acc: 1.00 - ETA: 9s - loss: 40.6429 - acc: 0.54 - ETA: 7s - loss: 28.4690 - acc: 0.47 - ETA: 6s - loss: 25.2254 - acc: 0.49 - ETA: 5s - loss: 20.4120 - acc: 0.45 - ETA: 5s - loss: 17.4701 - acc: 0.47 - ETA: 4s - loss: 15.1278 - acc: 0.47 - ETA: 4s - loss: 13.3260 - acc: 0.47 - ETA: 3s - loss: 11.9214 - acc: 0.48 - ETA: 3s - loss: 10.8073 - acc: 0.48 - ETA: 3s - loss: 9.8941 - acc: 0.4861 - ETA: 3s - loss: 9.1407 - acc: 0.470 - ETA: 3s - loss: 8.4783 - acc: 0.483 - ETA: 2s - loss: 7.9032 - acc: 0.517 - ETA: 2s - loss: 7.4046 - acc: 0.543 - ETA: 2s - loss: 7.0005 - acc: 0.546 - ETA: 2s - loss: 6.6259 - acc: 0.547 - ETA: 2s - loss: 6.2777 - acc: 0.563 - ETA: 1s - loss: 5.9643 - acc: 0.583 - ETA: 1s - loss: 5.6845 - acc: 0.595 - ETA: 1s - loss: 5.4246 - acc: 0.609 - ETA: 1s - loss: 5.1834 - acc: 0.628 - ETA: 1s - loss: 4.9709 - acc: 0.640 - ETA: 1s - loss: 4.7988 - acc: 0.637 - ETA: 1s - loss: 4.6255 - acc: 0.640 - ETA: 0s - loss: 4.4606 - acc: 0.648 - ETA: 0s - loss: 4.3083 - acc: 0.657 - ETA: 0s - loss: 4.1654 - acc: 0.664 - ETA: 0s - loss: 4.0268 - acc: 0.675 - ETA: 0s - loss: 3.8990 - acc: 0.683 - ETA: 0s - loss: 3.7774 - acc: 0.691 - ETA: 0s - loss: 3.6634 - acc: 0.700 - 5s 164ms/step - loss: 3.5569 - acc: 0.7089 - val_loss: 1.1422 - val_acc: 0.7461\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0890 - acc: 0.968 - ETA: 4s - loss: 0.0859 - acc: 0.968 - ETA: 4s - loss: 0.4305 - acc: 0.843 - ETA: 3s - loss: 0.6968 - acc: 0.757 - ETA: 3s - loss: 0.6321 - acc: 0.781 - ETA: 3s - loss: 0.5873 - acc: 0.791 - ETA: 3s - loss: 0.5681 - acc: 0.785 - ETA: 3s - loss: 0.5259 - acc: 0.804 - ETA: 2s - loss: 0.5137 - acc: 0.769 - ETA: 2s - loss: 0.5436 - acc: 0.752 - ETA: 2s - loss: 0.5250 - acc: 0.760 - ETA: 2s - loss: 0.5012 - acc: 0.775 - ETA: 2s - loss: 0.4773 - acc: 0.790 - ETA: 2s - loss: 0.4497 - acc: 0.804 - ETA: 1s - loss: 0.4318 - acc: 0.815 - ETA: 1s - loss: 0.4177 - acc: 0.823 - ETA: 1s - loss: 0.4083 - acc: 0.826 - ETA: 1s - loss: 0.3957 - acc: 0.834 - ETA: 1s - loss: 0.3837 - acc: 0.841 - ETA: 1s - loss: 0.3699 - acc: 0.849 - ETA: 1s - loss: 0.3568 - acc: 0.856 - ETA: 1s - loss: 0.3449 - acc: 0.861 - ETA: 1s - loss: 0.3334 - acc: 0.867 - ETA: 0s - loss: 0.3297 - acc: 0.869 - ETA: 0s - loss: 0.3202 - acc: 0.873 - ETA: 0s - loss: 0.3108 - acc: 0.877 - ETA: 0s - loss: 0.3035 - acc: 0.881 - ETA: 0s - loss: 0.2974 - acc: 0.883 - ETA: 0s - loss: 0.2892 - acc: 0.887 - ETA: 0s - loss: 0.2810 - acc: 0.891 - ETA: 0s - loss: 0.2751 - acc: 0.893 - 5s 151ms/step - loss: 0.2701 - acc: 0.8948 - val_loss: 1.2618 - val_acc: 0.7656\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0876 - acc: 1.000 - ETA: 4s - loss: 0.0611 - acc: 1.000 - ETA: 4s - loss: 0.0482 - acc: 1.000 - ETA: 3s - loss: 0.0825 - acc: 0.976 - ETA: 3s - loss: 0.1109 - acc: 0.962 - ETA: 3s - loss: 0.1356 - acc: 0.953 - ETA: 3s - loss: 0.1245 - acc: 0.959 - ETA: 3s - loss: 0.1372 - acc: 0.957 - ETA: 3s - loss: 0.1453 - acc: 0.951 - ETA: 2s - loss: 0.1345 - acc: 0.956 - ETA: 2s - loss: 0.1259 - acc: 0.957 - ETA: 2s - loss: 0.1172 - acc: 0.960 - ETA: 2s - loss: 0.1120 - acc: 0.963 - ETA: 2s - loss: 0.1057 - acc: 0.966 - ETA: 1s - loss: 0.1018 - acc: 0.964 - ETA: 1s - loss: 0.1075 - acc: 0.963 - ETA: 1s - loss: 0.1035 - acc: 0.965 - ETA: 1s - loss: 0.0998 - acc: 0.967 - ETA: 1s - loss: 0.0955 - acc: 0.968 - ETA: 1s - loss: 0.0929 - acc: 0.968 - ETA: 1s - loss: 0.0890 - acc: 0.970 - ETA: 1s - loss: 0.0868 - acc: 0.970 - ETA: 1s - loss: 0.0871 - acc: 0.970 - ETA: 0s - loss: 0.0845 - acc: 0.971 - ETA: 0s - loss: 0.0823 - acc: 0.972 - ETA: 0s - loss: 0.0792 - acc: 0.973 - ETA: 0s - loss: 0.0824 - acc: 0.972 - ETA: 0s - loss: 0.1799 - acc: 0.956 - ETA: 0s - loss: 0.2497 - acc: 0.944 - ETA: 0s - loss: 0.2525 - acc: 0.941 - ETA: 0s - loss: 0.2513 - acc: 0.939 - 5s 149ms/step - loss: 0.2452 - acc: 0.9416 - val_loss: 0.8931 - val_acc: 0.8281\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0409 - acc: 1.000 - ETA: 4s - loss: 0.0503 - acc: 0.984 - ETA: 4s - loss: 0.0420 - acc: 0.989 - ETA: 3s - loss: 0.0343 - acc: 0.992 - ETA: 3s - loss: 0.0305 - acc: 0.993 - ETA: 3s - loss: 0.0273 - acc: 0.994 - ETA: 3s - loss: 0.0254 - acc: 0.995 - ETA: 3s - loss: 0.0342 - acc: 0.988 - ETA: 3s - loss: 0.0477 - acc: 0.982 - ETA: 2s - loss: 0.0468 - acc: 0.984 - ETA: 2s - loss: 0.0449 - acc: 0.985 - ETA: 2s - loss: 0.0432 - acc: 0.987 - ETA: 2s - loss: 0.0415 - acc: 0.988 - ETA: 2s - loss: 0.0389 - acc: 0.988 - ETA: 2s - loss: 0.0368 - acc: 0.989 - ETA: 2s - loss: 0.0360 - acc: 0.990 - ETA: 1s - loss: 0.0368 - acc: 0.989 - ETA: 1s - loss: 0.0350 - acc: 0.989 - ETA: 1s - loss: 0.0337 - acc: 0.990 - ETA: 1s - loss: 0.0327 - acc: 0.990 - ETA: 1s - loss: 0.0313 - acc: 0.991 - ETA: 1s - loss: 0.0299 - acc: 0.991 - ETA: 1s - loss: 0.0288 - acc: 0.991 - ETA: 1s - loss: 0.0282 - acc: 0.992 - ETA: 0s - loss: 0.0275 - acc: 0.992 - ETA: 0s - loss: 0.0265 - acc: 0.992 - ETA: 0s - loss: 0.0266 - acc: 0.993 - ETA: 0s - loss: 0.0262 - acc: 0.993 - ETA: 0s - loss: 0.0255 - acc: 0.993 - ETA: 0s - loss: 0.0249 - acc: 0.993 - ETA: 0s - loss: 0.0244 - acc: 0.994 - 4s 135ms/step - loss: 0.0237 - acc: 0.9942 - val_loss: 2.1331 - val_acc: 0.7891\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 9.2604e-04 - acc: 1.000 - ETA: 4s - loss: 6.7099e-04 - acc: 1.000 - ETA: 4s - loss: 8.4376e-04 - acc: 1.000 - ETA: 3s - loss: 0.0027 - acc: 1.0000    - ETA: 3s - loss: 0.0043 - acc: 1.000 - ETA: 3s - loss: 0.0461 - acc: 0.974 - ETA: 3s - loss: 0.4892 - acc: 0.915 - ETA: 3s - loss: 0.4532 - acc: 0.925 - ETA: 3s - loss: 0.4611 - acc: 0.906 - ETA: 2s - loss: 0.4285 - acc: 0.909 - ETA: 2s - loss: 0.3955 - acc: 0.914 - ETA: 2s - loss: 0.3725 - acc: 0.916 - ETA: 2s - loss: 0.3566 - acc: 0.915 - ETA: 2s - loss: 0.3383 - acc: 0.917 - ETA: 2s - loss: 0.3193 - acc: 0.920 - ETA: 2s - loss: 0.2999 - acc: 0.925 - ETA: 1s - loss: 0.2851 - acc: 0.928 - ETA: 1s - loss: 0.2723 - acc: 0.930 - ETA: 1s - loss: 0.2678 - acc: 0.929 - ETA: 1s - loss: 0.2548 - acc: 0.932 - ETA: 1s - loss: 0.2448 - acc: 0.934 - ETA: 1s - loss: 0.2340 - acc: 0.937 - ETA: 1s - loss: 0.2243 - acc: 0.940 - ETA: 1s - loss: 0.2152 - acc: 0.942 - ETA: 0s - loss: 0.2067 - acc: 0.945 - ETA: 0s - loss: 0.1988 - acc: 0.947 - ETA: 0s - loss: 0.1917 - acc: 0.949 - ETA: 0s - loss: 0.1785 - acc: 0.951 - ETA: 0s - loss: 0.1729 - acc: 0.952 - ETA: 0s - loss: 0.1676 - acc: 0.954 - ETA: 0s - loss: 0.1629 - acc: 0.955 - 4s 134ms/step - loss: 0.1581 - acc: 0.9572 - val_loss: 1.7506 - val_acc: 0.8047\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.828125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 192)               16370880  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 193       \n",
      "=================================================================\n",
      "Total params: 16,373,841\n",
      "Trainable params: 16,373,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - ETA: 17s - loss: 0.7180 - acc: 0.31 - ETA: 10s - loss: 51.7722 - acc: 0.328 - ETA: 7s - loss: 36.9701 - acc: 0.395 - ETA: 6s - loss: 31.0119 - acc: 0.35 - ETA: 5s - loss: 25.9758 - acc: 0.39 - ETA: 5s - loss: 22.2687 - acc: 0.41 - ETA: 4s - loss: 19.4397 - acc: 0.42 - ETA: 4s - loss: 17.2405 - acc: 0.41 - ETA: 4s - loss: 15.3802 - acc: 0.46 - ETA: 3s - loss: 13.9105 - acc: 0.47 - ETA: 3s - loss: 12.6956 - acc: 0.49 - ETA: 3s - loss: 11.6890 - acc: 0.50 - ETA: 3s - loss: 10.8354 - acc: 0.51 - ETA: 2s - loss: 10.1198 - acc: 0.51 - ETA: 2s - loss: 9.4758 - acc: 0.5375 - ETA: 2s - loss: 8.9109 - acc: 0.560 - ETA: 2s - loss: 8.0512 - acc: 0.563 - ETA: 1s - loss: 7.6538 - acc: 0.573 - ETA: 1s - loss: 7.2931 - acc: 0.585 - ETA: 1s - loss: 6.9724 - acc: 0.587 - ETA: 1s - loss: 6.6740 - acc: 0.598 - ETA: 1s - loss: 6.4012 - acc: 0.608 - ETA: 1s - loss: 6.1433 - acc: 0.625 - ETA: 1s - loss: 5.9076 - acc: 0.635 - ETA: 0s - loss: 5.6957 - acc: 0.641 - ETA: 0s - loss: 5.5019 - acc: 0.645 - ETA: 0s - loss: 5.3159 - acc: 0.652 - ETA: 0s - loss: 5.1411 - acc: 0.664 - ETA: 0s - loss: 5.0018 - acc: 0.659 - ETA: 0s - loss: 4.8822 - acc: 0.656 - ETA: 0s - loss: 4.7401 - acc: 0.661 - 5s 155ms/step - loss: 4.6116 - acc: 0.6680 - val_loss: 0.6670 - val_acc: 0.6602\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.2223 - acc: 0.937 - ETA: 4s - loss: 0.1662 - acc: 0.953 - ETA: 4s - loss: 0.1892 - acc: 0.947 - ETA: 3s - loss: 0.1987 - acc: 0.937 - ETA: 3s - loss: 0.1876 - acc: 0.950 - ETA: 3s - loss: 0.1859 - acc: 0.947 - ETA: 3s - loss: 0.1874 - acc: 0.946 - ETA: 3s - loss: 0.2109 - acc: 0.933 - ETA: 3s - loss: 0.2504 - acc: 0.895 - ETA: 2s - loss: 0.2474 - acc: 0.903 - ETA: 2s - loss: 0.2406 - acc: 0.909 - ETA: 2s - loss: 0.2299 - acc: 0.914 - ETA: 2s - loss: 0.2215 - acc: 0.918 - ETA: 2s - loss: 0.2192 - acc: 0.919 - ETA: 2s - loss: 0.2131 - acc: 0.922 - ETA: 2s - loss: 0.2119 - acc: 0.923 - ETA: 1s - loss: 0.2205 - acc: 0.915 - ETA: 1s - loss: 0.2149 - acc: 0.920 - ETA: 1s - loss: 0.2080 - acc: 0.924 - ETA: 1s - loss: 0.2030 - acc: 0.926 - ETA: 1s - loss: 0.1960 - acc: 0.930 - ETA: 1s - loss: 0.1896 - acc: 0.933 - ETA: 1s - loss: 0.1848 - acc: 0.934 - ETA: 1s - loss: 0.1808 - acc: 0.936 - ETA: 0s - loss: 0.1811 - acc: 0.932 - ETA: 0s - loss: 0.1783 - acc: 0.935 - ETA: 0s - loss: 0.1775 - acc: 0.935 - ETA: 0s - loss: 0.1730 - acc: 0.937 - ETA: 0s - loss: 0.1685 - acc: 0.939 - ETA: 0s - loss: 0.1658 - acc: 0.940 - ETA: 0s - loss: 0.1643 - acc: 0.940 - 4s 134ms/step - loss: 0.1601 - acc: 0.9396 - val_loss: 1.4397 - val_acc: 0.6562\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0610 - acc: 1.000 - ETA: 4s - loss: 0.0527 - acc: 1.000 - ETA: 3s - loss: 0.0432 - acc: 1.000 - ETA: 3s - loss: 0.0547 - acc: 0.992 - ETA: 3s - loss: 0.0480 - acc: 0.993 - ETA: 3s - loss: 0.0520 - acc: 0.989 - ETA: 3s - loss: 0.0795 - acc: 0.964 - ETA: 3s - loss: 0.1003 - acc: 0.949 - ETA: 2s - loss: 0.0995 - acc: 0.951 - ETA: 2s - loss: 0.1029 - acc: 0.950 - ETA: 2s - loss: 0.1240 - acc: 0.946 - ETA: 2s - loss: 0.1302 - acc: 0.942 - ETA: 2s - loss: 0.1255 - acc: 0.947 - ETA: 2s - loss: 0.1232 - acc: 0.948 - ETA: 2s - loss: 0.1232 - acc: 0.947 - ETA: 2s - loss: 0.1178 - acc: 0.951 - ETA: 1s - loss: 0.1225 - acc: 0.946 - ETA: 1s - loss: 0.4357 - acc: 0.918 - ETA: 1s - loss: 0.4529 - acc: 0.908 - ETA: 1s - loss: 0.4410 - acc: 0.906 - ETA: 1s - loss: 0.4225 - acc: 0.911 - ETA: 1s - loss: 0.4050 - acc: 0.915 - ETA: 1s - loss: 0.3888 - acc: 0.918 - ETA: 0s - loss: 0.3765 - acc: 0.919 - ETA: 0s - loss: 0.3632 - acc: 0.922 - ETA: 0s - loss: 0.3502 - acc: 0.925 - ETA: 0s - loss: 0.3380 - acc: 0.928 - ETA: 0s - loss: 0.3272 - acc: 0.931 - ETA: 0s - loss: 0.3206 - acc: 0.931 - ETA: 0s - loss: 0.3173 - acc: 0.931 - ETA: 0s - loss: 0.3099 - acc: 0.932 - 5s 141ms/step - loss: 0.3023 - acc: 0.9348 - val_loss: 1.3270 - val_acc: 0.7266\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0266 - acc: 1.000 - ETA: 4s - loss: 0.0174 - acc: 1.000 - ETA: 4s - loss: 0.0258 - acc: 1.000 - ETA: 3s - loss: 0.0214 - acc: 1.000 - ETA: 3s - loss: 0.0200 - acc: 1.000 - ETA: 3s - loss: 0.0246 - acc: 0.994 - ETA: 3s - loss: 0.0278 - acc: 0.991 - ETA: 3s - loss: 0.0300 - acc: 0.988 - ETA: 3s - loss: 0.0328 - acc: 0.989 - ETA: 2s - loss: 0.0308 - acc: 0.990 - ETA: 2s - loss: 0.0282 - acc: 0.991 - ETA: 2s - loss: 0.0276 - acc: 0.992 - ETA: 2s - loss: 0.0259 - acc: 0.992 - ETA: 2s - loss: 0.0242 - acc: 0.993 - ETA: 2s - loss: 0.0241 - acc: 0.993 - ETA: 2s - loss: 0.0235 - acc: 0.994 - ETA: 1s - loss: 0.0226 - acc: 0.994 - ETA: 1s - loss: 0.0214 - acc: 0.994 - ETA: 1s - loss: 0.0203 - acc: 0.995 - ETA: 1s - loss: 0.0194 - acc: 0.995 - ETA: 1s - loss: 0.0192 - acc: 0.994 - ETA: 1s - loss: 0.0997 - acc: 0.977 - ETA: 1s - loss: 0.1806 - acc: 0.954 - ETA: 0s - loss: 0.1810 - acc: 0.954 - ETA: 0s - loss: 0.1761 - acc: 0.955 - ETA: 0s - loss: 0.1733 - acc: 0.956 - ETA: 0s - loss: 0.1690 - acc: 0.958 - ETA: 0s - loss: 0.1656 - acc: 0.960 - ETA: 0s - loss: 0.1639 - acc: 0.960 - ETA: 0s - loss: 0.1600 - acc: 0.960 - ETA: 0s - loss: 0.1564 - acc: 0.961 - 4s 135ms/step - loss: 0.1524 - acc: 0.9630 - val_loss: 1.4637 - val_acc: 0.6953\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0100 - acc: 1.000 - ETA: 4s - loss: 0.0131 - acc: 1.000 - ETA: 3s - loss: 0.0152 - acc: 1.000 - ETA: 3s - loss: 0.0190 - acc: 1.000 - ETA: 3s - loss: 0.0207 - acc: 1.000 - ETA: 3s - loss: 0.0200 - acc: 1.000 - ETA: 3s - loss: 0.0197 - acc: 1.000 - ETA: 3s - loss: 0.0206 - acc: 1.000 - ETA: 2s - loss: 0.0218 - acc: 1.000 - ETA: 2s - loss: 0.0222 - acc: 1.000 - ETA: 2s - loss: 0.0204 - acc: 1.000 - ETA: 2s - loss: 0.0200 - acc: 1.000 - ETA: 2s - loss: 0.0201 - acc: 1.000 - ETA: 2s - loss: 0.0189 - acc: 1.000 - ETA: 1s - loss: 0.0186 - acc: 1.000 - ETA: 1s - loss: 0.0178 - acc: 1.000 - ETA: 1s - loss: 0.0169 - acc: 1.000 - ETA: 1s - loss: 0.0161 - acc: 1.000 - ETA: 1s - loss: 0.0154 - acc: 1.000 - ETA: 1s - loss: 0.0149 - acc: 1.000 - ETA: 1s - loss: 0.0144 - acc: 1.000 - ETA: 1s - loss: 0.0142 - acc: 1.000 - ETA: 1s - loss: 0.0136 - acc: 1.000 - ETA: 0s - loss: 0.0132 - acc: 1.000 - ETA: 0s - loss: 0.0128 - acc: 1.000 - ETA: 0s - loss: 0.0124 - acc: 1.000 - ETA: 0s - loss: 0.0121 - acc: 1.000 - ETA: 0s - loss: 0.0119 - acc: 1.000 - ETA: 0s - loss: 0.0115 - acc: 1.000 - ETA: 0s - loss: 0.0115 - acc: 1.000 - ETA: 0s - loss: 0.0169 - acc: 0.996 - 4s 134ms/step - loss: 0.0406 - acc: 0.9854 - val_loss: 1.7505 - val_acc: 0.5273\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7265625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 320)               1311040   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 1,332,641\n",
      "Trainable params: 1,332,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - ETA: 29s - loss: 0.7025 - acc: 0.46 - ETA: 9s - loss: 1.1585 - acc: 0.4688 - ETA: 7s - loss: 1.0404 - acc: 0.474 - ETA: 5s - loss: 0.9802 - acc: 0.509 - ETA: 4s - loss: 0.9377 - acc: 0.502 - ETA: 4s - loss: 0.9035 - acc: 0.555 - ETA: 4s - loss: 0.8765 - acc: 0.552 - ETA: 3s - loss: 0.9077 - acc: 0.518 - ETA: 3s - loss: 0.8814 - acc: 0.535 - ETA: 3s - loss: 0.8653 - acc: 0.538 - ETA: 3s - loss: 0.8491 - acc: 0.542 - ETA: 2s - loss: 0.8281 - acc: 0.551 - ETA: 2s - loss: 0.8145 - acc: 0.552 - ETA: 2s - loss: 0.7959 - acc: 0.573 - ETA: 2s - loss: 0.7940 - acc: 0.578 - ETA: 2s - loss: 0.7794 - acc: 0.596 - ETA: 1s - loss: 0.7639 - acc: 0.606 - ETA: 1s - loss: 0.7485 - acc: 0.618 - ETA: 1s - loss: 0.7265 - acc: 0.634 - ETA: 1s - loss: 0.7359 - acc: 0.632 - ETA: 1s - loss: 0.7406 - acc: 0.623 - ETA: 1s - loss: 0.7331 - acc: 0.631 - ETA: 1s - loss: 0.7235 - acc: 0.639 - ETA: 0s - loss: 0.7150 - acc: 0.643 - ETA: 0s - loss: 0.7054 - acc: 0.650 - ETA: 0s - loss: 0.6964 - acc: 0.655 - ETA: 0s - loss: 0.6826 - acc: 0.663 - ETA: 0s - loss: 0.6672 - acc: 0.672 - ETA: 0s - loss: 0.6515 - acc: 0.680 - ETA: 0s - loss: 0.6534 - acc: 0.681 - 5s 153ms/step - loss: 0.6462 - acc: 0.6816 - val_loss: 0.5862 - val_acc: 0.8242\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.1310 - acc: 0.968 - ETA: 4s - loss: 0.1417 - acc: 0.953 - ETA: 4s - loss: 0.1173 - acc: 0.968 - ETA: 3s - loss: 0.1062 - acc: 0.968 - ETA: 3s - loss: 0.1027 - acc: 0.975 - ETA: 3s - loss: 0.1219 - acc: 0.958 - ETA: 3s - loss: 0.1332 - acc: 0.942 - ETA: 3s - loss: 0.1522 - acc: 0.933 - ETA: 3s - loss: 0.1456 - acc: 0.937 - ETA: 2s - loss: 0.1421 - acc: 0.940 - ETA: 2s - loss: 0.1505 - acc: 0.934 - ETA: 2s - loss: 0.1534 - acc: 0.932 - ETA: 2s - loss: 0.1483 - acc: 0.935 - ETA: 2s - loss: 0.1411 - acc: 0.939 - ETA: 2s - loss: 0.1338 - acc: 0.943 - ETA: 2s - loss: 0.1311 - acc: 0.947 - ETA: 1s - loss: 0.1327 - acc: 0.944 - ETA: 1s - loss: 0.1341 - acc: 0.944 - ETA: 1s - loss: 0.1312 - acc: 0.945 - ETA: 1s - loss: 0.1399 - acc: 0.942 - ETA: 1s - loss: 0.1476 - acc: 0.937 - ETA: 1s - loss: 0.1498 - acc: 0.937 - ETA: 1s - loss: 0.1490 - acc: 0.937 - ETA: 0s - loss: 0.1494 - acc: 0.937 - ETA: 0s - loss: 0.1449 - acc: 0.940 - ETA: 0s - loss: 0.1405 - acc: 0.942 - ETA: 0s - loss: 0.1383 - acc: 0.943 - ETA: 0s - loss: 0.1450 - acc: 0.941 - ETA: 0s - loss: 0.1513 - acc: 0.937 - ETA: 0s - loss: 0.1520 - acc: 0.938 - ETA: 0s - loss: 0.1517 - acc: 0.937 - 4s 135ms/step - loss: 0.1491 - acc: 0.9396 - val_loss: 1.0888 - val_acc: 0.8320\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0543 - acc: 1.000 - ETA: 4s - loss: 0.0350 - acc: 1.000 - ETA: 4s - loss: 0.0250 - acc: 1.000 - ETA: 3s - loss: 0.0196 - acc: 1.000 - ETA: 3s - loss: 0.0214 - acc: 1.000 - ETA: 3s - loss: 0.0233 - acc: 0.994 - ETA: 3s - loss: 0.0464 - acc: 0.982 - ETA: 3s - loss: 0.0500 - acc: 0.976 - ETA: 3s - loss: 0.0474 - acc: 0.979 - ETA: 2s - loss: 0.0451 - acc: 0.981 - ETA: 2s - loss: 0.0414 - acc: 0.983 - ETA: 2s - loss: 0.0384 - acc: 0.984 - ETA: 2s - loss: 0.0380 - acc: 0.983 - ETA: 2s - loss: 0.0427 - acc: 0.979 - ETA: 2s - loss: 0.0518 - acc: 0.975 - ETA: 2s - loss: 0.0714 - acc: 0.966 - ETA: 1s - loss: 0.6389 - acc: 0.943 - ETA: 1s - loss: 0.6105 - acc: 0.943 - ETA: 1s - loss: 0.5882 - acc: 0.942 - ETA: 1s - loss: 0.5650 - acc: 0.942 - ETA: 1s - loss: 0.5413 - acc: 0.945 - ETA: 1s - loss: 0.5193 - acc: 0.947 - ETA: 1s - loss: 0.5011 - acc: 0.948 - ETA: 0s - loss: 0.4821 - acc: 0.950 - ETA: 0s - loss: 0.4669 - acc: 0.951 - ETA: 0s - loss: 0.4520 - acc: 0.952 - ETA: 0s - loss: 0.4379 - acc: 0.952 - ETA: 0s - loss: 0.4256 - acc: 0.953 - ETA: 0s - loss: 0.4116 - acc: 0.954 - ETA: 0s - loss: 0.3985 - acc: 0.956 - ETA: 0s - loss: 0.3867 - acc: 0.957 - 4s 134ms/step - loss: 0.3783 - acc: 0.9562 - val_loss: 2.1721 - val_acc: 0.7305\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0245 - acc: 1.000 - ETA: 4s - loss: 0.0873 - acc: 0.937 - ETA: 4s - loss: 0.0807 - acc: 0.947 - ETA: 3s - loss: 0.0624 - acc: 0.960 - ETA: 3s - loss: 0.0576 - acc: 0.962 - ETA: 3s - loss: 0.0501 - acc: 0.968 - ETA: 3s - loss: 0.0550 - acc: 0.968 - ETA: 3s - loss: 0.0542 - acc: 0.968 - ETA: 2s - loss: 0.0484 - acc: 0.972 - ETA: 2s - loss: 0.0463 - acc: 0.975 - ETA: 2s - loss: 0.0428 - acc: 0.977 - ETA: 2s - loss: 0.0402 - acc: 0.979 - ETA: 2s - loss: 0.0375 - acc: 0.980 - ETA: 2s - loss: 0.0356 - acc: 0.982 - ETA: 2s - loss: 0.0334 - acc: 0.983 - ETA: 2s - loss: 0.0328 - acc: 0.984 - ETA: 1s - loss: 0.0349 - acc: 0.983 - ETA: 1s - loss: 0.0425 - acc: 0.979 - ETA: 1s - loss: 0.0530 - acc: 0.972 - ETA: 1s - loss: 0.0546 - acc: 0.970 - ETA: 1s - loss: 0.0533 - acc: 0.971 - ETA: 1s - loss: 0.0519 - acc: 0.973 - ETA: 1s - loss: 0.0502 - acc: 0.974 - ETA: 0s - loss: 0.0506 - acc: 0.972 - ETA: 0s - loss: 0.0492 - acc: 0.973 - ETA: 0s - loss: 0.0475 - acc: 0.974 - ETA: 0s - loss: 0.0462 - acc: 0.975 - ETA: 0s - loss: 0.0470 - acc: 0.975 - ETA: 0s - loss: 0.0456 - acc: 0.976 - ETA: 0s - loss: 0.0445 - acc: 0.977 - ETA: 0s - loss: 0.0434 - acc: 0.977 - 4s 135ms/step - loss: 0.0424 - acc: 0.9786 - val_loss: 1.1215 - val_acc: 0.8672\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0122 - acc: 1.000 - ETA: 4s - loss: 0.0069 - acc: 1.000 - ETA: 3s - loss: 0.0048 - acc: 1.000 - ETA: 3s - loss: 0.0074 - acc: 1.000 - ETA: 3s - loss: 0.1003 - acc: 0.968 - ETA: 3s - loss: 0.1805 - acc: 0.932 - ETA: 3s - loss: 0.3282 - acc: 0.866 - ETA: 3s - loss: 0.3119 - acc: 0.871 - ETA: 2s - loss: 0.2796 - acc: 0.885 - ETA: 2s - loss: 0.2579 - acc: 0.893 - ETA: 2s - loss: 0.2485 - acc: 0.897 - ETA: 2s - loss: 0.2282 - acc: 0.906 - ETA: 2s - loss: 0.2136 - acc: 0.911 - ETA: 2s - loss: 0.2009 - acc: 0.917 - ETA: 2s - loss: 0.1878 - acc: 0.922 - ETA: 2s - loss: 0.1765 - acc: 0.927 - ETA: 1s - loss: 0.1668 - acc: 0.932 - ETA: 1s - loss: 0.1607 - acc: 0.934 - ETA: 1s - loss: 0.1539 - acc: 0.935 - ETA: 1s - loss: 0.1473 - acc: 0.939 - ETA: 1s - loss: 0.1416 - acc: 0.942 - ETA: 1s - loss: 0.1359 - acc: 0.944 - ETA: 1s - loss: 0.1303 - acc: 0.947 - ETA: 1s - loss: 0.1249 - acc: 0.949 - ETA: 0s - loss: 0.1200 - acc: 0.951 - ETA: 0s - loss: 0.1156 - acc: 0.953 - ETA: 0s - loss: 0.1116 - acc: 0.954 - ETA: 0s - loss: 0.1076 - acc: 0.956 - ETA: 0s - loss: 0.1006 - acc: 0.958 - ETA: 0s - loss: 0.0974 - acc: 0.959 - ETA: 0s - loss: 0.0944 - acc: 0.960 - 4s 134ms/step - loss: 0.0917 - acc: 0.9620 - val_loss: 1.7415 - val_acc: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 320</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8671875</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 320)               1311040   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 1,332,641\n",
      "Trainable params: 1,332,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - ETA: 21s - loss: 0.7049 - acc: 0.43 - ETA: 12s - loss: 0.7879 - acc: 0.50 - ETA: 9s - loss: 0.7479 - acc: 0.5312 - ETA: 7s - loss: 0.7880 - acc: 0.515 - ETA: 6s - loss: 0.7787 - acc: 0.493 - ETA: 5s - loss: 0.7657 - acc: 0.479 - ETA: 5s - loss: 0.7532 - acc: 0.544 - ETA: 4s - loss: 0.7414 - acc: 0.550 - ETA: 4s - loss: 0.7306 - acc: 0.548 - ETA: 3s - loss: 0.7678 - acc: 0.535 - ETA: 3s - loss: 0.7624 - acc: 0.523 - ETA: 3s - loss: 0.7564 - acc: 0.522 - ETA: 2s - loss: 0.7500 - acc: 0.541 - ETA: 2s - loss: 0.7431 - acc: 0.569 - ETA: 2s - loss: 0.7353 - acc: 0.594 - ETA: 2s - loss: 0.7212 - acc: 0.609 - ETA: 2s - loss: 0.7658 - acc: 0.597 - ETA: 2s - loss: 0.7509 - acc: 0.607 - ETA: 1s - loss: 0.7448 - acc: 0.602 - ETA: 1s - loss: 0.7305 - acc: 0.620 - ETA: 1s - loss: 0.7126 - acc: 0.634 - ETA: 1s - loss: 0.6896 - acc: 0.647 - ETA: 1s - loss: 0.6748 - acc: 0.654 - ETA: 1s - loss: 0.7282 - acc: 0.649 - ETA: 0s - loss: 0.7203 - acc: 0.658 - ETA: 0s - loss: 0.7088 - acc: 0.670 - ETA: 0s - loss: 0.6987 - acc: 0.680 - ETA: 0s - loss: 0.6860 - acc: 0.691 - ETA: 0s - loss: 0.6746 - acc: 0.699 - ETA: 0s - loss: 0.6627 - acc: 0.707 - ETA: 0s - loss: 0.6484 - acc: 0.715 - 5s 153ms/step - loss: 0.6353 - acc: 0.7215 - val_loss: 0.4645 - val_acc: 0.8750\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.3553 - acc: 0.875 - ETA: 4s - loss: 0.3329 - acc: 0.828 - ETA: 3s - loss: 0.2839 - acc: 0.864 - ETA: 3s - loss: 0.2574 - acc: 0.890 - ETA: 3s - loss: 0.2210 - acc: 0.912 - ETA: 3s - loss: 0.1926 - acc: 0.927 - ETA: 3s - loss: 0.1836 - acc: 0.933 - ETA: 3s - loss: 0.1883 - acc: 0.933 - ETA: 2s - loss: 0.2167 - acc: 0.916 - ETA: 2s - loss: 0.2201 - acc: 0.912 - ETA: 2s - loss: 0.2166 - acc: 0.911 - ETA: 2s - loss: 0.2149 - acc: 0.911 - ETA: 2s - loss: 0.2046 - acc: 0.918 - ETA: 2s - loss: 0.1945 - acc: 0.924 - ETA: 2s - loss: 0.1897 - acc: 0.927 - ETA: 2s - loss: 0.1875 - acc: 0.927 - ETA: 1s - loss: 0.1853 - acc: 0.928 - ETA: 1s - loss: 0.2036 - acc: 0.918 - ETA: 1s - loss: 0.2261 - acc: 0.906 - ETA: 1s - loss: 0.2243 - acc: 0.909 - ETA: 1s - loss: 0.2173 - acc: 0.913 - ETA: 1s - loss: 0.2128 - acc: 0.914 - ETA: 1s - loss: 0.2104 - acc: 0.914 - ETA: 1s - loss: 0.2030 - acc: 0.918 - ETA: 0s - loss: 0.2007 - acc: 0.918 - ETA: 0s - loss: 0.1952 - acc: 0.921 - ETA: 0s - loss: 0.1935 - acc: 0.922 - ETA: 0s - loss: 0.1834 - acc: 0.923 - ETA: 0s - loss: 0.1784 - acc: 0.925 - ETA: 0s - loss: 0.1746 - acc: 0.927 - ETA: 0s - loss: 0.1702 - acc: 0.928 - 4s 133ms/step - loss: 0.1660 - acc: 0.9309 - val_loss: 2.0141 - val_acc: 0.7852\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.1320 - acc: 0.937 - ETA: 4s - loss: 0.2094 - acc: 0.937 - ETA: 4s - loss: 0.2328 - acc: 0.916 - ETA: 3s - loss: 0.1899 - acc: 0.929 - ETA: 3s - loss: 0.1550 - acc: 0.943 - ETA: 3s - loss: 0.1330 - acc: 0.953 - ETA: 3s - loss: 0.1350 - acc: 0.955 - ETA: 3s - loss: 0.1228 - acc: 0.957 - ETA: 2s - loss: 0.1128 - acc: 0.961 - ETA: 2s - loss: 0.1044 - acc: 0.962 - ETA: 2s - loss: 0.1041 - acc: 0.963 - ETA: 2s - loss: 0.0917 - acc: 0.966 - ETA: 2s - loss: 0.0861 - acc: 0.969 - ETA: 2s - loss: 0.0820 - acc: 0.971 - ETA: 1s - loss: 0.0841 - acc: 0.971 - ETA: 1s - loss: 0.0818 - acc: 0.970 - ETA: 1s - loss: 0.0776 - acc: 0.972 - ETA: 1s - loss: 0.0768 - acc: 0.972 - ETA: 1s - loss: 0.0744 - acc: 0.973 - ETA: 1s - loss: 0.0710 - acc: 0.975 - ETA: 1s - loss: 0.0693 - acc: 0.976 - ETA: 1s - loss: 0.0817 - acc: 0.968 - ETA: 1s - loss: 0.1134 - acc: 0.955 - ETA: 0s - loss: 0.1200 - acc: 0.955 - ETA: 0s - loss: 0.1231 - acc: 0.955 - ETA: 0s - loss: 0.1202 - acc: 0.956 - ETA: 0s - loss: 0.1197 - acc: 0.957 - ETA: 0s - loss: 0.1164 - acc: 0.958 - ETA: 0s - loss: 0.1158 - acc: 0.958 - ETA: 0s - loss: 0.1129 - acc: 0.959 - ETA: 0s - loss: 0.1112 - acc: 0.959 - 4s 133ms/step - loss: 0.1102 - acc: 0.9601 - val_loss: 2.0343 - val_acc: 0.7734\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0138 - acc: 1.000 - ETA: 4s - loss: 0.0180 - acc: 1.000 - ETA: 4s - loss: 0.0334 - acc: 0.989 - ETA: 3s - loss: 0.0577 - acc: 0.976 - ETA: 3s - loss: 0.0588 - acc: 0.968 - ETA: 3s - loss: 0.0548 - acc: 0.974 - ETA: 3s - loss: 0.0480 - acc: 0.977 - ETA: 3s - loss: 0.0431 - acc: 0.980 - ETA: 2s - loss: 0.0403 - acc: 0.982 - ETA: 2s - loss: 0.0398 - acc: 0.984 - ETA: 2s - loss: 0.0367 - acc: 0.985 - ETA: 2s - loss: 0.0345 - acc: 0.987 - ETA: 2s - loss: 0.0319 - acc: 0.988 - ETA: 2s - loss: 0.0297 - acc: 0.988 - ETA: 2s - loss: 0.0286 - acc: 0.989 - ETA: 2s - loss: 0.0551 - acc: 0.980 - ETA: 1s - loss: 0.1455 - acc: 0.963 - ETA: 1s - loss: 0.1450 - acc: 0.963 - ETA: 1s - loss: 0.1442 - acc: 0.962 - ETA: 1s - loss: 0.1389 - acc: 0.964 - ETA: 1s - loss: 0.1340 - acc: 0.965 - ETA: 1s - loss: 0.1327 - acc: 0.965 - ETA: 1s - loss: 0.1274 - acc: 0.967 - ETA: 0s - loss: 0.1218 - acc: 0.967 - ETA: 0s - loss: 0.1189 - acc: 0.968 - ETA: 0s - loss: 0.1158 - acc: 0.970 - ETA: 0s - loss: 0.1121 - acc: 0.971 - ETA: 0s - loss: 0.1095 - acc: 0.972 - ETA: 0s - loss: 0.1063 - acc: 0.973 - ETA: 0s - loss: 0.1038 - acc: 0.974 - ETA: 0s - loss: 0.1012 - acc: 0.974 - 4s 133ms/step - loss: 0.1002 - acc: 0.9737 - val_loss: 2.7495 - val_acc: 0.7266\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.1752 - acc: 0.906 - ETA: 4s - loss: 0.1032 - acc: 0.953 - ETA: 4s - loss: 0.0758 - acc: 0.968 - ETA: 3s - loss: 0.0655 - acc: 0.976 - ETA: 3s - loss: 0.0527 - acc: 0.981 - ETA: 3s - loss: 0.0455 - acc: 0.984 - ETA: 3s - loss: 0.0412 - acc: 0.986 - ETA: 3s - loss: 0.0369 - acc: 0.988 - ETA: 3s - loss: 0.0337 - acc: 0.989 - ETA: 2s - loss: 0.0307 - acc: 0.990 - ETA: 2s - loss: 0.0281 - acc: 0.991 - ETA: 2s - loss: 0.0259 - acc: 0.992 - ETA: 2s - loss: 0.0239 - acc: 0.992 - ETA: 2s - loss: 0.0222 - acc: 0.993 - ETA: 2s - loss: 0.0208 - acc: 0.993 - ETA: 2s - loss: 0.0218 - acc: 0.992 - ETA: 1s - loss: 0.0209 - acc: 0.992 - ETA: 1s - loss: 0.0198 - acc: 0.993 - ETA: 1s - loss: 0.0188 - acc: 0.993 - ETA: 1s - loss: 0.0183 - acc: 0.993 - ETA: 1s - loss: 0.0236 - acc: 0.992 - ETA: 1s - loss: 0.0343 - acc: 0.985 - ETA: 1s - loss: 0.0514 - acc: 0.976 - ETA: 1s - loss: 0.0538 - acc: 0.976 - ETA: 0s - loss: 0.0533 - acc: 0.977 - ETA: 0s - loss: 0.0496 - acc: 0.978 - ETA: 0s - loss: 0.0546 - acc: 0.976 - ETA: 0s - loss: 0.0566 - acc: 0.975 - ETA: 0s - loss: 0.0648 - acc: 0.972 - ETA: 0s - loss: 0.1213 - acc: 0.962 - ETA: 0s - loss: 0.1319 - acc: 0.960 - 4s 134ms/step - loss: 0.1280 - acc: 0.9620 - val_loss: 2.6447 - val_acc: 0.7305\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0018 - acc: 1.000 - ETA: 4s - loss: 0.0046 - acc: 1.000 - ETA: 4s - loss: 0.0311 - acc: 0.989 - ETA: 3s - loss: 0.0241 - acc: 0.992 - ETA: 3s - loss: 0.0201 - acc: 0.993 - ETA: 3s - loss: 0.0195 - acc: 0.994 - ETA: 3s - loss: 0.0178 - acc: 0.995 - ETA: 3s - loss: 0.0169 - acc: 0.996 - ETA: 2s - loss: 0.0163 - acc: 0.996 - ETA: 2s - loss: 0.0158 - acc: 0.996 - ETA: 2s - loss: 0.0147 - acc: 0.997 - ETA: 2s - loss: 0.0138 - acc: 0.997 - ETA: 2s - loss: 0.0133 - acc: 0.997 - ETA: 2s - loss: 0.0126 - acc: 0.997 - ETA: 2s - loss: 0.0119 - acc: 0.997 - ETA: 2s - loss: 0.0113 - acc: 0.998 - ETA: 1s - loss: 0.0108 - acc: 0.998 - ETA: 1s - loss: 0.0103 - acc: 0.998 - ETA: 1s - loss: 0.0099 - acc: 0.998 - ETA: 1s - loss: 0.0097 - acc: 0.998 - ETA: 1s - loss: 0.0095 - acc: 0.998 - ETA: 1s - loss: 0.0097 - acc: 0.998 - ETA: 1s - loss: 0.0178 - acc: 0.994 - ETA: 1s - loss: 0.0387 - acc: 0.989 - ETA: 0s - loss: 0.0386 - acc: 0.990 - ETA: 0s - loss: 0.0375 - acc: 0.990 - ETA: 0s - loss: 0.0362 - acc: 0.990 - ETA: 0s - loss: 0.0358 - acc: 0.991 - ETA: 0s - loss: 0.0351 - acc: 0.991 - ETA: 0s - loss: 0.0329 - acc: 0.991 - ETA: 0s - loss: 0.0328 - acc: 0.991 - 4s 133ms/step - loss: 0.0320 - acc: 0.9912 - val_loss: 1.8646 - val_acc: 0.7930\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0060 - acc: 1.000 - ETA: 4s - loss: 0.0046 - acc: 1.000 - ETA: 4s - loss: 0.0051 - acc: 1.000 - ETA: 3s - loss: 0.0041 - acc: 1.000 - ETA: 3s - loss: 0.0036 - acc: 1.000 - ETA: 3s - loss: 0.0036 - acc: 1.000 - ETA: 3s - loss: 0.0032 - acc: 1.000 - ETA: 2s - loss: 0.0032 - acc: 1.000 - ETA: 2s - loss: 0.0030 - acc: 1.000 - ETA: 2s - loss: 0.0028 - acc: 1.000 - ETA: 2s - loss: 0.0026 - acc: 1.000 - ETA: 2s - loss: 0.0026 - acc: 1.000 - ETA: 2s - loss: 0.0029 - acc: 1.000 - ETA: 2s - loss: 0.0031 - acc: 1.000 - ETA: 1s - loss: 0.0030 - acc: 1.000 - ETA: 1s - loss: 0.0028 - acc: 1.000 - ETA: 1s - loss: 0.0028 - acc: 1.000 - ETA: 1s - loss: 0.0027 - acc: 1.000 - ETA: 1s - loss: 0.0025 - acc: 1.000 - ETA: 1s - loss: 0.0024 - acc: 1.000 - ETA: 1s - loss: 0.0023 - acc: 1.000 - ETA: 1s - loss: 0.0024 - acc: 1.000 - ETA: 1s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 0.0024 - acc: 1.000 - ETA: 0s - loss: 0.0086 - acc: 0.997 - ETA: 0s - loss: 0.0381 - acc: 0.986 - ETA: 0s - loss: 0.0385 - acc: 0.987 - ETA: 0s - loss: 0.0375 - acc: 0.987 - ETA: 0s - loss: 0.0381 - acc: 0.987 - ETA: 0s - loss: 0.0374 - acc: 0.987 - ETA: 0s - loss: 0.0364 - acc: 0.987 - 4s 133ms/step - loss: 0.0356 - acc: 0.9883 - val_loss: 2.2427 - val_acc: 0.8125\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0028 - acc: 1.000 - ETA: 4s - loss: 0.0063 - acc: 1.000 - ETA: 4s - loss: 0.0059 - acc: 1.000 - ETA: 3s - loss: 0.0063 - acc: 1.000 - ETA: 3s - loss: 0.0057 - acc: 1.000 - ETA: 3s - loss: 0.0051 - acc: 1.000 - ETA: 3s - loss: 0.0050 - acc: 1.000 - ETA: 3s - loss: 0.0051 - acc: 1.000 - ETA: 3s - loss: 0.0052 - acc: 1.000 - ETA: 2s - loss: 0.0049 - acc: 1.000 - ETA: 2s - loss: 0.0046 - acc: 1.000 - ETA: 2s - loss: 0.0039 - acc: 1.000 - ETA: 2s - loss: 0.0037 - acc: 1.000 - ETA: 2s - loss: 0.0035 - acc: 1.000 - ETA: 1s - loss: 0.0033 - acc: 1.000 - ETA: 1s - loss: 0.0032 - acc: 1.000 - ETA: 1s - loss: 0.0033 - acc: 1.000 - ETA: 1s - loss: 0.0034 - acc: 1.000 - ETA: 1s - loss: 0.0033 - acc: 1.000 - ETA: 1s - loss: 0.0032 - acc: 1.000 - ETA: 1s - loss: 0.0033 - acc: 1.000 - ETA: 1s - loss: 0.0032 - acc: 1.000 - ETA: 1s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0048 - acc: 0.998 - ETA: 0s - loss: 0.0047 - acc: 0.998 - ETA: 0s - loss: 0.0046 - acc: 0.998 - ETA: 0s - loss: 0.0049 - acc: 0.998 - ETA: 0s - loss: 0.0116 - acc: 0.995 - ETA: 0s - loss: 0.0442 - acc: 0.985 - ETA: 0s - loss: 0.0440 - acc: 0.985 - ETA: 0s - loss: 0.0431 - acc: 0.985 - 4s 134ms/step - loss: 0.0418 - acc: 0.9864 - val_loss: 1.8810 - val_acc: 0.8281\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0010 - acc: 1.000 - ETA: 4s - loss: 0.0028 - acc: 1.000 - ETA: 3s - loss: 0.0032 - acc: 1.000 - ETA: 3s - loss: 0.0034 - acc: 1.000 - ETA: 3s - loss: 0.0038 - acc: 1.000 - ETA: 3s - loss: 0.0034 - acc: 1.000 - ETA: 3s - loss: 0.0031 - acc: 1.000 - ETA: 3s - loss: 0.0032 - acc: 1.000 - ETA: 2s - loss: 0.0032 - acc: 1.000 - ETA: 2s - loss: 0.0029 - acc: 1.000 - ETA: 2s - loss: 0.0095 - acc: 0.997 - ETA: 2s - loss: 0.0177 - acc: 0.992 - ETA: 2s - loss: 0.1048 - acc: 0.971 - ETA: 2s - loss: 0.1198 - acc: 0.966 - ETA: 2s - loss: 0.1119 - acc: 0.968 - ETA: 2s - loss: 0.1051 - acc: 0.970 - ETA: 1s - loss: 0.0990 - acc: 0.972 - ETA: 1s - loss: 0.0936 - acc: 0.974 - ETA: 1s - loss: 0.0889 - acc: 0.975 - ETA: 1s - loss: 0.0846 - acc: 0.976 - ETA: 1s - loss: 0.0807 - acc: 0.977 - ETA: 1s - loss: 0.0772 - acc: 0.978 - ETA: 1s - loss: 0.0739 - acc: 0.979 - ETA: 1s - loss: 0.0709 - acc: 0.980 - ETA: 0s - loss: 0.0681 - acc: 0.981 - ETA: 0s - loss: 0.0655 - acc: 0.982 - ETA: 0s - loss: 0.0631 - acc: 0.982 - ETA: 0s - loss: 0.0608 - acc: 0.983 - ETA: 0s - loss: 0.0588 - acc: 0.983 - ETA: 0s - loss: 0.0568 - acc: 0.984 - ETA: 0s - loss: 0.0533 - acc: 0.984 - 4s 133ms/step - loss: 0.0517 - acc: 0.9854 - val_loss: 3.7054 - val_acc: 0.7500\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0015 - acc: 1.000 - ETA: 4s - loss: 0.0010 - acc: 1.000 - ETA: 4s - loss: 7.4655e-04 - acc: 1.000 - ETA: 3s - loss: 8.9072e-04 - acc: 1.000 - ETA: 3s - loss: 7.6692e-04 - acc: 1.000 - ETA: 3s - loss: 6.5676e-04 - acc: 1.000 - ETA: 3s - loss: 6.2529e-04 - acc: 1.000 - ETA: 3s - loss: 5.5150e-04 - acc: 1.000 - ETA: 2s - loss: 5.0267e-04 - acc: 1.000 - ETA: 2s - loss: 4.7057e-04 - acc: 1.000 - ETA: 2s - loss: 4.8158e-04 - acc: 1.000 - ETA: 2s - loss: 4.5467e-04 - acc: 1.000 - ETA: 2s - loss: 4.2435e-04 - acc: 1.000 - ETA: 2s - loss: 4.0960e-04 - acc: 1.000 - ETA: 2s - loss: 4.1638e-04 - acc: 1.000 - ETA: 2s - loss: 4.8903e-04 - acc: 1.000 - ETA: 1s - loss: 4.6288e-04 - acc: 1.000 - ETA: 1s - loss: 4.4912e-04 - acc: 1.000 - ETA: 1s - loss: 4.2682e-04 - acc: 1.000 - ETA: 1s - loss: 4.6323e-04 - acc: 1.000 - ETA: 1s - loss: 4.4298e-04 - acc: 1.000 - ETA: 1s - loss: 4.2580e-04 - acc: 1.000 - ETA: 1s - loss: 4.1050e-04 - acc: 1.000 - ETA: 0s - loss: 4.1813e-04 - acc: 1.000 - ETA: 0s - loss: 4.1125e-04 - acc: 1.000 - ETA: 0s - loss: 4.1126e-04 - acc: 1.000 - ETA: 0s - loss: 4.2847e-04 - acc: 1.000 - ETA: 0s - loss: 4.1593e-04 - acc: 1.000 - ETA: 0s - loss: 4.0707e-04 - acc: 1.000 - ETA: 0s - loss: 3.9429e-04 - acc: 1.000 - ETA: 0s - loss: 3.8421e-04 - acc: 1.000 - 4s 134ms/step - loss: 3.7438e-04 - acc: 1.0000 - val_loss: 4.5116 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 320</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 15</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/trial_id: 19ec0e172dfbcf999f585e05751e0205</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.875</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 416)               8154016   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 417       \n",
      "=================================================================\n",
      "Total params: 8,159,521\n",
      "Trainable params: 8,159,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - ETA: 19s - loss: 0.6975 - acc: 0.46 - ETA: 11s - loss: 1.2096 - acc: 0.45 - ETA: 8s - loss: 3.3619 - acc: 0.4167 - ETA: 5s - loss: 2.2806 - acc: 0.450 - ETA: 4s - loss: 2.0167 - acc: 0.454 - ETA: 4s - loss: 1.8251 - acc: 0.471 - ETA: 4s - loss: 1.6768 - acc: 0.484 - ETA: 3s - loss: 1.5546 - acc: 0.501 - ETA: 3s - loss: 1.4486 - acc: 0.549 - ETA: 3s - loss: 1.3737 - acc: 0.554 - ETA: 3s - loss: 1.3045 - acc: 0.569 - ETA: 2s - loss: 1.2358 - acc: 0.594 - ETA: 2s - loss: 1.1936 - acc: 0.601 - ETA: 2s - loss: 1.1434 - acc: 0.618 - ETA: 2s - loss: 1.0918 - acc: 0.641 - ETA: 2s - loss: 1.0465 - acc: 0.656 - ETA: 2s - loss: 1.0054 - acc: 0.667 - ETA: 1s - loss: 0.9679 - acc: 0.682 - ETA: 1s - loss: 0.9296 - acc: 0.697 - ETA: 1s - loss: 0.8933 - acc: 0.709 - ETA: 1s - loss: 0.8643 - acc: 0.718 - ETA: 1s - loss: 0.8352 - acc: 0.728 - ETA: 1s - loss: 0.8101 - acc: 0.736 - ETA: 1s - loss: 0.7803 - acc: 0.747 - ETA: 0s - loss: 0.7630 - acc: 0.752 - ETA: 0s - loss: 0.7733 - acc: 0.743 - ETA: 0s - loss: 0.7780 - acc: 0.739 - ETA: 0s - loss: 0.7569 - acc: 0.748 - ETA: 0s - loss: 0.7385 - acc: 0.754 - ETA: 0s - loss: 0.7192 - acc: 0.761 - ETA: 0s - loss: 0.6994 - acc: 0.768 - 5s 153ms/step - loss: 0.6829 - acc: 0.7751 - val_loss: 0.6939 - val_acc: 0.8477\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0542 - acc: 1.000 - ETA: 4s - loss: 0.0494 - acc: 1.000 - ETA: 3s - loss: 0.0669 - acc: 0.989 - ETA: 3s - loss: 0.0708 - acc: 0.984 - ETA: 3s - loss: 0.0749 - acc: 0.981 - ETA: 3s - loss: 0.0821 - acc: 0.979 - ETA: 3s - loss: 0.0751 - acc: 0.982 - ETA: 3s - loss: 0.0696 - acc: 0.984 - ETA: 2s - loss: 0.0656 - acc: 0.986 - ETA: 2s - loss: 0.0709 - acc: 0.981 - ETA: 2s - loss: 0.0873 - acc: 0.965 - ETA: 2s - loss: 0.1651 - acc: 0.934 - ETA: 2s - loss: 0.2014 - acc: 0.913 - ETA: 2s - loss: 0.2105 - acc: 0.906 - ETA: 2s - loss: 0.2007 - acc: 0.912 - ETA: 2s - loss: 0.1949 - acc: 0.918 - ETA: 1s - loss: 0.1878 - acc: 0.922 - ETA: 1s - loss: 0.1835 - acc: 0.925 - ETA: 1s - loss: 0.1791 - acc: 0.926 - ETA: 1s - loss: 0.1727 - acc: 0.929 - ETA: 1s - loss: 0.1660 - acc: 0.933 - ETA: 1s - loss: 0.1607 - acc: 0.936 - ETA: 1s - loss: 0.1542 - acc: 0.938 - ETA: 1s - loss: 0.1491 - acc: 0.940 - ETA: 0s - loss: 0.1443 - acc: 0.942 - ETA: 0s - loss: 0.1401 - acc: 0.944 - ETA: 0s - loss: 0.1353 - acc: 0.946 - ETA: 0s - loss: 0.1309 - acc: 0.948 - ETA: 0s - loss: 0.1267 - acc: 0.950 - ETA: 0s - loss: 0.1193 - acc: 0.952 - ETA: 0s - loss: 0.1183 - acc: 0.952 - 4s 133ms/step - loss: 0.1215 - acc: 0.9513 - val_loss: 0.9830 - val_acc: 0.6016\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 1.7042 - acc: 0.562 - ETA: 4s - loss: 0.8867 - acc: 0.765 - ETA: 3s - loss: 0.6662 - acc: 0.802 - ETA: 3s - loss: 0.5798 - acc: 0.812 - ETA: 3s - loss: 0.4747 - acc: 0.850 - ETA: 3s - loss: 0.4131 - acc: 0.869 - ETA: 3s - loss: 0.3592 - acc: 0.888 - ETA: 3s - loss: 0.3191 - acc: 0.902 - ETA: 2s - loss: 0.2878 - acc: 0.913 - ETA: 2s - loss: 0.2605 - acc: 0.921 - ETA: 2s - loss: 0.2373 - acc: 0.929 - ETA: 2s - loss: 0.2223 - acc: 0.932 - ETA: 2s - loss: 0.2088 - acc: 0.937 - ETA: 2s - loss: 0.1969 - acc: 0.939 - ETA: 2s - loss: 0.1856 - acc: 0.943 - ETA: 2s - loss: 0.1742 - acc: 0.947 - ETA: 1s - loss: 0.1645 - acc: 0.950 - ETA: 1s - loss: 0.1579 - acc: 0.951 - ETA: 1s - loss: 0.1498 - acc: 0.953 - ETA: 1s - loss: 0.1428 - acc: 0.956 - ETA: 1s - loss: 0.1380 - acc: 0.956 - ETA: 1s - loss: 0.1352 - acc: 0.957 - ETA: 1s - loss: 0.1322 - acc: 0.957 - ETA: 1s - loss: 0.1283 - acc: 0.959 - ETA: 0s - loss: 0.1195 - acc: 0.961 - ETA: 0s - loss: 0.1151 - acc: 0.962 - ETA: 0s - loss: 0.1111 - acc: 0.964 - ETA: 0s - loss: 0.1085 - acc: 0.965 - ETA: 0s - loss: 0.1050 - acc: 0.966 - ETA: 0s - loss: 0.1020 - acc: 0.967 - ETA: 0s - loss: 0.1003 - acc: 0.968 - 4s 133ms/step - loss: 0.0977 - acc: 0.9698 - val_loss: 2.1855 - val_acc: 0.8047\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0086 - acc: 1.000 - ETA: 4s - loss: 0.0109 - acc: 1.000 - ETA: 2s - loss: 0.0087 - acc: 1.000 - ETA: 2s - loss: 0.0099 - acc: 1.000 - ETA: 2s - loss: 0.0087 - acc: 1.000 - ETA: 2s - loss: 0.0080 - acc: 1.000 - ETA: 2s - loss: 0.0081 - acc: 1.000 - ETA: 2s - loss: 0.0076 - acc: 1.000 - ETA: 2s - loss: 0.0071 - acc: 1.000 - ETA: 2s - loss: 0.0064 - acc: 1.000 - ETA: 2s - loss: 0.0061 - acc: 1.000 - ETA: 2s - loss: 0.0063 - acc: 1.000 - ETA: 2s - loss: 0.0062 - acc: 1.000 - ETA: 2s - loss: 0.0061 - acc: 1.000 - ETA: 1s - loss: 0.0068 - acc: 1.000 - ETA: 1s - loss: 0.0086 - acc: 0.998 - ETA: 1s - loss: 0.0102 - acc: 0.998 - ETA: 1s - loss: 0.0358 - acc: 0.987 - ETA: 1s - loss: 0.0396 - acc: 0.985 - ETA: 1s - loss: 1.2975 - acc: 0.951 - ETA: 1s - loss: 1.2857 - acc: 0.936 - ETA: 1s - loss: 1.2352 - acc: 0.936 - ETA: 1s - loss: 1.1843 - acc: 0.939 - ETA: 0s - loss: 1.1379 - acc: 0.941 - ETA: 0s - loss: 1.0959 - acc: 0.942 - ETA: 0s - loss: 1.0597 - acc: 0.942 - ETA: 0s - loss: 1.0226 - acc: 0.944 - ETA: 0s - loss: 0.9876 - acc: 0.946 - ETA: 0s - loss: 0.9549 - acc: 0.948 - ETA: 0s - loss: 0.9250 - acc: 0.950 - ETA: 0s - loss: 0.8964 - acc: 0.951 - 4s 133ms/step - loss: 0.8702 - acc: 0.9533 - val_loss: 1.8081 - val_acc: 0.8281\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0044 - acc: 1.000 - ETA: 4s - loss: 0.0051 - acc: 1.000 - ETA: 3s - loss: 0.0044 - acc: 1.000 - ETA: 3s - loss: 0.0074 - acc: 1.000 - ETA: 3s - loss: 0.0078 - acc: 1.000 - ETA: 3s - loss: 0.0105 - acc: 1.000 - ETA: 3s - loss: 0.0251 - acc: 0.986 - ETA: 3s - loss: 0.0371 - acc: 0.984 - ETA: 2s - loss: 0.0336 - acc: 0.986 - ETA: 2s - loss: 0.0326 - acc: 0.987 - ETA: 2s - loss: 0.0298 - acc: 0.988 - ETA: 2s - loss: 0.0279 - acc: 0.989 - ETA: 2s - loss: 0.0270 - acc: 0.990 - ETA: 2s - loss: 0.0258 - acc: 0.991 - ETA: 2s - loss: 0.0247 - acc: 0.991 - ETA: 2s - loss: 0.0233 - acc: 0.992 - ETA: 1s - loss: 0.0220 - acc: 0.992 - ETA: 1s - loss: 0.0209 - acc: 0.993 - ETA: 1s - loss: 0.0202 - acc: 0.993 - ETA: 1s - loss: 0.0193 - acc: 0.993 - ETA: 1s - loss: 0.0185 - acc: 0.994 - ETA: 1s - loss: 0.0178 - acc: 0.994 - ETA: 1s - loss: 0.0175 - acc: 0.994 - ETA: 1s - loss: 0.0178 - acc: 0.994 - ETA: 0s - loss: 0.0172 - acc: 0.995 - ETA: 0s - loss: 0.0165 - acc: 0.995 - ETA: 0s - loss: 0.0161 - acc: 0.995 - ETA: 0s - loss: 0.0156 - acc: 0.995 - ETA: 0s - loss: 0.0151 - acc: 0.995 - ETA: 0s - loss: 0.0141 - acc: 0.995 - ETA: 0s - loss: 0.0138 - acc: 0.996 - 4s 134ms/step - loss: 0.0134 - acc: 0.9961 - val_loss: 2.5017 - val_acc: 0.8242\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 4.2784e-04 - acc: 1.000 - ETA: 4s - loss: 3.7282e-04 - acc: 1.000 - ETA: 3s - loss: 7.0739e-04 - acc: 1.000 - ETA: 3s - loss: 0.0011 - acc: 1.0000    - ETA: 3s - loss: 9.4042e-04 - acc: 1.000 - ETA: 3s - loss: 8.6041e-04 - acc: 1.000 - ETA: 3s - loss: 0.0012 - acc: 1.0000    - ETA: 3s - loss: 0.0018 - acc: 1.000 - ETA: 2s - loss: 0.0026 - acc: 1.000 - ETA: 2s - loss: 0.0040 - acc: 1.000 - ETA: 2s - loss: 0.0040 - acc: 1.000 - ETA: 2s - loss: 0.0038 - acc: 1.000 - ETA: 2s - loss: 0.0035 - acc: 1.000 - ETA: 2s - loss: 0.0033 - acc: 1.000 - ETA: 2s - loss: 0.0031 - acc: 1.000 - ETA: 2s - loss: 0.0087 - acc: 0.998 - ETA: 1s - loss: 0.1840 - acc: 0.983 - ETA: 1s - loss: 0.1779 - acc: 0.982 - ETA: 1s - loss: 0.1725 - acc: 0.981 - ETA: 1s - loss: 0.1663 - acc: 0.982 - ETA: 1s - loss: 0.1587 - acc: 0.983 - ETA: 1s - loss: 0.1517 - acc: 0.984 - ETA: 1s - loss: 0.1451 - acc: 0.985 - ETA: 1s - loss: 0.1391 - acc: 0.985 - ETA: 0s - loss: 0.1337 - acc: 0.986 - ETA: 0s - loss: 0.1286 - acc: 0.986 - ETA: 0s - loss: 0.1240 - acc: 0.987 - ETA: 0s - loss: 0.1198 - acc: 0.987 - ETA: 0s - loss: 0.1160 - acc: 0.988 - ETA: 0s - loss: 0.1122 - acc: 0.988 - ETA: 0s - loss: 0.1054 - acc: 0.988 - 4s 133ms/step - loss: 0.1024 - acc: 0.9893 - val_loss: 2.4224 - val_acc: 0.8359\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0031 - acc: 1.000 - ETA: 4s - loss: 0.0018 - acc: 1.000 - ETA: 3s - loss: 0.0015 - acc: 1.000 - ETA: 3s - loss: 0.0012 - acc: 1.000 - ETA: 3s - loss: 9.4254e-04 - acc: 1.000 - ETA: 3s - loss: 9.3938e-04 - acc: 1.000 - ETA: 3s - loss: 8.7918e-04 - acc: 1.000 - ETA: 3s - loss: 8.1326e-04 - acc: 1.000 - ETA: 2s - loss: 7.6624e-04 - acc: 1.000 - ETA: 2s - loss: 7.4401e-04 - acc: 1.000 - ETA: 2s - loss: 0.0016 - acc: 1.0000    - ETA: 2s - loss: 0.0642 - acc: 0.979 - ETA: 2s - loss: 0.1606 - acc: 0.961 - ETA: 2s - loss: 0.1509 - acc: 0.964 - ETA: 1s - loss: 0.1418 - acc: 0.966 - ETA: 1s - loss: 0.1339 - acc: 0.968 - ETA: 1s - loss: 0.1285 - acc: 0.970 - ETA: 1s - loss: 0.1224 - acc: 0.972 - ETA: 1s - loss: 0.1171 - acc: 0.973 - ETA: 1s - loss: 0.1118 - acc: 0.975 - ETA: 1s - loss: 0.1071 - acc: 0.976 - ETA: 1s - loss: 0.1026 - acc: 0.977 - ETA: 1s - loss: 0.0984 - acc: 0.978 - ETA: 0s - loss: 0.0945 - acc: 0.979 - ETA: 0s - loss: 0.0911 - acc: 0.980 - ETA: 0s - loss: 0.0878 - acc: 0.980 - ETA: 0s - loss: 0.0848 - acc: 0.981 - ETA: 0s - loss: 0.0820 - acc: 0.982 - ETA: 0s - loss: 0.0793 - acc: 0.982 - ETA: 0s - loss: 0.0768 - acc: 0.983 - ETA: 0s - loss: 0.0745 - acc: 0.983 - 4s 133ms/step - loss: 0.0723 - acc: 0.9844 - val_loss: 2.3947 - val_acc: 0.8359\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - ETA: 4s - loss: 7.3109e-04 - acc: 1.000 - ETA: 4s - loss: 0.0014 - acc: 1.0000    - ETA: 3s - loss: 0.0015 - acc: 1.000 - ETA: 3s - loss: 0.0015 - acc: 1.000 - ETA: 3s - loss: 0.0026 - acc: 1.000 - ETA: 3s - loss: 0.0023 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0017 - acc: 1.000 - ETA: 2s - loss: 0.0016 - acc: 1.000 - ETA: 2s - loss: 0.0016 - acc: 1.000 - ETA: 2s - loss: 0.0015 - acc: 1.000 - ETA: 2s - loss: 0.0015 - acc: 1.000 - ETA: 2s - loss: 0.0014 - acc: 1.000 - ETA: 2s - loss: 0.0014 - acc: 1.000 - ETA: 2s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0012 - acc: 1.000 - ETA: 1s - loss: 0.0012 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0087 - acc: 0.995 - ETA: 1s - loss: 0.0422 - acc: 0.989 - ETA: 1s - loss: 0.3488 - acc: 0.970 - ETA: 0s - loss: 0.3559 - acc: 0.966 - ETA: 0s - loss: 0.3429 - acc: 0.967 - ETA: 0s - loss: 0.3392 - acc: 0.966 - ETA: 0s - loss: 0.3277 - acc: 0.967 - ETA: 0s - loss: 0.3168 - acc: 0.968 - ETA: 0s - loss: 0.3067 - acc: 0.969 - ETA: 0s - loss: 0.2973 - acc: 0.970 - ETA: 0s - loss: 0.2882 - acc: 0.971 - 4s 133ms/step - loss: 0.2797 - acc: 0.9718 - val_loss: 2.8159 - val_acc: 0.8086\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 3s - loss: 0.0031 - acc: 1.000 - ETA: 3s - loss: 0.0036 - acc: 1.000 - ETA: 3s - loss: 0.0032 - acc: 1.000 - ETA: 3s - loss: 0.0033 - acc: 1.000 - ETA: 3s - loss: 0.0031 - acc: 1.000 - ETA: 3s - loss: 0.0046 - acc: 1.000 - ETA: 2s - loss: 0.0051 - acc: 1.000 - ETA: 2s - loss: 0.0048 - acc: 1.000 - ETA: 2s - loss: 0.0045 - acc: 1.000 - ETA: 2s - loss: 0.0041 - acc: 1.000 - ETA: 2s - loss: 0.0043 - acc: 1.000 - ETA: 2s - loss: 0.0043 - acc: 1.000 - ETA: 2s - loss: 0.0041 - acc: 1.000 - ETA: 2s - loss: 0.0039 - acc: 1.000 - ETA: 1s - loss: 0.0037 - acc: 1.000 - ETA: 1s - loss: 0.0038 - acc: 1.000 - ETA: 1s - loss: 0.0036 - acc: 1.000 - ETA: 1s - loss: 0.0034 - acc: 1.000 - ETA: 1s - loss: 0.0033 - acc: 1.000 - ETA: 1s - loss: 0.0031 - acc: 1.000 - ETA: 1s - loss: 0.0030 - acc: 1.000 - ETA: 1s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0028 - acc: 1.000 - ETA: 0s - loss: 0.0027 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0024 - acc: 1.000 - ETA: 0s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 0.0023 - acc: 1.000 - 4s 133ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 3.5204 - val_acc: 0.8164\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - ETA: 4s - loss: 8.9145e-05 - acc: 1.000 - ETA: 4s - loss: 6.9555e-04 - acc: 1.000 - ETA: 3s - loss: 6.0618e-04 - acc: 1.000 - ETA: 3s - loss: 4.9778e-04 - acc: 1.000 - ETA: 3s - loss: 4.0990e-04 - acc: 1.000 - ETA: 3s - loss: 4.9508e-04 - acc: 1.000 - ETA: 3s - loss: 4.5337e-04 - acc: 1.000 - ETA: 3s - loss: 4.2440e-04 - acc: 1.000 - ETA: 2s - loss: 4.5071e-04 - acc: 1.000 - ETA: 2s - loss: 4.0682e-04 - acc: 1.000 - ETA: 2s - loss: 3.7303e-04 - acc: 1.000 - ETA: 2s - loss: 3.4488e-04 - acc: 1.000 - ETA: 2s - loss: 3.2380e-04 - acc: 1.000 - ETA: 2s - loss: 3.0666e-04 - acc: 1.000 - ETA: 2s - loss: 2.9431e-04 - acc: 1.000 - ETA: 2s - loss: 2.9367e-04 - acc: 1.000 - ETA: 1s - loss: 2.7872e-04 - acc: 1.000 - ETA: 1s - loss: 2.7876e-04 - acc: 1.000 - ETA: 1s - loss: 2.6514e-04 - acc: 1.000 - ETA: 1s - loss: 2.5541e-04 - acc: 1.000 - ETA: 1s - loss: 2.4967e-04 - acc: 1.000 - ETA: 1s - loss: 2.5178e-04 - acc: 1.000 - ETA: 1s - loss: 2.5333e-04 - acc: 1.000 - ETA: 1s - loss: 2.4680e-04 - acc: 1.000 - ETA: 0s - loss: 2.3705e-04 - acc: 1.000 - ETA: 0s - loss: 2.3347e-04 - acc: 1.000 - ETA: 0s - loss: 2.2628e-04 - acc: 1.000 - ETA: 0s - loss: 2.2459e-04 - acc: 1.000 - ETA: 0s - loss: 2.1306e-04 - acc: 1.000 - ETA: 0s - loss: 2.0780e-04 - acc: 1.000 - ETA: 0s - loss: 2.0145e-04 - acc: 1.000 - 4s 133ms/step - loss: 1.9585e-04 - acc: 1.0000 - val_loss: 4.0761 - val_acc: 0.8203\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 15</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/trial_id: 0147c05a8b786fc73d4214f6d15a084d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.84765625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               20070656  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 20,117,569\n",
      "Trainable params: 20,117,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/15\n",
      "33/33 [==============================] - ETA: 20s - loss: 0.7005 - acc: 0.37 - ETA: 11s - loss: 12.8019 - acc: 0.421 - ETA: 8s - loss: 10.4464 - acc: 0.479 - ETA: 7s - loss: 8.1375 - acc: 0.4922 - ETA: 6s - loss: 6.6492 - acc: 0.481 - ETA: 5s - loss: 5.6506 - acc: 0.494 - ETA: 5s - loss: 4.9631 - acc: 0.491 - ETA: 4s - loss: 4.6068 - acc: 0.468 - ETA: 4s - loss: 4.1714 - acc: 0.479 - ETA: 3s - loss: 3.8181 - acc: 0.487 - ETA: 3s - loss: 3.5267 - acc: 0.497 - ETA: 3s - loss: 3.2871 - acc: 0.507 - ETA: 3s - loss: 3.0890 - acc: 0.507 - ETA: 2s - loss: 2.9188 - acc: 0.495 - ETA: 2s - loss: 2.7654 - acc: 0.508 - ETA: 2s - loss: 2.6244 - acc: 0.525 - ETA: 2s - loss: 2.6718 - acc: 0.526 - ETA: 1s - loss: 2.5598 - acc: 0.537 - ETA: 1s - loss: 2.4590 - acc: 0.541 - ETA: 1s - loss: 2.3662 - acc: 0.556 - ETA: 1s - loss: 2.2756 - acc: 0.571 - ETA: 1s - loss: 2.2033 - acc: 0.579 - ETA: 1s - loss: 2.1311 - acc: 0.585 - ETA: 1s - loss: 2.0567 - acc: 0.599 - ETA: 0s - loss: 1.9871 - acc: 0.612 - ETA: 0s - loss: 1.9518 - acc: 0.615 - ETA: 0s - loss: 1.8990 - acc: 0.620 - ETA: 0s - loss: 1.8462 - acc: 0.629 - ETA: 0s - loss: 1.7949 - acc: 0.640 - ETA: 0s - loss: 1.7444 - acc: 0.650 - ETA: 0s - loss: 1.7005 - acc: 0.654 - 5s 159ms/step - loss: 1.6592 - acc: 0.6592 - val_loss: 1.7226 - val_acc: 0.6602\n",
      "Epoch 2/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.2188 - acc: 0.937 - ETA: 4s - loss: 0.2092 - acc: 0.921 - ETA: 4s - loss: 0.1861 - acc: 0.916 - ETA: 3s - loss: 0.1641 - acc: 0.929 - ETA: 3s - loss: 0.1558 - acc: 0.937 - ETA: 3s - loss: 0.1678 - acc: 0.937 - ETA: 3s - loss: 0.2591 - acc: 0.892 - ETA: 3s - loss: 0.2930 - acc: 0.863 - ETA: 3s - loss: 0.2927 - acc: 0.868 - ETA: 2s - loss: 0.2823 - acc: 0.878 - ETA: 2s - loss: 0.2706 - acc: 0.886 - ETA: 2s - loss: 0.3303 - acc: 0.870 - ETA: 2s - loss: 0.3502 - acc: 0.852 - ETA: 2s - loss: 0.3375 - acc: 0.860 - ETA: 1s - loss: 0.3223 - acc: 0.869 - ETA: 1s - loss: 0.3061 - acc: 0.877 - ETA: 1s - loss: 0.2944 - acc: 0.883 - ETA: 1s - loss: 0.2847 - acc: 0.886 - ETA: 1s - loss: 0.2868 - acc: 0.883 - ETA: 1s - loss: 0.2827 - acc: 0.883 - ETA: 1s - loss: 0.2768 - acc: 0.885 - ETA: 1s - loss: 0.2733 - acc: 0.888 - ETA: 1s - loss: 0.2691 - acc: 0.890 - ETA: 0s - loss: 0.2628 - acc: 0.891 - ETA: 0s - loss: 0.2549 - acc: 0.895 - ETA: 0s - loss: 0.2472 - acc: 0.899 - ETA: 0s - loss: 0.2407 - acc: 0.902 - ETA: 0s - loss: 0.2408 - acc: 0.903 - ETA: 0s - loss: 0.2420 - acc: 0.901 - ETA: 0s - loss: 0.2373 - acc: 0.903 - ETA: 0s - loss: 0.2342 - acc: 0.905 - 5s 144ms/step - loss: 0.2296 - acc: 0.9075 - val_loss: 1.2650 - val_acc: 0.8438\n",
      "Epoch 3/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0523 - acc: 1.000 - ETA: 4s - loss: 0.1217 - acc: 0.953 - ETA: 4s - loss: 0.1471 - acc: 0.937 - ETA: 3s - loss: 0.2166 - acc: 0.921 - ETA: 3s - loss: 0.2032 - acc: 0.925 - ETA: 3s - loss: 0.1893 - acc: 0.927 - ETA: 3s - loss: 0.1679 - acc: 0.937 - ETA: 3s - loss: 0.1540 - acc: 0.941 - ETA: 3s - loss: 0.1507 - acc: 0.944 - ETA: 2s - loss: 0.1475 - acc: 0.943 - ETA: 2s - loss: 0.1396 - acc: 0.948 - ETA: 2s - loss: 0.1291 - acc: 0.953 - ETA: 2s - loss: 0.1196 - acc: 0.956 - ETA: 2s - loss: 0.1131 - acc: 0.959 - ETA: 2s - loss: 0.1069 - acc: 0.962 - ETA: 2s - loss: 0.1016 - acc: 0.964 - ETA: 1s - loss: 0.0967 - acc: 0.966 - ETA: 1s - loss: 0.0917 - acc: 0.968 - ETA: 1s - loss: 0.0871 - acc: 0.970 - ETA: 1s - loss: 0.0830 - acc: 0.971 - ETA: 1s - loss: 0.0794 - acc: 0.973 - ETA: 1s - loss: 0.0758 - acc: 0.974 - ETA: 1s - loss: 0.0742 - acc: 0.974 - ETA: 1s - loss: 0.0724 - acc: 0.975 - ETA: 1s - loss: 0.0721 - acc: 0.975 - ETA: 0s - loss: 0.0737 - acc: 0.974 - ETA: 0s - loss: 0.0846 - acc: 0.972 - ETA: 0s - loss: 0.3492 - acc: 0.958 - ETA: 0s - loss: 0.3385 - acc: 0.959 - ETA: 0s - loss: 0.3543 - acc: 0.951 - ETA: 0s - loss: 0.3664 - acc: 0.941 - 5s 138ms/step - loss: 0.3572 - acc: 0.9435 - val_loss: 1.6876 - val_acc: 0.7695\n",
      "Epoch 4/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0447 - acc: 1.000 - ETA: 4s - loss: 0.0419 - acc: 1.000 - ETA: 4s - loss: 0.0330 - acc: 1.000 - ETA: 3s - loss: 0.0271 - acc: 1.000 - ETA: 2s - loss: 0.0379 - acc: 0.987 - ETA: 2s - loss: 0.0855 - acc: 0.959 - ETA: 2s - loss: 0.0806 - acc: 0.960 - ETA: 2s - loss: 0.0728 - acc: 0.965 - ETA: 2s - loss: 0.0657 - acc: 0.969 - ETA: 2s - loss: 0.0608 - acc: 0.972 - ETA: 2s - loss: 0.0575 - acc: 0.974 - ETA: 2s - loss: 0.0572 - acc: 0.974 - ETA: 2s - loss: 0.0535 - acc: 0.976 - ETA: 2s - loss: 0.0502 - acc: 0.977 - ETA: 1s - loss: 0.0473 - acc: 0.979 - ETA: 1s - loss: 0.0454 - acc: 0.980 - ETA: 1s - loss: 0.0435 - acc: 0.981 - ETA: 1s - loss: 0.0431 - acc: 0.981 - ETA: 1s - loss: 0.0436 - acc: 0.982 - ETA: 1s - loss: 0.0425 - acc: 0.982 - ETA: 1s - loss: 0.0410 - acc: 0.983 - ETA: 1s - loss: 0.0433 - acc: 0.981 - ETA: 1s - loss: 0.0430 - acc: 0.981 - ETA: 0s - loss: 0.0418 - acc: 0.981 - ETA: 0s - loss: 0.0406 - acc: 0.982 - ETA: 0s - loss: 0.0391 - acc: 0.983 - ETA: 0s - loss: 0.0385 - acc: 0.983 - ETA: 0s - loss: 0.0423 - acc: 0.982 - ETA: 0s - loss: 0.0978 - acc: 0.974 - ETA: 0s - loss: 0.1696 - acc: 0.960 - ETA: 0s - loss: 0.1671 - acc: 0.961 - 4s 136ms/step - loss: 0.1625 - acc: 0.9630 - val_loss: 3.2241 - val_acc: 0.7852\n",
      "Epoch 5/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.3180 - acc: 0.906 - ETA: 4s - loss: 0.2357 - acc: 0.906 - ETA: 4s - loss: 0.1688 - acc: 0.927 - ETA: 3s - loss: 0.1297 - acc: 0.945 - ETA: 3s - loss: 0.1044 - acc: 0.956 - ETA: 3s - loss: 0.0906 - acc: 0.963 - ETA: 3s - loss: 0.0787 - acc: 0.968 - ETA: 3s - loss: 0.0694 - acc: 0.972 - ETA: 3s - loss: 0.0628 - acc: 0.975 - ETA: 2s - loss: 0.0578 - acc: 0.978 - ETA: 2s - loss: 0.0541 - acc: 0.980 - ETA: 2s - loss: 0.0498 - acc: 0.981 - ETA: 2s - loss: 0.0460 - acc: 0.983 - ETA: 2s - loss: 0.0451 - acc: 0.982 - ETA: 2s - loss: 0.0536 - acc: 0.977 - ETA: 2s - loss: 0.0514 - acc: 0.978 - ETA: 2s - loss: 0.0486 - acc: 0.979 - ETA: 1s - loss: 0.0487 - acc: 0.979 - ETA: 1s - loss: 0.0461 - acc: 0.980 - ETA: 1s - loss: 0.0475 - acc: 0.979 - ETA: 1s - loss: 0.0672 - acc: 0.976 - ETA: 1s - loss: 0.0770 - acc: 0.973 - ETA: 1s - loss: 0.0753 - acc: 0.974 - ETA: 0s - loss: 0.0721 - acc: 0.974 - ETA: 0s - loss: 0.0694 - acc: 0.975 - ETA: 0s - loss: 0.0670 - acc: 0.976 - ETA: 0s - loss: 0.0656 - acc: 0.976 - ETA: 0s - loss: 0.0671 - acc: 0.975 - ETA: 0s - loss: 0.0651 - acc: 0.976 - ETA: 0s - loss: 0.0630 - acc: 0.977 - ETA: 0s - loss: 0.0611 - acc: 0.977 - 5s 137ms/step - loss: 0.0595 - acc: 0.9786 - val_loss: 4.6191 - val_acc: 0.7578\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 4.0070e-04 - acc: 1.000 - ETA: 4s - loss: 0.0010 - acc: 1.0000    - ETA: 4s - loss: 7.4092e-04 - acc: 1.000 - ETA: 3s - loss: 6.1143e-04 - acc: 1.000 - ETA: 3s - loss: 0.0022 - acc: 1.0000    - ETA: 3s - loss: 0.0041 - acc: 1.000 - ETA: 3s - loss: 0.0200 - acc: 0.991 - ETA: 3s - loss: 0.1123 - acc: 0.988 - ETA: 3s - loss: 1.6539 - acc: 0.923 - ETA: 2s - loss: 1.5383 - acc: 0.919 - ETA: 2s - loss: 1.4108 - acc: 0.926 - ETA: 2s - loss: 1.3025 - acc: 0.932 - ETA: 2s - loss: 1.2097 - acc: 0.937 - ETA: 2s - loss: 1.1292 - acc: 0.942 - ETA: 2s - loss: 1.0592 - acc: 0.946 - ETA: 1s - loss: 0.9977 - acc: 0.949 - ETA: 1s - loss: 0.9429 - acc: 0.952 - ETA: 1s - loss: 0.8935 - acc: 0.955 - ETA: 1s - loss: 0.8490 - acc: 0.957 - ETA: 1s - loss: 0.8088 - acc: 0.959 - ETA: 1s - loss: 0.7723 - acc: 0.961 - ETA: 1s - loss: 0.7393 - acc: 0.963 - ETA: 1s - loss: 0.7085 - acc: 0.964 - ETA: 0s - loss: 0.6803 - acc: 0.966 - ETA: 0s - loss: 0.6548 - acc: 0.967 - ETA: 0s - loss: 0.6312 - acc: 0.968 - ETA: 0s - loss: 0.6087 - acc: 0.970 - ETA: 0s - loss: 0.5878 - acc: 0.971 - ETA: 0s - loss: 0.5683 - acc: 0.972 - ETA: 0s - loss: 0.5500 - acc: 0.973 - ETA: 0s - loss: 0.5328 - acc: 0.973 - 5s 137ms/step - loss: 0.5156 - acc: 0.9747 - val_loss: 4.2634 - val_acc: 0.7539\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0040 - acc: 1.000 - ETA: 4s - loss: 0.0025 - acc: 1.000 - ETA: 4s - loss: 0.0027 - acc: 1.000 - ETA: 3s - loss: 0.0021 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0018 - acc: 1.000 - ETA: 3s - loss: 0.0016 - acc: 1.000 - ETA: 3s - loss: 0.0014 - acc: 1.000 - ETA: 3s - loss: 0.0013 - acc: 1.000 - ETA: 2s - loss: 0.0012 - acc: 1.000 - ETA: 2s - loss: 0.0012 - acc: 1.000 - ETA: 2s - loss: 0.0011 - acc: 1.000 - ETA: 2s - loss: 0.0010 - acc: 1.000 - ETA: 2s - loss: 9.7353e-04 - acc: 1.000 - ETA: 2s - loss: 9.2911e-04 - acc: 1.000 - ETA: 2s - loss: 8.7708e-04 - acc: 1.000 - ETA: 1s - loss: 8.5003e-04 - acc: 1.000 - ETA: 1s - loss: 8.2335e-04 - acc: 1.000 - ETA: 1s - loss: 8.5115e-04 - acc: 1.000 - ETA: 1s - loss: 8.6252e-04 - acc: 1.000 - ETA: 1s - loss: 0.0014 - acc: 1.0000    - ETA: 1s - loss: 0.0092 - acc: 0.998 - ETA: 1s - loss: 0.0094 - acc: 0.998 - ETA: 1s - loss: 0.0103 - acc: 0.997 - ETA: 0s - loss: 0.0099 - acc: 0.997 - ETA: 0s - loss: 0.0096 - acc: 0.997 - ETA: 0s - loss: 0.0093 - acc: 0.997 - ETA: 0s - loss: 0.0090 - acc: 0.997 - ETA: 0s - loss: 0.0088 - acc: 0.997 - ETA: 0s - loss: 0.0082 - acc: 0.997 - ETA: 0s - loss: 0.0079 - acc: 0.998 - 5s 137ms/step - loss: 0.0077 - acc: 0.9981 - val_loss: 3.7343 - val_acc: 0.8008\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 2.0233e-04 - acc: 1.000 - ETA: 4s - loss: 1.6718e-04 - acc: 1.000 - ETA: 4s - loss: 1.6422e-04 - acc: 1.000 - ETA: 3s - loss: 1.9857e-04 - acc: 1.000 - ETA: 3s - loss: 1.9327e-04 - acc: 1.000 - ETA: 3s - loss: 3.3684e-04 - acc: 1.000 - ETA: 3s - loss: 3.3180e-04 - acc: 1.000 - ETA: 3s - loss: 3.0831e-04 - acc: 1.000 - ETA: 3s - loss: 2.9403e-04 - acc: 1.000 - ETA: 2s - loss: 2.6873e-04 - acc: 1.000 - ETA: 2s - loss: 2.5754e-04 - acc: 1.000 - ETA: 2s - loss: 2.3879e-04 - acc: 1.000 - ETA: 2s - loss: 2.2720e-04 - acc: 1.000 - ETA: 2s - loss: 2.1396e-04 - acc: 1.000 - ETA: 2s - loss: 2.0190e-04 - acc: 1.000 - ETA: 2s - loss: 3.1699e-04 - acc: 1.000 - ETA: 1s - loss: 0.0014 - acc: 1.0000    - ETA: 1s - loss: 0.0024 - acc: 1.000 - ETA: 1s - loss: 0.0048 - acc: 0.998 - ETA: 1s - loss: 0.0394 - acc: 0.989 - ETA: 1s - loss: 0.0625 - acc: 0.982 - ETA: 1s - loss: 0.0648 - acc: 0.977 - ETA: 1s - loss: 0.0621 - acc: 0.978 - ETA: 0s - loss: 0.0598 - acc: 0.979 - ETA: 0s - loss: 0.0591 - acc: 0.980 - ETA: 0s - loss: 0.0576 - acc: 0.980 - ETA: 0s - loss: 0.0556 - acc: 0.981 - ETA: 0s - loss: 0.0537 - acc: 0.982 - ETA: 0s - loss: 0.0520 - acc: 0.982 - ETA: 0s - loss: 0.0504 - acc: 0.983 - ETA: 0s - loss: 0.0488 - acc: 0.983 - 4s 135ms/step - loss: 0.0474 - acc: 0.9844 - val_loss: 4.4826 - val_acc: 0.8164\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 1.7404e-04 - acc: 1.000 - ETA: 3s - loss: 1.5347e-04 - acc: 1.000 - ETA: 3s - loss: 3.1723e-04 - acc: 1.000 - ETA: 3s - loss: 3.6097e-04 - acc: 1.000 - ETA: 3s - loss: 4.4337e-04 - acc: 1.000 - ETA: 2s - loss: 4.5089e-04 - acc: 1.000 - ETA: 2s - loss: 4.8368e-04 - acc: 1.000 - ETA: 2s - loss: 4.3660e-04 - acc: 1.000 - ETA: 2s - loss: 4.1127e-04 - acc: 1.000 - ETA: 2s - loss: 4.1816e-04 - acc: 1.000 - ETA: 2s - loss: 3.8613e-04 - acc: 1.000 - ETA: 2s - loss: 3.8469e-04 - acc: 1.000 - ETA: 2s - loss: 3.7078e-04 - acc: 1.000 - ETA: 2s - loss: 3.4906e-04 - acc: 1.000 - ETA: 1s - loss: 3.3926e-04 - acc: 1.000 - ETA: 1s - loss: 3.4750e-04 - acc: 1.000 - ETA: 1s - loss: 3.5008e-04 - acc: 1.000 - ETA: 1s - loss: 3.4015e-04 - acc: 1.000 - ETA: 1s - loss: 3.4003e-04 - acc: 1.000 - ETA: 1s - loss: 3.3917e-04 - acc: 1.000 - ETA: 1s - loss: 3.3061e-04 - acc: 1.000 - ETA: 1s - loss: 3.1865e-04 - acc: 1.000 - ETA: 1s - loss: 3.2016e-04 - acc: 1.000 - ETA: 0s - loss: 3.5277e-04 - acc: 1.000 - ETA: 0s - loss: 3.4918e-04 - acc: 1.000 - ETA: 0s - loss: 3.4763e-04 - acc: 1.000 - ETA: 0s - loss: 3.3732e-04 - acc: 1.000 - ETA: 0s - loss: 3.4145e-04 - acc: 1.000 - ETA: 0s - loss: 3.4454e-04 - acc: 1.000 - ETA: 0s - loss: 3.3804e-04 - acc: 1.000 - ETA: 0s - loss: 3.3468e-04 - acc: 1.000 - 4s 135ms/step - loss: 3.2886e-04 - acc: 1.0000 - val_loss: 5.3485 - val_acc: 0.8008\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 5.2340e-05 - acc: 1.000 - ETA: 4s - loss: 4.9061e-05 - acc: 1.000 - ETA: 4s - loss: 4.5230e-05 - acc: 1.000 - ETA: 3s - loss: 3.5487e-05 - acc: 1.000 - ETA: 3s - loss: 4.0690e-05 - acc: 1.000 - ETA: 3s - loss: 5.7230e-05 - acc: 1.000 - ETA: 3s - loss: 5.7887e-05 - acc: 1.000 - ETA: 3s - loss: 5.6718e-05 - acc: 1.000 - ETA: 3s - loss: 5.1237e-05 - acc: 1.000 - ETA: 2s - loss: 5.4221e-05 - acc: 1.000 - ETA: 2s - loss: 5.2056e-05 - acc: 1.000 - ETA: 2s - loss: 5.3610e-05 - acc: 1.000 - ETA: 2s - loss: 5.2773e-05 - acc: 1.000 - ETA: 2s - loss: 5.0627e-05 - acc: 1.000 - ETA: 1s - loss: 5.1450e-05 - acc: 1.000 - ETA: 1s - loss: 5.1462e-05 - acc: 1.000 - ETA: 1s - loss: 5.3080e-05 - acc: 1.000 - ETA: 1s - loss: 5.1211e-05 - acc: 1.000 - ETA: 1s - loss: 5.6608e-05 - acc: 1.000 - ETA: 1s - loss: 5.6924e-05 - acc: 1.000 - ETA: 1s - loss: 5.8109e-05 - acc: 1.000 - ETA: 1s - loss: 5.9791e-05 - acc: 1.000 - ETA: 1s - loss: 5.8165e-05 - acc: 1.000 - ETA: 0s - loss: 5.6837e-05 - acc: 1.000 - ETA: 0s - loss: 5.4735e-05 - acc: 1.000 - ETA: 0s - loss: 5.2861e-05 - acc: 1.000 - ETA: 0s - loss: 5.1507e-05 - acc: 1.000 - ETA: 0s - loss: 5.1132e-05 - acc: 1.000 - ETA: 0s - loss: 5.0795e-05 - acc: 1.000 - ETA: 0s - loss: 4.9207e-05 - acc: 1.000 - ETA: 0s - loss: 4.7994e-05 - acc: 1.000 - 4s 135ms/step - loss: 4.6864e-05 - acc: 1.0000 - val_loss: 6.1464 - val_acc: 0.7969\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 1.1632e-05 - acc: 1.000 - ETA: 4s - loss: 7.8769e-06 - acc: 1.000 - ETA: 4s - loss: 6.5871e-06 - acc: 1.000 - ETA: 3s - loss: 6.3701e-06 - acc: 1.000 - ETA: 3s - loss: 8.8096e-06 - acc: 1.000 - ETA: 3s - loss: 1.2218e-05 - acc: 1.000 - ETA: 3s - loss: 1.1720e-05 - acc: 1.000 - ETA: 3s - loss: 1.1926e-05 - acc: 1.000 - ETA: 3s - loss: 1.0972e-05 - acc: 1.000 - ETA: 2s - loss: 1.2558e-05 - acc: 1.000 - ETA: 2s - loss: 1.1438e-05 - acc: 1.000 - ETA: 2s - loss: 1.0996e-05 - acc: 1.000 - ETA: 2s - loss: 1.0926e-05 - acc: 1.000 - ETA: 2s - loss: 1.0224e-05 - acc: 1.000 - ETA: 1s - loss: 9.9409e-06 - acc: 1.000 - ETA: 1s - loss: 9.5191e-06 - acc: 1.000 - ETA: 1s - loss: 9.9645e-06 - acc: 1.000 - ETA: 1s - loss: 9.5317e-06 - acc: 1.000 - ETA: 1s - loss: 9.0893e-06 - acc: 1.000 - ETA: 1s - loss: 8.7263e-06 - acc: 1.000 - ETA: 1s - loss: 8.8855e-06 - acc: 1.000 - ETA: 1s - loss: 8.7312e-06 - acc: 1.000 - ETA: 1s - loss: 8.6337e-06 - acc: 1.000 - ETA: 0s - loss: 8.3511e-06 - acc: 1.000 - ETA: 0s - loss: 8.0625e-06 - acc: 1.000 - ETA: 0s - loss: 7.9470e-06 - acc: 1.000 - ETA: 0s - loss: 7.8527e-06 - acc: 1.000 - ETA: 0s - loss: 7.5958e-06 - acc: 1.000 - ETA: 0s - loss: 7.3458e-06 - acc: 1.000 - ETA: 0s - loss: 7.3116e-06 - acc: 1.000 - ETA: 0s - loss: 7.1371e-06 - acc: 1.000 - 4s 135ms/step - loss: 6.9432e-06 - acc: 1.0000 - val_loss: 7.1128 - val_acc: 0.7812\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 1.3240e-06 - acc: 1.000 - ETA: 4s - loss: 1.8893e-06 - acc: 1.000 - ETA: 4s - loss: 1.8127e-06 - acc: 1.000 - ETA: 3s - loss: 2.1545e-06 - acc: 1.000 - ETA: 3s - loss: 1.7924e-06 - acc: 1.000 - ETA: 3s - loss: 1.7102e-06 - acc: 1.000 - ETA: 3s - loss: 1.5107e-06 - acc: 1.000 - ETA: 3s - loss: 1.4567e-06 - acc: 1.000 - ETA: 3s - loss: 1.3011e-06 - acc: 1.000 - ETA: 2s - loss: 1.3249e-06 - acc: 1.000 - ETA: 2s - loss: 1.2372e-06 - acc: 1.000 - ETA: 2s - loss: 1.1929e-06 - acc: 1.000 - ETA: 2s - loss: 1.1769e-06 - acc: 1.000 - ETA: 2s - loss: 1.3085e-06 - acc: 1.000 - ETA: 2s - loss: 1.2481e-06 - acc: 1.000 - ETA: 2s - loss: 1.2017e-06 - acc: 1.000 - ETA: 1s - loss: 1.1668e-06 - acc: 1.000 - ETA: 1s - loss: 1.1032e-06 - acc: 1.000 - ETA: 1s - loss: 1.0480e-06 - acc: 1.000 - ETA: 1s - loss: 1.0034e-06 - acc: 1.000 - ETA: 1s - loss: 9.7375e-07 - acc: 1.000 - ETA: 1s - loss: 1.2974e-06 - acc: 1.000 - ETA: 1s - loss: 9.4176e-05 - acc: 1.000 - ETA: 1s - loss: 0.0231 - acc: 0.9987    - ETA: 0s - loss: 3.1810 - acc: 0.976 - ETA: 0s - loss: 3.0599 - acc: 0.976 - ETA: 0s - loss: 2.9468 - acc: 0.976 - ETA: 0s - loss: 2.8423 - acc: 0.977 - ETA: 0s - loss: 2.6528 - acc: 0.978 - ETA: 0s - loss: 2.5676 - acc: 0.979 - ETA: 0s - loss: 2.4894 - acc: 0.978 - 4s 135ms/step - loss: 2.4190 - acc: 0.9786 - val_loss: 5.0605 - val_acc: 0.8164\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0088 - acc: 1.000 - ETA: 2s - loss: 0.0032 - acc: 1.000 - ETA: 3s - loss: 0.0025 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 2s - loss: 0.0017 - acc: 1.000 - ETA: 2s - loss: 0.0015 - acc: 1.000 - ETA: 2s - loss: 0.0016 - acc: 1.000 - ETA: 2s - loss: 0.0014 - acc: 1.000 - ETA: 2s - loss: 0.0014 - acc: 1.000 - ETA: 2s - loss: 0.0014 - acc: 1.000 - ETA: 2s - loss: 0.0012 - acc: 1.000 - ETA: 2s - loss: 0.0012 - acc: 1.000 - ETA: 2s - loss: 0.0011 - acc: 1.000 - ETA: 2s - loss: 0.0010 - acc: 1.000 - ETA: 1s - loss: 9.8381e-04 - acc: 1.000 - ETA: 1s - loss: 9.3070e-04 - acc: 1.000 - ETA: 1s - loss: 8.7949e-04 - acc: 1.000 - ETA: 1s - loss: 8.3998e-04 - acc: 1.000 - ETA: 1s - loss: 7.9865e-04 - acc: 1.000 - ETA: 1s - loss: 7.6462e-04 - acc: 1.000 - ETA: 1s - loss: 7.3938e-04 - acc: 1.000 - ETA: 1s - loss: 7.0744e-04 - acc: 1.000 - ETA: 1s - loss: 6.8287e-04 - acc: 1.000 - ETA: 0s - loss: 6.5938e-04 - acc: 1.000 - ETA: 0s - loss: 6.3447e-04 - acc: 1.000 - ETA: 0s - loss: 7.5139e-04 - acc: 1.000 - ETA: 0s - loss: 7.6961e-04 - acc: 1.000 - ETA: 0s - loss: 7.4362e-04 - acc: 1.000 - ETA: 0s - loss: 7.1926e-04 - acc: 1.000 - ETA: 0s - loss: 6.9747e-04 - acc: 1.000 - ETA: 0s - loss: 6.7605e-04 - acc: 1.000 - 5s 144ms/step - loss: 6.8371e-04 - acc: 1.0000 - val_loss: 4.4619 - val_acc: 0.8516\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 5.8971e-06 - acc: 1.000 - ETA: 4s - loss: 1.1952e-05 - acc: 1.000 - ETA: 4s - loss: 1.0189e-05 - acc: 1.000 - ETA: 3s - loss: 8.0216e-06 - acc: 1.000 - ETA: 3s - loss: 7.3123e-06 - acc: 1.000 - ETA: 3s - loss: 7.6905e-06 - acc: 1.000 - ETA: 3s - loss: 9.1431e-06 - acc: 1.000 - ETA: 3s - loss: 9.8284e-06 - acc: 1.000 - ETA: 3s - loss: 8.7968e-06 - acc: 1.000 - ETA: 2s - loss: 7.5006e-06 - acc: 1.000 - ETA: 2s - loss: 7.9127e-06 - acc: 1.000 - ETA: 2s - loss: 1.6489e-05 - acc: 1.000 - ETA: 2s - loss: 1.5532e-05 - acc: 1.000 - ETA: 2s - loss: 1.5335e-05 - acc: 1.000 - ETA: 1s - loss: 1.4683e-05 - acc: 1.000 - ETA: 1s - loss: 1.4439e-05 - acc: 1.000 - ETA: 1s - loss: 1.5455e-05 - acc: 1.000 - ETA: 1s - loss: 1.4831e-05 - acc: 1.000 - ETA: 1s - loss: 1.4098e-05 - acc: 1.000 - ETA: 1s - loss: 1.6780e-05 - acc: 1.000 - ETA: 1s - loss: 1.7853e-05 - acc: 1.000 - ETA: 1s - loss: 1.7140e-05 - acc: 1.000 - ETA: 1s - loss: 1.6846e-05 - acc: 1.000 - ETA: 0s - loss: 1.6817e-05 - acc: 1.000 - ETA: 0s - loss: 1.6243e-05 - acc: 1.000 - ETA: 0s - loss: 3.5517e-05 - acc: 1.000 - ETA: 0s - loss: 1.2657e-04 - acc: 1.000 - ETA: 0s - loss: 1.2221e-04 - acc: 1.000 - ETA: 0s - loss: 1.1822e-04 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 0.9990    - ETA: 0s - loss: 0.1029 - acc: 0.991 - 5s 144ms/step - loss: 0.1098 - acc: 0.9883 - val_loss: 1.8993 - val_acc: 0.8945\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0171 - acc: 1.000 - ETA: 4s - loss: 0.0510 - acc: 0.984 - ETA: 4s - loss: 0.0424 - acc: 0.979 - ETA: 3s - loss: 0.0321 - acc: 0.984 - ETA: 3s - loss: 0.0279 - acc: 0.987 - ETA: 3s - loss: 0.0247 - acc: 0.989 - ETA: 3s - loss: 0.0214 - acc: 0.991 - ETA: 3s - loss: 0.0187 - acc: 0.992 - ETA: 3s - loss: 0.0167 - acc: 0.993 - ETA: 2s - loss: 0.0150 - acc: 0.993 - ETA: 2s - loss: 0.0137 - acc: 0.994 - ETA: 2s - loss: 0.0126 - acc: 0.994 - ETA: 2s - loss: 0.0117 - acc: 0.995 - ETA: 2s - loss: 0.0109 - acc: 0.995 - ETA: 2s - loss: 0.0102 - acc: 0.995 - ETA: 2s - loss: 0.0095 - acc: 0.996 - ETA: 1s - loss: 0.0090 - acc: 0.996 - ETA: 1s - loss: 0.0085 - acc: 0.996 - ETA: 1s - loss: 0.0080 - acc: 0.996 - ETA: 1s - loss: 0.0077 - acc: 0.996 - ETA: 1s - loss: 0.0073 - acc: 0.997 - ETA: 1s - loss: 0.0070 - acc: 0.997 - ETA: 1s - loss: 0.0067 - acc: 0.997 - ETA: 1s - loss: 0.0064 - acc: 0.997 - ETA: 0s - loss: 0.0063 - acc: 0.997 - ETA: 0s - loss: 0.0068 - acc: 0.997 - ETA: 0s - loss: 0.0072 - acc: 0.997 - ETA: 0s - loss: 0.0070 - acc: 0.997 - ETA: 0s - loss: 0.0066 - acc: 0.997 - ETA: 0s - loss: 0.0064 - acc: 0.997 - ETA: 0s - loss: 0.0069 - acc: 0.998 - 4s 135ms/step - loss: 0.0101 - acc: 0.9971 - val_loss: 24.5920 - val_acc: 0.6602\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 15</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.89453125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 352)               6899552   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 353       \n",
      "=================================================================\n",
      "Total params: 6,918,865\n",
      "Trainable params: 6,918,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/15\n",
      "33/33 [==============================] - ETA: 19s - loss: 0.6696 - acc: 0.59 - ETA: 11s - loss: 14.1002 - acc: 0.515 - ETA: 8s - loss: 11.1931 - acc: 0.520 - ETA: 7s - loss: 8.5913 - acc: 0.5078 - ETA: 6s - loss: 7.0221 - acc: 0.493 - ETA: 5s - loss: 5.9616 - acc: 0.520 - ETA: 4s - loss: 5.2044 - acc: 0.513 - ETA: 4s - loss: 4.6260 - acc: 0.546 - ETA: 4s - loss: 4.1804 - acc: 0.566 - ETA: 3s - loss: 3.8494 - acc: 0.556 - ETA: 3s - loss: 3.5551 - acc: 0.593 - ETA: 3s - loss: 3.3023 - acc: 0.609 - ETA: 3s - loss: 3.0930 - acc: 0.625 - ETA: 2s - loss: 2.9024 - acc: 0.640 - ETA: 2s - loss: 2.7438 - acc: 0.639 - ETA: 2s - loss: 2.6020 - acc: 0.646 - ETA: 2s - loss: 2.4673 - acc: 0.656 - ETA: 2s - loss: 2.3524 - acc: 0.666 - ETA: 2s - loss: 2.2448 - acc: 0.676 - ETA: 1s - loss: 2.2718 - acc: 0.665 - ETA: 1s - loss: 2.2011 - acc: 0.653 - ETA: 1s - loss: 2.1598 - acc: 0.647 - ETA: 1s - loss: 2.0876 - acc: 0.661 - ETA: 1s - loss: 2.0234 - acc: 0.662 - ETA: 1s - loss: 1.9610 - acc: 0.675 - ETA: 0s - loss: 1.8311 - acc: 0.687 - ETA: 0s - loss: 1.7768 - acc: 0.693 - ETA: 0s - loss: 1.7271 - acc: 0.699 - ETA: 0s - loss: 1.6754 - acc: 0.707 - ETA: 0s - loss: 1.6343 - acc: 0.711 - ETA: 0s - loss: 1.5979 - acc: 0.714 - 5s 154ms/step - loss: 1.5555 - acc: 0.7225 - val_loss: 1.1801 - val_acc: 0.7734\n",
      "Epoch 2/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0968 - acc: 0.937 - ETA: 3s - loss: 0.0645 - acc: 0.970 - ETA: 3s - loss: 0.3787 - acc: 0.828 - ETA: 3s - loss: 0.6127 - acc: 0.740 - ETA: 2s - loss: 0.5732 - acc: 0.773 - ETA: 2s - loss: 0.5461 - acc: 0.789 - ETA: 2s - loss: 0.5272 - acc: 0.806 - ETA: 2s - loss: 0.4980 - acc: 0.826 - ETA: 2s - loss: 0.4666 - acc: 0.841 - ETA: 2s - loss: 0.4527 - acc: 0.835 - ETA: 2s - loss: 0.4430 - acc: 0.839 - ETA: 2s - loss: 0.4745 - acc: 0.824 - ETA: 2s - loss: 0.4879 - acc: 0.823 - ETA: 2s - loss: 0.4640 - acc: 0.831 - ETA: 1s - loss: 0.4605 - acc: 0.826 - ETA: 1s - loss: 0.4387 - acc: 0.836 - ETA: 1s - loss: 0.4192 - acc: 0.842 - ETA: 1s - loss: 0.4017 - acc: 0.848 - ETA: 1s - loss: 0.3916 - acc: 0.849 - ETA: 1s - loss: 0.3782 - acc: 0.856 - ETA: 1s - loss: 0.3636 - acc: 0.862 - ETA: 1s - loss: 0.3525 - acc: 0.865 - ETA: 1s - loss: 0.3461 - acc: 0.868 - ETA: 0s - loss: 0.3436 - acc: 0.872 - ETA: 0s - loss: 0.3393 - acc: 0.874 - ETA: 0s - loss: 0.3299 - acc: 0.879 - ETA: 0s - loss: 0.3216 - acc: 0.882 - ETA: 0s - loss: 0.3136 - acc: 0.884 - ETA: 0s - loss: 0.3056 - acc: 0.887 - ETA: 0s - loss: 0.3026 - acc: 0.887 - ETA: 0s - loss: 0.2973 - acc: 0.890 - 4s 135ms/step - loss: 0.2920 - acc: 0.8929 - val_loss: 2.4119 - val_acc: 0.7500\n",
      "Epoch 3/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.1309 - acc: 0.968 - ETA: 4s - loss: 0.4508 - acc: 0.796 - ETA: 4s - loss: 0.7259 - acc: 0.791 - ETA: 3s - loss: 1.4508 - acc: 0.765 - ETA: 3s - loss: 1.2213 - acc: 0.775 - ETA: 2s - loss: 0.9183 - acc: 0.805 - ETA: 2s - loss: 0.8137 - acc: 0.832 - ETA: 2s - loss: 0.7366 - acc: 0.845 - ETA: 2s - loss: 0.6648 - acc: 0.862 - ETA: 2s - loss: 0.6057 - acc: 0.876 - ETA: 2s - loss: 0.5633 - acc: 0.887 - ETA: 2s - loss: 0.5383 - acc: 0.886 - ETA: 2s - loss: 0.5020 - acc: 0.895 - ETA: 2s - loss: 0.4712 - acc: 0.902 - ETA: 1s - loss: 0.4429 - acc: 0.908 - ETA: 1s - loss: 0.4171 - acc: 0.914 - ETA: 1s - loss: 0.3955 - acc: 0.917 - ETA: 1s - loss: 0.3969 - acc: 0.915 - ETA: 1s - loss: 0.4104 - acc: 0.908 - ETA: 1s - loss: 0.3967 - acc: 0.911 - ETA: 1s - loss: 0.3831 - acc: 0.914 - ETA: 1s - loss: 0.3713 - acc: 0.915 - ETA: 1s - loss: 0.3594 - acc: 0.918 - ETA: 0s - loss: 0.3514 - acc: 0.919 - ETA: 0s - loss: 0.3595 - acc: 0.911 - ETA: 0s - loss: 0.3558 - acc: 0.911 - ETA: 0s - loss: 0.3451 - acc: 0.913 - ETA: 0s - loss: 0.3411 - acc: 0.914 - ETA: 0s - loss: 0.3329 - acc: 0.916 - ETA: 0s - loss: 0.3242 - acc: 0.918 - ETA: 0s - loss: 0.3173 - acc: 0.919 - 4s 134ms/step - loss: 0.3168 - acc: 0.9192 - val_loss: 2.1750 - val_acc: 0.7266\n",
      "Epoch 4/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0404 - acc: 1.000 - ETA: 4s - loss: 0.0253 - acc: 1.000 - ETA: 4s - loss: 0.0353 - acc: 0.989 - ETA: 3s - loss: 0.0424 - acc: 0.984 - ETA: 3s - loss: 0.0379 - acc: 0.987 - ETA: 3s - loss: 0.0338 - acc: 0.989 - ETA: 3s - loss: 0.0335 - acc: 0.986 - ETA: 2s - loss: 0.0268 - acc: 0.988 - ETA: 2s - loss: 0.0251 - acc: 0.989 - ETA: 2s - loss: 0.0232 - acc: 0.990 - ETA: 2s - loss: 0.0226 - acc: 0.991 - ETA: 2s - loss: 0.0211 - acc: 0.992 - ETA: 2s - loss: 0.0212 - acc: 0.992 - ETA: 2s - loss: 0.0259 - acc: 0.988 - ETA: 1s - loss: 0.0255 - acc: 0.989 - ETA: 1s - loss: 0.0245 - acc: 0.990 - ETA: 1s - loss: 0.0234 - acc: 0.990 - ETA: 1s - loss: 0.0223 - acc: 0.991 - ETA: 1s - loss: 0.0244 - acc: 0.990 - ETA: 1s - loss: 0.0257 - acc: 0.989 - ETA: 1s - loss: 0.0275 - acc: 0.988 - ETA: 1s - loss: 0.0312 - acc: 0.985 - ETA: 1s - loss: 0.0483 - acc: 0.983 - ETA: 0s - loss: 0.0711 - acc: 0.979 - ETA: 0s - loss: 0.0725 - acc: 0.980 - ETA: 0s - loss: 0.0737 - acc: 0.979 - ETA: 0s - loss: 0.0721 - acc: 0.980 - ETA: 0s - loss: 0.0748 - acc: 0.978 - ETA: 0s - loss: 0.0774 - acc: 0.977 - ETA: 0s - loss: 0.0834 - acc: 0.976 - ETA: 0s - loss: 0.0829 - acc: 0.976 - 5s 138ms/step - loss: 0.0856 - acc: 0.9757 - val_loss: 0.9475 - val_acc: 0.8711\n",
      "Epoch 5/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.5832 - acc: 0.812 - ETA: 4s - loss: 0.3526 - acc: 0.875 - ETA: 4s - loss: 0.2445 - acc: 0.916 - ETA: 3s - loss: 0.1845 - acc: 0.937 - ETA: 3s - loss: 0.1821 - acc: 0.931 - ETA: 3s - loss: 0.4680 - acc: 0.895 - ETA: 3s - loss: 0.5026 - acc: 0.897 - ETA: 3s - loss: 7.2500 - acc: 0.851 - ETA: 3s - loss: 6.4574 - acc: 0.861 - ETA: 2s - loss: 5.8230 - acc: 0.868 - ETA: 2s - loss: 5.2975 - acc: 0.880 - ETA: 2s - loss: 4.8694 - acc: 0.885 - ETA: 2s - loss: 4.5086 - acc: 0.889 - ETA: 2s - loss: 4.1916 - acc: 0.895 - ETA: 2s - loss: 3.9150 - acc: 0.900 - ETA: 2s - loss: 3.6711 - acc: 0.906 - ETA: 1s - loss: 3.4576 - acc: 0.911 - ETA: 1s - loss: 3.2680 - acc: 0.914 - ETA: 1s - loss: 3.0983 - acc: 0.919 - ETA: 1s - loss: 2.9437 - acc: 0.923 - ETA: 1s - loss: 2.8046 - acc: 0.927 - ETA: 1s - loss: 2.5610 - acc: 0.930 - ETA: 1s - loss: 2.4551 - acc: 0.933 - ETA: 0s - loss: 2.3582 - acc: 0.936 - ETA: 0s - loss: 2.2689 - acc: 0.939 - ETA: 0s - loss: 2.1857 - acc: 0.941 - ETA: 0s - loss: 2.1078 - acc: 0.943 - ETA: 0s - loss: 2.0363 - acc: 0.944 - ETA: 0s - loss: 1.9693 - acc: 0.946 - ETA: 0s - loss: 1.9059 - acc: 0.948 - ETA: 0s - loss: 1.8477 - acc: 0.948 - 4s 135ms/step - loss: 1.7938 - acc: 0.9503 - val_loss: 3.2030 - val_acc: 0.7578\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0037 - acc: 1.000 - ETA: 4s - loss: 0.0270 - acc: 0.984 - ETA: 4s - loss: 0.0270 - acc: 0.989 - ETA: 3s - loss: 0.0208 - acc: 0.992 - ETA: 3s - loss: 0.0193 - acc: 0.993 - ETA: 3s - loss: 0.0170 - acc: 0.994 - ETA: 3s - loss: 0.0153 - acc: 0.995 - ETA: 3s - loss: 0.0137 - acc: 0.996 - ETA: 3s - loss: 0.0125 - acc: 0.996 - ETA: 2s - loss: 0.0138 - acc: 0.996 - ETA: 2s - loss: 0.0134 - acc: 0.997 - ETA: 2s - loss: 0.0129 - acc: 0.997 - ETA: 2s - loss: 0.0122 - acc: 0.997 - ETA: 2s - loss: 0.0119 - acc: 0.997 - ETA: 2s - loss: 0.0114 - acc: 0.997 - ETA: 2s - loss: 0.0107 - acc: 0.998 - ETA: 1s - loss: 0.0102 - acc: 0.998 - ETA: 1s - loss: 0.0097 - acc: 0.998 - ETA: 1s - loss: 0.0089 - acc: 0.998 - ETA: 1s - loss: 0.0085 - acc: 0.998 - ETA: 1s - loss: 0.0082 - acc: 0.998 - ETA: 1s - loss: 0.0079 - acc: 0.998 - ETA: 1s - loss: 0.0076 - acc: 0.998 - ETA: 0s - loss: 0.0076 - acc: 0.998 - ETA: 0s - loss: 0.0073 - acc: 0.998 - ETA: 0s - loss: 0.0071 - acc: 0.998 - ETA: 0s - loss: 0.0069 - acc: 0.998 - ETA: 0s - loss: 0.0067 - acc: 0.998 - ETA: 0s - loss: 0.0065 - acc: 0.998 - ETA: 0s - loss: 0.0064 - acc: 0.999 - ETA: 0s - loss: 0.0068 - acc: 0.999 - 4s 135ms/step - loss: 0.0352 - acc: 0.9942 - val_loss: 1.2140 - val_acc: 0.7109\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 2.7731 - acc: 0.500 - ETA: 4s - loss: 1.5999 - acc: 0.687 - ETA: 4s - loss: 1.0692 - acc: 0.791 - ETA: 3s - loss: 0.8025 - acc: 0.843 - ETA: 3s - loss: 0.6428 - acc: 0.875 - ETA: 3s - loss: 0.5383 - acc: 0.895 - ETA: 3s - loss: 0.4620 - acc: 0.910 - ETA: 3s - loss: 0.4047 - acc: 0.921 - ETA: 3s - loss: 0.3612 - acc: 0.930 - ETA: 2s - loss: 0.3278 - acc: 0.937 - ETA: 2s - loss: 0.2986 - acc: 0.943 - ETA: 2s - loss: 0.2742 - acc: 0.947 - ETA: 2s - loss: 0.2536 - acc: 0.951 - ETA: 2s - loss: 0.2391 - acc: 0.953 - ETA: 2s - loss: 0.3510 - acc: 0.937 - ETA: 2s - loss: 0.3474 - acc: 0.937 - ETA: 1s - loss: 0.3275 - acc: 0.941 - ETA: 1s - loss: 0.3258 - acc: 0.941 - ETA: 1s - loss: 0.3107 - acc: 0.944 - ETA: 1s - loss: 0.2980 - acc: 0.945 - ETA: 1s - loss: 0.2993 - acc: 0.940 - ETA: 1s - loss: 0.2871 - acc: 0.940 - ETA: 1s - loss: 0.2751 - acc: 0.943 - ETA: 0s - loss: 0.2641 - acc: 0.945 - ETA: 0s - loss: 0.2540 - acc: 0.947 - ETA: 0s - loss: 0.2446 - acc: 0.949 - ETA: 0s - loss: 0.2359 - acc: 0.951 - ETA: 0s - loss: 0.2284 - acc: 0.953 - ETA: 0s - loss: 0.2229 - acc: 0.953 - ETA: 0s - loss: 0.2157 - acc: 0.955 - ETA: 0s - loss: 0.2112 - acc: 0.955 - 4s 135ms/step - loss: 0.2050 - acc: 0.9572 - val_loss: 2.9798 - val_acc: 0.8242\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0168 - acc: 1.000 - ETA: 4s - loss: 0.0204 - acc: 1.000 - ETA: 4s - loss: 0.0139 - acc: 1.000 - ETA: 3s - loss: 0.0127 - acc: 1.000 - ETA: 3s - loss: 0.0102 - acc: 1.000 - ETA: 3s - loss: 0.0085 - acc: 1.000 - ETA: 3s - loss: 0.0074 - acc: 1.000 - ETA: 3s - loss: 0.0067 - acc: 1.000 - ETA: 2s - loss: 0.0059 - acc: 1.000 - ETA: 2s - loss: 0.0055 - acc: 1.000 - ETA: 2s - loss: 0.0050 - acc: 1.000 - ETA: 2s - loss: 0.0055 - acc: 1.000 - ETA: 2s - loss: 0.0048 - acc: 1.000 - ETA: 2s - loss: 0.0055 - acc: 1.000 - ETA: 1s - loss: 0.0176 - acc: 0.997 - ETA: 1s - loss: 0.0292 - acc: 0.994 - ETA: 1s - loss: 0.0300 - acc: 0.992 - ETA: 1s - loss: 0.2698 - acc: 0.968 - ETA: 1s - loss: 0.4714 - acc: 0.942 - ETA: 1s - loss: 0.4523 - acc: 0.944 - ETA: 1s - loss: 0.4353 - acc: 0.945 - ETA: 1s - loss: 0.4223 - acc: 0.946 - ETA: 1s - loss: 0.4096 - acc: 0.947 - ETA: 0s - loss: 0.3940 - acc: 0.949 - ETA: 0s - loss: 0.3828 - acc: 0.950 - ETA: 0s - loss: 0.3698 - acc: 0.952 - ETA: 0s - loss: 0.3582 - acc: 0.953 - ETA: 0s - loss: 0.3460 - acc: 0.955 - ETA: 0s - loss: 0.3348 - acc: 0.957 - ETA: 0s - loss: 0.3245 - acc: 0.958 - ETA: 0s - loss: 0.3146 - acc: 0.959 - 4s 135ms/step - loss: 0.3055 - acc: 0.9611 - val_loss: 2.5060 - val_acc: 0.7969\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0016 - acc: 1.000 - ETA: 4s - loss: 0.0065 - acc: 1.000 - ETA: 4s - loss: 0.0086 - acc: 1.000 - ETA: 3s - loss: 0.0073 - acc: 1.000 - ETA: 3s - loss: 0.0062 - acc: 1.000 - ETA: 3s - loss: 0.0077 - acc: 1.000 - ETA: 3s - loss: 0.0069 - acc: 1.000 - ETA: 3s - loss: 0.0064 - acc: 1.000 - ETA: 3s - loss: 0.0065 - acc: 1.000 - ETA: 2s - loss: 0.0059 - acc: 1.000 - ETA: 2s - loss: 0.0056 - acc: 1.000 - ETA: 2s - loss: 0.0053 - acc: 1.000 - ETA: 2s - loss: 0.0054 - acc: 1.000 - ETA: 2s - loss: 0.0052 - acc: 1.000 - ETA: 2s - loss: 0.0049 - acc: 1.000 - ETA: 2s - loss: 0.0046 - acc: 1.000 - ETA: 1s - loss: 0.0045 - acc: 1.000 - ETA: 1s - loss: 0.0043 - acc: 1.000 - ETA: 1s - loss: 0.0044 - acc: 1.000 - ETA: 1s - loss: 0.0043 - acc: 1.000 - ETA: 1s - loss: 0.0041 - acc: 1.000 - ETA: 1s - loss: 0.0039 - acc: 1.000 - ETA: 1s - loss: 0.0038 - acc: 1.000 - ETA: 1s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0033 - acc: 1.000 - ETA: 0s - loss: 0.0031 - acc: 1.000 - ETA: 0s - loss: 0.0031 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - 4s 135ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 4.2412 - val_acc: 0.7656\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0013 - acc: 1.000 - ETA: 4s - loss: 7.1785e-04 - acc: 1.000 - ETA: 4s - loss: 0.0011 - acc: 1.0000    - ETA: 3s - loss: 8.4889e-04 - acc: 1.000 - ETA: 3s - loss: 7.2740e-04 - acc: 1.000 - ETA: 3s - loss: 7.0019e-04 - acc: 1.000 - ETA: 3s - loss: 6.1552e-04 - acc: 1.000 - ETA: 3s - loss: 5.4206e-04 - acc: 1.000 - ETA: 3s - loss: 5.0920e-04 - acc: 1.000 - ETA: 2s - loss: 4.6246e-04 - acc: 1.000 - ETA: 2s - loss: 4.4172e-04 - acc: 1.000 - ETA: 2s - loss: 4.2612e-04 - acc: 1.000 - ETA: 2s - loss: 4.1407e-04 - acc: 1.000 - ETA: 2s - loss: 3.9587e-04 - acc: 1.000 - ETA: 2s - loss: 3.7372e-04 - acc: 1.000 - ETA: 2s - loss: 3.6499e-04 - acc: 1.000 - ETA: 1s - loss: 3.5807e-04 - acc: 1.000 - ETA: 1s - loss: 3.7034e-04 - acc: 1.000 - ETA: 1s - loss: 8.3649e-04 - acc: 1.000 - ETA: 1s - loss: 0.3756 - acc: 0.9797    - ETA: 1s - loss: 0.4454 - acc: 0.974 - ETA: 1s - loss: 0.4252 - acc: 0.975 - ETA: 1s - loss: 0.4067 - acc: 0.976 - ETA: 1s - loss: 0.3898 - acc: 0.977 - ETA: 0s - loss: 0.3742 - acc: 0.978 - ETA: 0s - loss: 0.3598 - acc: 0.979 - ETA: 0s - loss: 0.3465 - acc: 0.980 - ETA: 0s - loss: 0.3342 - acc: 0.981 - ETA: 0s - loss: 0.3227 - acc: 0.981 - ETA: 0s - loss: 0.3173 - acc: 0.981 - ETA: 0s - loss: 0.3814 - acc: 0.974 - 5s 139ms/step - loss: 0.3672 - acc: 0.9747 - val_loss: 2.5936 - val_acc: 0.8828\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.2355 - acc: 0.937 - ETA: 4s - loss: 0.1195 - acc: 0.968 - ETA: 4s - loss: 0.1306 - acc: 0.968 - ETA: 3s - loss: 0.0989 - acc: 0.976 - ETA: 3s - loss: 0.0791 - acc: 0.981 - ETA: 3s - loss: 0.0660 - acc: 0.984 - ETA: 3s - loss: 0.0565 - acc: 0.986 - ETA: 3s - loss: 0.0495 - acc: 0.988 - ETA: 3s - loss: 0.0440 - acc: 0.989 - ETA: 2s - loss: 0.0360 - acc: 0.990 - ETA: 2s - loss: 0.0330 - acc: 0.991 - ETA: 2s - loss: 0.0506 - acc: 0.989 - ETA: 2s - loss: 0.4585 - acc: 0.976 - ETA: 2s - loss: 0.5093 - acc: 0.966 - ETA: 1s - loss: 0.4775 - acc: 0.968 - ETA: 1s - loss: 0.4517 - acc: 0.968 - ETA: 1s - loss: 0.4288 - acc: 0.968 - ETA: 1s - loss: 0.4105 - acc: 0.968 - ETA: 1s - loss: 0.3900 - acc: 0.970 - ETA: 1s - loss: 0.3714 - acc: 0.972 - ETA: 1s - loss: 0.3545 - acc: 0.973 - ETA: 1s - loss: 0.3448 - acc: 0.973 - ETA: 1s - loss: 0.3304 - acc: 0.974 - ETA: 0s - loss: 0.3172 - acc: 0.975 - ETA: 0s - loss: 0.3050 - acc: 0.976 - ETA: 0s - loss: 0.2937 - acc: 0.977 - ETA: 0s - loss: 0.2834 - acc: 0.978 - ETA: 0s - loss: 0.2736 - acc: 0.978 - ETA: 0s - loss: 0.2645 - acc: 0.979 - ETA: 0s - loss: 0.2560 - acc: 0.980 - ETA: 0s - loss: 0.2480 - acc: 0.980 - 4s 135ms/step - loss: 0.2407 - acc: 0.9815 - val_loss: 5.7348 - val_acc: 0.7734\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 8.7421e-06 - acc: 1.000 - ETA: 4s - loss: 4.6098e-04 - acc: 1.000 - ETA: 4s - loss: 3.2921e-04 - acc: 1.000 - ETA: 3s - loss: 3.6243e-04 - acc: 1.000 - ETA: 3s - loss: 3.3051e-04 - acc: 1.000 - ETA: 3s - loss: 2.8538e-04 - acc: 1.000 - ETA: 3s - loss: 2.5600e-04 - acc: 1.000 - ETA: 3s - loss: 2.3393e-04 - acc: 1.000 - ETA: 3s - loss: 2.1486e-04 - acc: 1.000 - ETA: 2s - loss: 6.1915e-04 - acc: 1.000 - ETA: 2s - loss: 5.6339e-04 - acc: 1.000 - ETA: 2s - loss: 6.3835e-04 - acc: 1.000 - ETA: 2s - loss: 5.9227e-04 - acc: 1.000 - ETA: 2s - loss: 5.5019e-04 - acc: 1.000 - ETA: 2s - loss: 5.1643e-04 - acc: 1.000 - ETA: 2s - loss: 4.8930e-04 - acc: 1.000 - ETA: 1s - loss: 4.6672e-04 - acc: 1.000 - ETA: 1s - loss: 4.4123e-04 - acc: 1.000 - ETA: 1s - loss: 4.2219e-04 - acc: 1.000 - ETA: 1s - loss: 4.0162e-04 - acc: 1.000 - ETA: 1s - loss: 3.9017e-04 - acc: 1.000 - ETA: 1s - loss: 3.7262e-04 - acc: 1.000 - ETA: 1s - loss: 3.5724e-04 - acc: 1.000 - ETA: 0s - loss: 3.3100e-04 - acc: 1.000 - ETA: 0s - loss: 3.2474e-04 - acc: 1.000 - ETA: 0s - loss: 3.1527e-04 - acc: 1.000 - ETA: 0s - loss: 3.0401e-04 - acc: 1.000 - ETA: 0s - loss: 2.9358e-04 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 0.9989    - ETA: 0s - loss: 0.0233 - acc: 0.995 - ETA: 0s - loss: 0.0494 - acc: 0.992 - 4s 135ms/step - loss: 0.1134 - acc: 0.9873 - val_loss: 11.2781 - val_acc: 0.6836\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.4870 - acc: 0.843 - ETA: 4s - loss: 0.2515 - acc: 0.921 - ETA: 4s - loss: 0.1977 - acc: 0.937 - ETA: 3s - loss: 0.1483 - acc: 0.953 - ETA: 3s - loss: 0.1202 - acc: 0.962 - ETA: 3s - loss: 0.1002 - acc: 0.968 - ETA: 3s - loss: 0.0860 - acc: 0.973 - ETA: 3s - loss: 0.0753 - acc: 0.976 - ETA: 3s - loss: 0.0672 - acc: 0.979 - ETA: 2s - loss: 0.0605 - acc: 0.981 - ETA: 2s - loss: 0.0567 - acc: 0.983 - ETA: 2s - loss: 0.0520 - acc: 0.984 - ETA: 2s - loss: 0.0480 - acc: 0.985 - ETA: 2s - loss: 0.0448 - acc: 0.986 - ETA: 2s - loss: 0.0418 - acc: 0.987 - ETA: 2s - loss: 0.0392 - acc: 0.988 - ETA: 1s - loss: 0.0369 - acc: 0.989 - ETA: 1s - loss: 0.0349 - acc: 0.989 - ETA: 1s - loss: 0.0331 - acc: 0.990 - ETA: 1s - loss: 0.0314 - acc: 0.990 - ETA: 1s - loss: 0.0299 - acc: 0.991 - ETA: 1s - loss: 0.0286 - acc: 0.991 - ETA: 1s - loss: 0.0262 - acc: 0.991 - ETA: 0s - loss: 0.0252 - acc: 0.992 - ETA: 0s - loss: 0.0242 - acc: 0.992 - ETA: 0s - loss: 0.0233 - acc: 0.992 - ETA: 0s - loss: 0.0225 - acc: 0.993 - ETA: 0s - loss: 0.0217 - acc: 0.993 - ETA: 0s - loss: 0.0210 - acc: 0.993 - ETA: 0s - loss: 0.0203 - acc: 0.993 - ETA: 0s - loss: 0.0197 - acc: 0.994 - 4s 135ms/step - loss: 0.0191 - acc: 0.9942 - val_loss: 4.1250 - val_acc: 0.8633\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 3.0414e-06 - acc: 1.000 - ETA: 4s - loss: 1.0461e-04 - acc: 1.000 - ETA: 4s - loss: 8.2654e-05 - acc: 1.000 - ETA: 3s - loss: 6.7320e-05 - acc: 1.000 - ETA: 3s - loss: 8.9224e-05 - acc: 1.000 - ETA: 3s - loss: 9.8311e-05 - acc: 1.000 - ETA: 3s - loss: 8.5784e-05 - acc: 1.000 - ETA: 3s - loss: 7.6139e-05 - acc: 1.000 - ETA: 3s - loss: 6.8304e-05 - acc: 1.000 - ETA: 2s - loss: 8.9334e-05 - acc: 1.000 - ETA: 2s - loss: 8.3105e-05 - acc: 1.000 - ETA: 2s - loss: 7.6446e-05 - acc: 1.000 - ETA: 2s - loss: 7.6088e-05 - acc: 1.000 - ETA: 2s - loss: 7.0778e-05 - acc: 1.000 - ETA: 2s - loss: 6.6564e-05 - acc: 1.000 - ETA: 2s - loss: 6.3069e-05 - acc: 1.000 - ETA: 1s - loss: 7.8067e-05 - acc: 1.000 - ETA: 1s - loss: 7.6872e-05 - acc: 1.000 - ETA: 1s - loss: 7.3051e-05 - acc: 1.000 - ETA: 1s - loss: 7.0186e-05 - acc: 1.000 - ETA: 1s - loss: 6.8622e-05 - acc: 1.000 - ETA: 1s - loss: 6.6122e-05 - acc: 1.000 - ETA: 1s - loss: 6.3386e-05 - acc: 1.000 - ETA: 1s - loss: 6.1623e-05 - acc: 1.000 - ETA: 0s - loss: 6.2698e-05 - acc: 1.000 - ETA: 0s - loss: 6.1257e-05 - acc: 1.000 - ETA: 0s - loss: 6.0816e-05 - acc: 1.000 - ETA: 0s - loss: 5.8829e-05 - acc: 1.000 - ETA: 0s - loss: 5.5392e-05 - acc: 1.000 - ETA: 0s - loss: 5.3799e-05 - acc: 1.000 - ETA: 0s - loss: 5.2211e-05 - acc: 1.000 - 4s 135ms/step - loss: 5.2593e-05 - acc: 1.0000 - val_loss: 4.5729 - val_acc: 0.8594\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 2.9545e-05 - acc: 1.000 - ETA: 4s - loss: 1.8085e-05 - acc: 1.000 - ETA: 4s - loss: 1.3740e-05 - acc: 1.000 - ETA: 3s - loss: 1.9425e-05 - acc: 1.000 - ETA: 3s - loss: 1.7083e-05 - acc: 1.000 - ETA: 3s - loss: 1.4966e-05 - acc: 1.000 - ETA: 3s - loss: 1.4021e-05 - acc: 1.000 - ETA: 3s - loss: 1.2485e-05 - acc: 1.000 - ETA: 3s - loss: 1.2918e-05 - acc: 1.000 - ETA: 2s - loss: 1.4863e-05 - acc: 1.000 - ETA: 2s - loss: 1.9891e-05 - acc: 1.000 - ETA: 2s - loss: 1.9077e-05 - acc: 1.000 - ETA: 2s - loss: 1.8251e-05 - acc: 1.000 - ETA: 2s - loss: 1.7061e-05 - acc: 1.000 - ETA: 2s - loss: 1.8146e-05 - acc: 1.000 - ETA: 2s - loss: 1.7566e-05 - acc: 1.000 - ETA: 1s - loss: 1.6574e-05 - acc: 1.000 - ETA: 1s - loss: 1.8512e-05 - acc: 1.000 - ETA: 1s - loss: 2.1085e-05 - acc: 1.000 - ETA: 1s - loss: 2.1434e-05 - acc: 1.000 - ETA: 1s - loss: 2.0504e-05 - acc: 1.000 - ETA: 1s - loss: 1.9867e-05 - acc: 1.000 - ETA: 1s - loss: 1.9319e-05 - acc: 1.000 - ETA: 1s - loss: 1.9696e-05 - acc: 1.000 - ETA: 0s - loss: 1.8995e-05 - acc: 1.000 - ETA: 0s - loss: 1.7887e-05 - acc: 1.000 - ETA: 0s - loss: 1.7370e-05 - acc: 1.000 - ETA: 0s - loss: 1.7264e-05 - acc: 1.000 - ETA: 0s - loss: 1.6696e-05 - acc: 1.000 - ETA: 0s - loss: 1.6290e-05 - acc: 1.000 - ETA: 0s - loss: 1.6174e-05 - acc: 1.000 - 4s 135ms/step - loss: 1.6579e-05 - acc: 1.0000 - val_loss: 4.5959 - val_acc: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 352</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 15</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8828125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 352)               27597152  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 353       \n",
      "=================================================================\n",
      "Total params: 27,673,153\n",
      "Trainable params: 27,673,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/15\n",
      "33/33 [==============================] - ETA: 21s - loss: 0.6922 - acc: 0.56 - ETA: 12s - loss: 31.3657 - acc: 0.546 - ETA: 9s - loss: 22.3867 - acc: 0.479 - ETA: 7s - loss: 16.9587 - acc: 0.52 - ETA: 6s - loss: 13.6909 - acc: 0.53 - ETA: 5s - loss: 11.6984 - acc: 0.54 - ETA: 4s - loss: 9.5492 - acc: 0.5463 - ETA: 4s - loss: 8.5583 - acc: 0.544 - ETA: 3s - loss: 7.7755 - acc: 0.549 - ETA: 3s - loss: 7.1229 - acc: 0.566 - ETA: 3s - loss: 6.5812 - acc: 0.571 - ETA: 3s - loss: 6.1266 - acc: 0.565 - ETA: 2s - loss: 5.7343 - acc: 0.563 - ETA: 2s - loss: 5.3849 - acc: 0.583 - ETA: 2s - loss: 5.1689 - acc: 0.569 - ETA: 2s - loss: 4.9296 - acc: 0.567 - ETA: 2s - loss: 4.6951 - acc: 0.563 - ETA: 2s - loss: 4.4723 - acc: 0.575 - ETA: 1s - loss: 4.2729 - acc: 0.579 - ETA: 1s - loss: 4.0862 - acc: 0.598 - ETA: 1s - loss: 3.9316 - acc: 0.601 - ETA: 1s - loss: 3.8492 - acc: 0.592 - ETA: 1s - loss: 3.7147 - acc: 0.599 - ETA: 1s - loss: 3.5914 - acc: 0.595 - ETA: 0s - loss: 3.4749 - acc: 0.605 - ETA: 0s - loss: 3.3654 - acc: 0.609 - ETA: 0s - loss: 3.2683 - acc: 0.609 - ETA: 0s - loss: 3.1731 - acc: 0.612 - ETA: 0s - loss: 3.0766 - acc: 0.624 - ETA: 0s - loss: 2.9832 - acc: 0.632 - ETA: 0s - loss: 2.8975 - acc: 0.642 - 5s 164ms/step - loss: 3.0320 - acc: 0.6349 - val_loss: 3.9505 - val_acc: 0.5000\n",
      "Epoch 2/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 2.2287 - acc: 0.468 - ETA: 5s - loss: 1.3879 - acc: 0.640 - ETA: 4s - loss: 1.1111 - acc: 0.750 - ETA: 4s - loss: 0.9871 - acc: 0.710 - ETA: 3s - loss: 0.8905 - acc: 0.756 - ETA: 3s - loss: 0.8260 - acc: 0.760 - ETA: 3s - loss: 0.7703 - acc: 0.772 - ETA: 3s - loss: 0.7317 - acc: 0.765 - ETA: 3s - loss: 0.6910 - acc: 0.784 - ETA: 2s - loss: 0.6493 - acc: 0.803 - ETA: 2s - loss: 0.6223 - acc: 0.804 - ETA: 2s - loss: 0.6174 - acc: 0.794 - ETA: 2s - loss: 0.5958 - acc: 0.795 - ETA: 2s - loss: 0.5688 - acc: 0.810 - ETA: 2s - loss: 0.5422 - acc: 0.820 - ETA: 2s - loss: 0.5381 - acc: 0.820 - ETA: 2s - loss: 0.5469 - acc: 0.819 - ETA: 1s - loss: 0.5304 - acc: 0.824 - ETA: 1s - loss: 0.5136 - acc: 0.830 - ETA: 1s - loss: 0.5044 - acc: 0.829 - ETA: 1s - loss: 0.5001 - acc: 0.830 - ETA: 1s - loss: 0.4830 - acc: 0.836 - ETA: 1s - loss: 0.4643 - acc: 0.842 - ETA: 1s - loss: 0.4481 - acc: 0.849 - ETA: 0s - loss: 0.4310 - acc: 0.855 - ETA: 0s - loss: 0.4033 - acc: 0.859 - ETA: 0s - loss: 0.5685 - acc: 0.845 - ETA: 0s - loss: 0.6351 - acc: 0.833 - ETA: 0s - loss: 0.6240 - acc: 0.835 - ETA: 0s - loss: 0.6109 - acc: 0.840 - ETA: 0s - loss: 0.6019 - acc: 0.841 - 5s 150ms/step - loss: 0.5857 - acc: 0.8462 - val_loss: 1.6882 - val_acc: 0.7773\n",
      "Epoch 3/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.1530 - acc: 0.968 - ETA: 5s - loss: 0.2242 - acc: 0.906 - ETA: 4s - loss: 0.2265 - acc: 0.916 - ETA: 4s - loss: 0.2074 - acc: 0.929 - ETA: 3s - loss: 0.1727 - acc: 0.943 - ETA: 3s - loss: 0.1510 - acc: 0.953 - ETA: 3s - loss: 0.1326 - acc: 0.959 - ETA: 3s - loss: 0.1350 - acc: 0.953 - ETA: 3s - loss: 0.1268 - acc: 0.958 - ETA: 3s - loss: 0.1175 - acc: 0.959 - ETA: 2s - loss: 0.1164 - acc: 0.957 - ETA: 2s - loss: 0.1123 - acc: 0.958 - ETA: 2s - loss: 0.1244 - acc: 0.956 - ETA: 2s - loss: 0.1209 - acc: 0.959 - ETA: 2s - loss: 0.1219 - acc: 0.960 - ETA: 1s - loss: 0.1105 - acc: 0.963 - ETA: 1s - loss: 0.1112 - acc: 0.963 - ETA: 1s - loss: 0.1113 - acc: 0.963 - ETA: 1s - loss: 0.1205 - acc: 0.959 - ETA: 1s - loss: 0.1566 - acc: 0.956 - ETA: 1s - loss: 0.1620 - acc: 0.954 - ETA: 1s - loss: 0.1643 - acc: 0.953 - ETA: 1s - loss: 0.1633 - acc: 0.954 - ETA: 0s - loss: 0.1578 - acc: 0.955 - ETA: 0s - loss: 0.1530 - acc: 0.957 - ETA: 0s - loss: 0.1482 - acc: 0.959 - ETA: 0s - loss: 0.1439 - acc: 0.960 - ETA: 0s - loss: 0.1396 - acc: 0.962 - ETA: 0s - loss: 0.1444 - acc: 0.961 - ETA: 0s - loss: 0.1502 - acc: 0.956 - ETA: 0s - loss: 0.1473 - acc: 0.956 - 5s 138ms/step - loss: 0.1432 - acc: 0.9581 - val_loss: 3.5573 - val_acc: 0.7617\n",
      "Epoch 4/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.0032 - acc: 1.000 - ETA: 5s - loss: 0.0219 - acc: 0.984 - ETA: 4s - loss: 1.3029 - acc: 0.895 - ETA: 4s - loss: 1.4448 - acc: 0.773 - ETA: 3s - loss: 1.2327 - acc: 0.812 - ETA: 3s - loss: 1.0741 - acc: 0.843 - ETA: 3s - loss: 0.9570 - acc: 0.848 - ETA: 3s - loss: 0.8726 - acc: 0.847 - ETA: 3s - loss: 0.8028 - acc: 0.857 - ETA: 3s - loss: 0.7334 - acc: 0.871 - ETA: 2s - loss: 0.6728 - acc: 0.880 - ETA: 2s - loss: 0.6225 - acc: 0.890 - ETA: 2s - loss: 0.5793 - acc: 0.899 - ETA: 2s - loss: 0.5422 - acc: 0.906 - ETA: 2s - loss: 0.5072 - acc: 0.912 - ETA: 2s - loss: 0.5296 - acc: 0.902 - ETA: 1s - loss: 0.4906 - acc: 0.903 - ETA: 1s - loss: 0.4826 - acc: 0.901 - ETA: 1s - loss: 0.4597 - acc: 0.906 - ETA: 1s - loss: 0.4473 - acc: 0.908 - ETA: 1s - loss: 0.4309 - acc: 0.911 - ETA: 1s - loss: 0.4127 - acc: 0.915 - ETA: 1s - loss: 0.3960 - acc: 0.918 - ETA: 0s - loss: 0.3805 - acc: 0.922 - ETA: 0s - loss: 0.3659 - acc: 0.925 - ETA: 0s - loss: 0.3525 - acc: 0.928 - ETA: 0s - loss: 0.3402 - acc: 0.930 - ETA: 0s - loss: 0.3286 - acc: 0.933 - ETA: 0s - loss: 0.3177 - acc: 0.935 - ETA: 0s - loss: 0.3075 - acc: 0.937 - ETA: 0s - loss: 0.2981 - acc: 0.939 - 5s 150ms/step - loss: 0.2904 - acc: 0.9406 - val_loss: 1.3715 - val_acc: 0.8867\n",
      "Epoch 5/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.1402 - acc: 0.906 - ETA: 5s - loss: 0.1182 - acc: 0.937 - ETA: 4s - loss: 0.1683 - acc: 0.947 - ETA: 3s - loss: 0.1153 - acc: 0.954 - ETA: 3s - loss: 0.0975 - acc: 0.963 - ETA: 3s - loss: 0.0839 - acc: 0.969 - ETA: 2s - loss: 0.0796 - acc: 0.969 - ETA: 2s - loss: 0.0737 - acc: 0.969 - ETA: 2s - loss: 0.0827 - acc: 0.962 - ETA: 2s - loss: 0.0868 - acc: 0.962 - ETA: 2s - loss: 0.0806 - acc: 0.966 - ETA: 2s - loss: 0.0784 - acc: 0.969 - ETA: 2s - loss: 0.0735 - acc: 0.971 - ETA: 2s - loss: 0.0688 - acc: 0.973 - ETA: 2s - loss: 0.0652 - acc: 0.975 - ETA: 1s - loss: 0.0668 - acc: 0.974 - ETA: 1s - loss: 0.0815 - acc: 0.970 - ETA: 1s - loss: 0.0828 - acc: 0.970 - ETA: 1s - loss: 0.6557 - acc: 0.944 - ETA: 1s - loss: 0.7743 - acc: 0.922 - ETA: 1s - loss: 0.7453 - acc: 0.921 - ETA: 1s - loss: 0.7178 - acc: 0.925 - ETA: 1s - loss: 0.6929 - acc: 0.925 - ETA: 0s - loss: 0.6682 - acc: 0.927 - ETA: 0s - loss: 0.6472 - acc: 0.926 - ETA: 0s - loss: 0.6280 - acc: 0.928 - ETA: 0s - loss: 0.6069 - acc: 0.930 - ETA: 0s - loss: 0.5944 - acc: 0.928 - ETA: 0s - loss: 0.5910 - acc: 0.928 - ETA: 0s - loss: 0.5731 - acc: 0.929 - ETA: 0s - loss: 0.5565 - acc: 0.931 - 5s 137ms/step - loss: 0.5404 - acc: 0.9338 - val_loss: 2.3729 - val_acc: 0.8281\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 6.4200e-04 - acc: 1.000 - ETA: 5s - loss: 0.0011 - acc: 1.0000    - ETA: 4s - loss: 0.0017 - acc: 1.000 - ETA: 4s - loss: 0.0031 - acc: 1.000 - ETA: 3s - loss: 0.0034 - acc: 1.000 - ETA: 3s - loss: 0.0031 - acc: 1.000 - ETA: 3s - loss: 0.0134 - acc: 0.995 - ETA: 3s - loss: 0.0335 - acc: 0.988 - ETA: 3s - loss: 0.0300 - acc: 0.989 - ETA: 2s - loss: 0.0283 - acc: 0.990 - ETA: 2s - loss: 0.0257 - acc: 0.991 - ETA: 2s - loss: 0.0237 - acc: 0.992 - ETA: 2s - loss: 0.0219 - acc: 0.992 - ETA: 2s - loss: 0.0191 - acc: 0.993 - ETA: 2s - loss: 0.0180 - acc: 0.993 - ETA: 1s - loss: 0.0177 - acc: 0.994 - ETA: 1s - loss: 0.0167 - acc: 0.994 - ETA: 1s - loss: 0.0159 - acc: 0.994 - ETA: 1s - loss: 0.0152 - acc: 0.995 - ETA: 1s - loss: 0.0145 - acc: 0.995 - ETA: 1s - loss: 0.0139 - acc: 0.995 - ETA: 1s - loss: 0.0133 - acc: 0.995 - ETA: 1s - loss: 0.0129 - acc: 0.995 - ETA: 0s - loss: 0.0125 - acc: 0.996 - ETA: 0s - loss: 0.0121 - acc: 0.996 - ETA: 0s - loss: 0.0120 - acc: 0.996 - ETA: 0s - loss: 0.0116 - acc: 0.996 - ETA: 0s - loss: 0.0116 - acc: 0.996 - ETA: 0s - loss: 0.0112 - acc: 0.996 - ETA: 0s - loss: 0.0109 - acc: 0.996 - ETA: 0s - loss: 0.0105 - acc: 0.997 - 5s 137ms/step - loss: 0.0103 - acc: 0.9971 - val_loss: 4.6811 - val_acc: 0.8047\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.0017 - acc: 1.000 - ETA: 4s - loss: 8.7600e-04 - acc: 1.000 - ETA: 4s - loss: 8.2392e-04 - acc: 1.000 - ETA: 4s - loss: 6.7457e-04 - acc: 1.000 - ETA: 3s - loss: 8.1161e-04 - acc: 1.000 - ETA: 3s - loss: 7.9963e-04 - acc: 1.000 - ETA: 3s - loss: 6.9225e-04 - acc: 1.000 - ETA: 3s - loss: 6.0831e-04 - acc: 1.000 - ETA: 3s - loss: 5.4573e-04 - acc: 1.000 - ETA: 2s - loss: 4.9147e-04 - acc: 1.000 - ETA: 2s - loss: 4.4769e-04 - acc: 1.000 - ETA: 2s - loss: 4.1880e-04 - acc: 1.000 - ETA: 2s - loss: 3.8705e-04 - acc: 1.000 - ETA: 2s - loss: 3.6475e-04 - acc: 1.000 - ETA: 2s - loss: 3.4201e-04 - acc: 1.000 - ETA: 2s - loss: 3.2127e-04 - acc: 1.000 - ETA: 2s - loss: 3.6225e-04 - acc: 1.000 - ETA: 1s - loss: 3.4298e-04 - acc: 1.000 - ETA: 1s - loss: 3.9943e-04 - acc: 1.000 - ETA: 1s - loss: 4.2444e-04 - acc: 1.000 - ETA: 1s - loss: 4.0446e-04 - acc: 1.000 - ETA: 1s - loss: 3.9812e-04 - acc: 1.000 - ETA: 1s - loss: 3.8098e-04 - acc: 1.000 - ETA: 1s - loss: 3.6593e-04 - acc: 1.000 - ETA: 1s - loss: 3.5303e-04 - acc: 1.000 - ETA: 0s - loss: 3.3946e-04 - acc: 1.000 - ETA: 0s - loss: 3.2707e-04 - acc: 1.000 - ETA: 0s - loss: 3.1947e-04 - acc: 1.000 - ETA: 0s - loss: 3.4139e-04 - acc: 1.000 - ETA: 0s - loss: 3.3003e-04 - acc: 1.000 - ETA: 0s - loss: 3.8447e-04 - acc: 1.000 - 5s 137ms/step - loss: 3.7559e-04 - acc: 1.0000 - val_loss: 6.6467 - val_acc: 0.7500\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.0475 - acc: 0.968 - ETA: 5s - loss: 10.2328 - acc: 0.75 - ETA: 4s - loss: 6.9239 - acc: 0.7708 - ETA: 4s - loss: 5.2061 - acc: 0.820 - ETA: 3s - loss: 4.1659 - acc: 0.856 - ETA: 3s - loss: 3.4724 - acc: 0.880 - ETA: 3s - loss: 2.9810 - acc: 0.892 - ETA: 3s - loss: 2.6087 - acc: 0.906 - ETA: 3s - loss: 2.3192 - acc: 0.916 - ETA: 2s - loss: 2.0878 - acc: 0.925 - ETA: 2s - loss: 1.8980 - acc: 0.931 - ETA: 2s - loss: 1.7400 - acc: 0.937 - ETA: 2s - loss: 1.6062 - acc: 0.942 - ETA: 2s - loss: 1.4916 - acc: 0.946 - ETA: 2s - loss: 1.3922 - acc: 0.950 - ETA: 1s - loss: 1.2286 - acc: 0.953 - ETA: 1s - loss: 1.1604 - acc: 0.956 - ETA: 1s - loss: 1.0994 - acc: 0.958 - ETA: 1s - loss: 1.0444 - acc: 0.960 - ETA: 1s - loss: 0.9951 - acc: 0.962 - ETA: 1s - loss: 0.9499 - acc: 0.964 - ETA: 1s - loss: 0.9091 - acc: 0.966 - ETA: 1s - loss: 0.8755 - acc: 0.964 - ETA: 0s - loss: 0.8516 - acc: 0.962 - ETA: 0s - loss: 0.8199 - acc: 0.962 - ETA: 0s - loss: 0.7936 - acc: 0.961 - ETA: 0s - loss: 0.7809 - acc: 0.958 - ETA: 0s - loss: 0.7540 - acc: 0.960 - ETA: 0s - loss: 0.7464 - acc: 0.959 - ETA: 0s - loss: 0.7247 - acc: 0.959 - ETA: 0s - loss: 0.7044 - acc: 0.959 - 5s 137ms/step - loss: 0.6869 - acc: 0.9591 - val_loss: 8.5443 - val_acc: 0.6914\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.0139 - acc: 1.000 - ETA: 4s - loss: 0.0279 - acc: 0.984 - ETA: 4s - loss: 0.0211 - acc: 0.989 - ETA: 4s - loss: 0.0185 - acc: 0.992 - ETA: 3s - loss: 0.0148 - acc: 0.993 - ETA: 3s - loss: 0.0125 - acc: 0.994 - ETA: 3s - loss: 0.0108 - acc: 0.995 - ETA: 3s - loss: 0.0094 - acc: 0.996 - ETA: 3s - loss: 0.0084 - acc: 0.996 - ETA: 2s - loss: 0.0078 - acc: 0.996 - ETA: 2s - loss: 0.0076 - acc: 0.997 - ETA: 2s - loss: 0.0074 - acc: 0.997 - ETA: 2s - loss: 0.0068 - acc: 0.997 - ETA: 2s - loss: 0.0063 - acc: 0.997 - ETA: 2s - loss: 0.0059 - acc: 0.997 - ETA: 2s - loss: 0.0056 - acc: 0.998 - ETA: 2s - loss: 0.0053 - acc: 0.998 - ETA: 1s - loss: 0.0050 - acc: 0.998 - ETA: 1s - loss: 0.0047 - acc: 0.998 - ETA: 1s - loss: 0.0045 - acc: 0.998 - ETA: 1s - loss: 0.0043 - acc: 0.998 - ETA: 1s - loss: 0.0041 - acc: 0.998 - ETA: 1s - loss: 0.0038 - acc: 0.998 - ETA: 0s - loss: 0.0036 - acc: 0.998 - ETA: 0s - loss: 0.0035 - acc: 0.998 - ETA: 0s - loss: 0.0033 - acc: 0.998 - ETA: 0s - loss: 0.0032 - acc: 0.998 - ETA: 0s - loss: 0.0031 - acc: 0.998 - ETA: 0s - loss: 0.0030 - acc: 0.998 - ETA: 0s - loss: 0.0029 - acc: 0.999 - ETA: 0s - loss: 0.0029 - acc: 0.999 - 5s 137ms/step - loss: 0.0028 - acc: 0.9990 - val_loss: 5.8135 - val_acc: 0.7617\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 7.4848e-06 - acc: 1.000 - ETA: 5s - loss: 3.6785e-05 - acc: 1.000 - ETA: 4s - loss: 2.9771e-05 - acc: 1.000 - ETA: 4s - loss: 4.1157e-05 - acc: 1.000 - ETA: 3s - loss: 5.5404e-05 - acc: 1.000 - ETA: 3s - loss: 4.9732e-05 - acc: 1.000 - ETA: 3s - loss: 4.6263e-05 - acc: 1.000 - ETA: 3s - loss: 5.2553e-05 - acc: 1.000 - ETA: 3s - loss: 5.0068e-05 - acc: 1.000 - ETA: 2s - loss: 4.6844e-05 - acc: 1.000 - ETA: 2s - loss: 4.5408e-05 - acc: 1.000 - ETA: 2s - loss: 4.7348e-05 - acc: 1.000 - ETA: 2s - loss: 4.6727e-05 - acc: 1.000 - ETA: 2s - loss: 4.4682e-05 - acc: 1.000 - ETA: 2s - loss: 4.2836e-05 - acc: 1.000 - ETA: 1s - loss: 4.6262e-05 - acc: 1.000 - ETA: 1s - loss: 4.3779e-05 - acc: 1.000 - ETA: 1s - loss: 4.1748e-05 - acc: 1.000 - ETA: 1s - loss: 4.0085e-05 - acc: 1.000 - ETA: 1s - loss: 4.0501e-05 - acc: 1.000 - ETA: 1s - loss: 3.8772e-05 - acc: 1.000 - ETA: 1s - loss: 3.7135e-05 - acc: 1.000 - ETA: 1s - loss: 3.5969e-05 - acc: 1.000 - ETA: 0s - loss: 3.7383e-05 - acc: 1.000 - ETA: 0s - loss: 3.6419e-05 - acc: 1.000 - ETA: 0s - loss: 4.1257e-05 - acc: 1.000 - ETA: 0s - loss: 4.0430e-05 - acc: 1.000 - ETA: 0s - loss: 3.9618e-05 - acc: 1.000 - ETA: 0s - loss: 3.8450e-05 - acc: 1.000 - ETA: 0s - loss: 3.7374e-05 - acc: 1.000 - ETA: 0s - loss: 3.7442e-05 - acc: 1.000 - 5s 137ms/step - loss: 3.6881e-05 - acc: 1.0000 - val_loss: 6.4131 - val_acc: 0.7695\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 4.4091e-06 - acc: 1.000 - ETA: 5s - loss: 4.9673e-06 - acc: 1.000 - ETA: 4s - loss: 4.6123e-06 - acc: 1.000 - ETA: 4s - loss: 5.2396e-06 - acc: 1.000 - ETA: 3s - loss: 3.5813e-06 - acc: 1.000 - ETA: 3s - loss: 1.0732e-05 - acc: 1.000 - ETA: 3s - loss: 1.0251e-05 - acc: 1.000 - ETA: 2s - loss: 9.3798e-06 - acc: 1.000 - ETA: 2s - loss: 9.9852e-06 - acc: 1.000 - ETA: 2s - loss: 1.0804e-05 - acc: 1.000 - ETA: 2s - loss: 1.0131e-05 - acc: 1.000 - ETA: 2s - loss: 9.3861e-06 - acc: 1.000 - ETA: 2s - loss: 8.8323e-06 - acc: 1.000 - ETA: 2s - loss: 8.8925e-06 - acc: 1.000 - ETA: 2s - loss: 8.3502e-06 - acc: 1.000 - ETA: 1s - loss: 8.7722e-06 - acc: 1.000 - ETA: 1s - loss: 9.1336e-06 - acc: 1.000 - ETA: 1s - loss: 8.6926e-06 - acc: 1.000 - ETA: 1s - loss: 8.3138e-06 - acc: 1.000 - ETA: 1s - loss: 8.8595e-06 - acc: 1.000 - ETA: 1s - loss: 8.4967e-06 - acc: 1.000 - ETA: 1s - loss: 9.2784e-06 - acc: 1.000 - ETA: 1s - loss: 9.6099e-06 - acc: 1.000 - ETA: 0s - loss: 9.2550e-06 - acc: 1.000 - ETA: 0s - loss: 8.9596e-06 - acc: 1.000 - ETA: 0s - loss: 8.7341e-06 - acc: 1.000 - ETA: 0s - loss: 1.0439e-05 - acc: 1.000 - ETA: 0s - loss: 1.0111e-05 - acc: 1.000 - ETA: 0s - loss: 1.2043e-05 - acc: 1.000 - ETA: 0s - loss: 2.5149e-05 - acc: 1.000 - ETA: 0s - loss: 0.0446 - acc: 0.9930    - 5s 138ms/step - loss: 0.1067 - acc: 0.9893 - val_loss: 636.8601 - val_acc: 0.5000\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 421.9698 - acc: 0.531 - ETA: 5s - loss: 211.9969 - acc: 0.687 - ETA: 4s - loss: 141.3318 - acc: 0.791 - ETA: 4s - loss: 105.9989 - acc: 0.843 - ETA: 3s - loss: 84.8222 - acc: 0.868 - ETA: 3s - loss: 70.6861 - acc: 0.89 - ETA: 3s - loss: 60.5935 - acc: 0.90 - ETA: 3s - loss: 53.0195 - acc: 0.91 - ETA: 3s - loss: 47.1296 - acc: 0.92 - ETA: 3s - loss: 42.4168 - acc: 0.93 - ETA: 2s - loss: 38.5620 - acc: 0.93 - ETA: 2s - loss: 35.3485 - acc: 0.94 - ETA: 2s - loss: 32.6294 - acc: 0.94 - ETA: 2s - loss: 30.3031 - acc: 0.94 - ETA: 2s - loss: 28.2893 - acc: 0.94 - ETA: 2s - loss: 26.5213 - acc: 0.94 - ETA: 2s - loss: 24.9762 - acc: 0.95 - ETA: 1s - loss: 23.5992 - acc: 0.95 - ETA: 1s - loss: 22.3572 - acc: 0.95 - ETA: 1s - loss: 21.2394 - acc: 0.95 - ETA: 1s - loss: 20.2280 - acc: 0.95 - ETA: 1s - loss: 19.3089 - acc: 0.96 - ETA: 1s - loss: 18.4694 - acc: 0.96 - ETA: 1s - loss: 17.6998 - acc: 0.96 - ETA: 0s - loss: 16.9918 - acc: 0.96 - ETA: 0s - loss: 16.3383 - acc: 0.96 - ETA: 0s - loss: 15.7332 - acc: 0.96 - ETA: 0s - loss: 15.1738 - acc: 0.96 - ETA: 0s - loss: 14.6506 - acc: 0.96 - ETA: 0s - loss: 14.1622 - acc: 0.96 - ETA: 0s - loss: 13.7063 - acc: 0.96 - 5s 137ms/step - loss: 12.8863 - acc: 0.9708 - val_loss: 8.1440 - val_acc: 0.7812\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.2330 - acc: 0.937 - ETA: 5s - loss: 0.1680 - acc: 0.937 - ETA: 4s - loss: 0.1124 - acc: 0.958 - ETA: 4s - loss: 0.0965 - acc: 0.960 - ETA: 3s - loss: 0.0772 - acc: 0.968 - ETA: 3s - loss: 0.0699 - acc: 0.968 - ETA: 3s - loss: 0.0604 - acc: 0.973 - ETA: 3s - loss: 0.0529 - acc: 0.976 - ETA: 3s - loss: 0.0489 - acc: 0.979 - ETA: 2s - loss: 0.0440 - acc: 0.981 - ETA: 2s - loss: 0.0401 - acc: 0.983 - ETA: 2s - loss: 0.0367 - acc: 0.984 - ETA: 2s - loss: 0.0351 - acc: 0.985 - ETA: 2s - loss: 0.0305 - acc: 0.986 - ETA: 2s - loss: 0.0286 - acc: 0.987 - ETA: 1s - loss: 0.0289 - acc: 0.986 - ETA: 1s - loss: 0.0289 - acc: 0.985 - ETA: 1s - loss: 0.0281 - acc: 0.986 - ETA: 1s - loss: 0.0267 - acc: 0.986 - ETA: 1s - loss: 0.0254 - acc: 0.987 - ETA: 1s - loss: 0.0242 - acc: 0.988 - ETA: 1s - loss: 0.0232 - acc: 0.988 - ETA: 1s - loss: 0.0230 - acc: 0.989 - ETA: 0s - loss: 0.0221 - acc: 0.989 - ETA: 0s - loss: 0.0212 - acc: 0.990 - ETA: 0s - loss: 0.0205 - acc: 0.990 - ETA: 0s - loss: 0.0197 - acc: 0.990 - ETA: 0s - loss: 0.0191 - acc: 0.991 - ETA: 0s - loss: 0.0185 - acc: 0.991 - ETA: 0s - loss: 0.0179 - acc: 0.991 - ETA: 0s - loss: 0.0173 - acc: 0.992 - 5s 137ms/step - loss: 0.0168 - acc: 0.9922 - val_loss: 7.8982 - val_acc: 0.7656\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 6.1802e-07 - acc: 1.000 - ETA: 5s - loss: 7.0104e-06 - acc: 1.000 - ETA: 4s - loss: 5.3540e-06 - acc: 1.000 - ETA: 4s - loss: 4.2371e-06 - acc: 1.000 - ETA: 3s - loss: 3.4316e-06 - acc: 1.000 - ETA: 3s - loss: 3.0066e-06 - acc: 1.000 - ETA: 3s - loss: 2.6376e-06 - acc: 1.000 - ETA: 3s - loss: 2.4556e-06 - acc: 1.000 - ETA: 3s - loss: 3.2178e-06 - acc: 1.000 - ETA: 3s - loss: 2.9078e-06 - acc: 1.000 - ETA: 2s - loss: 4.7232e-06 - acc: 1.000 - ETA: 2s - loss: 4.4189e-06 - acc: 1.000 - ETA: 2s - loss: 3.2403e-05 - acc: 1.000 - ETA: 2s - loss: 3.4657e-05 - acc: 1.000 - ETA: 2s - loss: 3.3340e-05 - acc: 1.000 - ETA: 2s - loss: 3.3296e-05 - acc: 1.000 - ETA: 1s - loss: 2.9606e-05 - acc: 1.000 - ETA: 1s - loss: 2.8345e-05 - acc: 1.000 - ETA: 1s - loss: 2.7050e-05 - acc: 1.000 - ETA: 1s - loss: 2.5777e-05 - acc: 1.000 - ETA: 1s - loss: 2.4611e-05 - acc: 1.000 - ETA: 1s - loss: 3.0566e-05 - acc: 1.000 - ETA: 1s - loss: 3.0465e-05 - acc: 1.000 - ETA: 0s - loss: 2.9271e-05 - acc: 1.000 - ETA: 0s - loss: 2.8153e-05 - acc: 1.000 - ETA: 0s - loss: 2.7410e-05 - acc: 1.000 - ETA: 0s - loss: 2.8150e-05 - acc: 1.000 - ETA: 0s - loss: 2.7244e-05 - acc: 1.000 - ETA: 0s - loss: 2.6356e-05 - acc: 1.000 - ETA: 0s - loss: 2.6435e-05 - acc: 1.000 - ETA: 0s - loss: 2.5640e-05 - acc: 1.000 - 5s 138ms/step - loss: 2.5063e-05 - acc: 1.0000 - val_loss: 7.8799 - val_acc: 0.7656\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 4.1367e-05 - acc: 1.000 - ETA: 5s - loss: 3.4018e-05 - acc: 1.000 - ETA: 4s - loss: 2.6766e-05 - acc: 1.000 - ETA: 4s - loss: 2.0108e-05 - acc: 1.000 - ETA: 3s - loss: 1.6231e-05 - acc: 1.000 - ETA: 3s - loss: 1.3671e-05 - acc: 1.000 - ETA: 3s - loss: 1.3970e-05 - acc: 1.000 - ETA: 3s - loss: 1.3764e-05 - acc: 1.000 - ETA: 3s - loss: 2.3079e-05 - acc: 1.000 - ETA: 2s - loss: 2.2972e-05 - acc: 1.000 - ETA: 2s - loss: 2.1571e-05 - acc: 1.000 - ETA: 2s - loss: 1.9842e-05 - acc: 1.000 - ETA: 2s - loss: 2.3316e-05 - acc: 1.000 - ETA: 2s - loss: 2.6235e-05 - acc: 1.000 - ETA: 2s - loss: 2.4490e-05 - acc: 1.000 - ETA: 2s - loss: 2.2989e-05 - acc: 1.000 - ETA: 2s - loss: 2.1651e-05 - acc: 1.000 - ETA: 1s - loss: 2.0523e-05 - acc: 1.000 - ETA: 1s - loss: 1.9449e-05 - acc: 1.000 - ETA: 1s - loss: 1.8654e-05 - acc: 1.000 - ETA: 1s - loss: 1.7788e-05 - acc: 1.000 - ETA: 1s - loss: 1.6989e-05 - acc: 1.000 - ETA: 1s - loss: 1.6553e-05 - acc: 1.000 - ETA: 0s - loss: 1.5232e-05 - acc: 1.000 - ETA: 0s - loss: 1.4691e-05 - acc: 1.000 - ETA: 0s - loss: 1.4160e-05 - acc: 1.000 - ETA: 0s - loss: 1.3665e-05 - acc: 1.000 - ETA: 0s - loss: 1.3228e-05 - acc: 1.000 - ETA: 0s - loss: 1.2788e-05 - acc: 1.000 - ETA: 0s - loss: 1.2416e-05 - acc: 1.000 - ETA: 0s - loss: 1.2043e-05 - acc: 1.000 - 5s 138ms/step - loss: 1.1769e-05 - acc: 1.0000 - val_loss: 8.3884 - val_acc: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 352</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 15</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.88671875</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,078,625\n",
      "Trainable params: 1,078,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 33 steps, validate for 8 steps\n",
      "Epoch 1/15\n",
      "33/33 [==============================] - ETA: 24s - loss: 0.6974 - acc: 0.40 - ETA: 12s - loss: 0.8791 - acc: 0.46 - ETA: 9s - loss: 0.8049 - acc: 0.5625 - ETA: 7s - loss: 0.8582 - acc: 0.562 - ETA: 6s - loss: 0.8246 - acc: 0.562 - ETA: 5s - loss: 0.8020 - acc: 0.557 - ETA: 5s - loss: 0.7826 - acc: 0.571 - ETA: 4s - loss: 0.7679 - acc: 0.574 - ETA: 4s - loss: 0.7555 - acc: 0.579 - ETA: 4s - loss: 0.7574 - acc: 0.562 - ETA: 3s - loss: 0.7507 - acc: 0.559 - ETA: 3s - loss: 0.7451 - acc: 0.549 - ETA: 3s - loss: 0.7390 - acc: 0.548 - ETA: 3s - loss: 0.7325 - acc: 0.555 - ETA: 2s - loss: 0.7324 - acc: 0.554 - ETA: 2s - loss: 0.7314 - acc: 0.552 - ETA: 2s - loss: 0.7269 - acc: 0.575 - ETA: 2s - loss: 0.7248 - acc: 0.569 - ETA: 1s - loss: 0.7145 - acc: 0.579 - ETA: 1s - loss: 0.7099 - acc: 0.584 - ETA: 1s - loss: 0.7066 - acc: 0.585 - ETA: 1s - loss: 0.7006 - acc: 0.585 - ETA: 1s - loss: 0.6946 - acc: 0.584 - ETA: 1s - loss: 0.6861 - acc: 0.597 - ETA: 0s - loss: 0.6793 - acc: 0.602 - ETA: 0s - loss: 0.6841 - acc: 0.608 - ETA: 0s - loss: 0.6803 - acc: 0.618 - ETA: 0s - loss: 0.6736 - acc: 0.629 - ETA: 0s - loss: 0.6840 - acc: 0.623 - ETA: 0s - loss: 0.6803 - acc: 0.623 - ETA: 0s - loss: 0.6750 - acc: 0.629 - 5s 156ms/step - loss: 0.6666 - acc: 0.6358 - val_loss: 0.7708 - val_acc: 0.7461\n",
      "Epoch 2/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 0.2790 - acc: 0.906 - ETA: 4s - loss: 0.3149 - acc: 0.875 - ETA: 4s - loss: 1.3379 - acc: 0.697 - ETA: 4s - loss: 1.1834 - acc: 0.656 - ETA: 3s - loss: 1.0451 - acc: 0.700 - ETA: 3s - loss: 0.9490 - acc: 0.724 - ETA: 3s - loss: 0.8733 - acc: 0.741 - ETA: 3s - loss: 0.8154 - acc: 0.757 - ETA: 3s - loss: 0.7498 - acc: 0.774 - ETA: 2s - loss: 0.7046 - acc: 0.781 - ETA: 2s - loss: 0.6666 - acc: 0.786 - ETA: 2s - loss: 0.6222 - acc: 0.804 - ETA: 2s - loss: 0.5908 - acc: 0.810 - ETA: 2s - loss: 0.5712 - acc: 0.817 - ETA: 2s - loss: 0.5400 - acc: 0.821 - ETA: 1s - loss: 0.5187 - acc: 0.831 - ETA: 1s - loss: 0.5032 - acc: 0.837 - ETA: 1s - loss: 0.4911 - acc: 0.839 - ETA: 1s - loss: 0.4774 - acc: 0.842 - ETA: 1s - loss: 0.4576 - acc: 0.849 - ETA: 1s - loss: 0.4500 - acc: 0.850 - ETA: 1s - loss: 0.4457 - acc: 0.851 - ETA: 1s - loss: 0.4400 - acc: 0.855 - ETA: 0s - loss: 0.4304 - acc: 0.859 - ETA: 0s - loss: 0.4231 - acc: 0.860 - ETA: 0s - loss: 0.4134 - acc: 0.863 - ETA: 0s - loss: 0.4054 - acc: 0.866 - ETA: 0s - loss: 0.4102 - acc: 0.864 - ETA: 0s - loss: 0.4196 - acc: 0.860 - ETA: 0s - loss: 0.4148 - acc: 0.861 - ETA: 0s - loss: 0.4070 - acc: 0.865 - 5s 139ms/step - loss: 0.4011 - acc: 0.8666 - val_loss: 0.9550 - val_acc: 0.8008\n",
      "Epoch 3/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.1722 - acc: 0.937 - ETA: 4s - loss: 0.1391 - acc: 0.953 - ETA: 4s - loss: 0.1279 - acc: 0.968 - ETA: 3s - loss: 0.1175 - acc: 0.968 - ETA: 3s - loss: 0.1074 - acc: 0.975 - ETA: 3s - loss: 0.0915 - acc: 0.979 - ETA: 3s - loss: 0.0948 - acc: 0.977 - ETA: 3s - loss: 0.0895 - acc: 0.980 - ETA: 3s - loss: 0.1047 - acc: 0.975 - ETA: 2s - loss: 0.1130 - acc: 0.968 - ETA: 2s - loss: 0.1150 - acc: 0.965 - ETA: 2s - loss: 0.1183 - acc: 0.960 - ETA: 2s - loss: 0.1233 - acc: 0.956 - ETA: 2s - loss: 0.1084 - acc: 0.960 - ETA: 2s - loss: 0.1083 - acc: 0.958 - ETA: 1s - loss: 0.1053 - acc: 0.961 - ETA: 1s - loss: 0.0997 - acc: 0.963 - ETA: 1s - loss: 0.0950 - acc: 0.965 - ETA: 1s - loss: 0.0910 - acc: 0.967 - ETA: 1s - loss: 0.0885 - acc: 0.968 - ETA: 1s - loss: 0.0872 - acc: 0.968 - ETA: 1s - loss: 0.0904 - acc: 0.966 - ETA: 1s - loss: 0.1002 - acc: 0.963 - ETA: 0s - loss: 0.2311 - acc: 0.948 - ETA: 0s - loss: 0.2443 - acc: 0.935 - ETA: 0s - loss: 0.2473 - acc: 0.937 - ETA: 0s - loss: 0.2487 - acc: 0.936 - ETA: 0s - loss: 0.2457 - acc: 0.938 - ETA: 0s - loss: 0.2483 - acc: 0.935 - ETA: 0s - loss: 0.2484 - acc: 0.935 - ETA: 0s - loss: 0.2456 - acc: 0.937 - 5s 138ms/step - loss: 0.2435 - acc: 0.9367 - val_loss: 0.8512 - val_acc: 0.8477\n",
      "Epoch 4/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0995 - acc: 1.000 - ETA: 4s - loss: 0.0866 - acc: 0.984 - ETA: 4s - loss: 0.0807 - acc: 0.989 - ETA: 4s - loss: 0.0778 - acc: 0.984 - ETA: 3s - loss: 0.1094 - acc: 0.962 - ETA: 3s - loss: 0.0994 - acc: 0.968 - ETA: 3s - loss: 0.0986 - acc: 0.973 - ETA: 3s - loss: 0.0903 - acc: 0.976 - ETA: 3s - loss: 0.0839 - acc: 0.979 - ETA: 2s - loss: 0.0819 - acc: 0.978 - ETA: 2s - loss: 0.1848 - acc: 0.948 - ETA: 2s - loss: 0.1797 - acc: 0.947 - ETA: 2s - loss: 0.2016 - acc: 0.944 - ETA: 2s - loss: 0.2220 - acc: 0.939 - ETA: 2s - loss: 0.2246 - acc: 0.933 - ETA: 2s - loss: 0.2168 - acc: 0.937 - ETA: 2s - loss: 0.2184 - acc: 0.935 - ETA: 1s - loss: 0.2101 - acc: 0.939 - ETA: 1s - loss: 0.2050 - acc: 0.940 - ETA: 1s - loss: 0.1968 - acc: 0.943 - ETA: 1s - loss: 0.1933 - acc: 0.943 - ETA: 1s - loss: 0.1987 - acc: 0.940 - ETA: 1s - loss: 0.1921 - acc: 0.942 - ETA: 1s - loss: 0.1872 - acc: 0.944 - ETA: 0s - loss: 0.1838 - acc: 0.945 - ETA: 0s - loss: 0.1780 - acc: 0.945 - ETA: 0s - loss: 0.1719 - acc: 0.947 - ETA: 0s - loss: 0.1606 - acc: 0.949 - ETA: 0s - loss: 0.1566 - acc: 0.951 - ETA: 0s - loss: 0.1516 - acc: 0.953 - ETA: 0s - loss: 0.1471 - acc: 0.954 - 5s 136ms/step - loss: 0.1441 - acc: 0.9552 - val_loss: 1.7006 - val_acc: 0.8320\n",
      "Epoch 5/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0263 - acc: 1.000 - ETA: 4s - loss: 0.0942 - acc: 0.953 - ETA: 4s - loss: 0.2381 - acc: 0.927 - ETA: 3s - loss: 0.1972 - acc: 0.945 - ETA: 3s - loss: 0.1607 - acc: 0.956 - ETA: 3s - loss: 0.1415 - acc: 0.958 - ETA: 3s - loss: 0.1264 - acc: 0.964 - ETA: 3s - loss: 0.1127 - acc: 0.968 - ETA: 3s - loss: 0.1063 - acc: 0.968 - ETA: 2s - loss: 0.0967 - acc: 0.971 - ETA: 2s - loss: 0.0885 - acc: 0.974 - ETA: 2s - loss: 0.0820 - acc: 0.976 - ETA: 2s - loss: 0.0761 - acc: 0.978 - ETA: 2s - loss: 0.0708 - acc: 0.979 - ETA: 2s - loss: 0.0661 - acc: 0.981 - ETA: 2s - loss: 0.0627 - acc: 0.982 - ETA: 1s - loss: 0.0606 - acc: 0.983 - ETA: 1s - loss: 0.0819 - acc: 0.974 - ETA: 1s - loss: 0.0900 - acc: 0.968 - ETA: 1s - loss: 0.1016 - acc: 0.965 - ETA: 1s - loss: 0.1575 - acc: 0.952 - ETA: 1s - loss: 0.1736 - acc: 0.947 - ETA: 1s - loss: 0.1674 - acc: 0.949 - ETA: 0s - loss: 0.1638 - acc: 0.950 - ETA: 0s - loss: 0.1600 - acc: 0.951 - ETA: 0s - loss: 0.1550 - acc: 0.953 - ETA: 0s - loss: 0.1499 - acc: 0.955 - ETA: 0s - loss: 0.1454 - acc: 0.956 - ETA: 0s - loss: 0.1406 - acc: 0.958 - ETA: 0s - loss: 0.1364 - acc: 0.959 - ETA: 0s - loss: 0.1322 - acc: 0.960 - 4s 136ms/step - loss: 0.1309 - acc: 0.9601 - val_loss: 1.1216 - val_acc: 0.8242\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.1355 - acc: 0.906 - ETA: 4s - loss: 0.0999 - acc: 0.937 - ETA: 4s - loss: 0.0843 - acc: 0.947 - ETA: 4s - loss: 0.0711 - acc: 0.953 - ETA: 3s - loss: 0.0572 - acc: 0.962 - ETA: 2s - loss: 0.0427 - acc: 0.969 - ETA: 2s - loss: 0.0375 - acc: 0.973 - ETA: 2s - loss: 0.0400 - acc: 0.973 - ETA: 2s - loss: 0.0396 - acc: 0.975 - ETA: 2s - loss: 0.0388 - acc: 0.978 - ETA: 2s - loss: 0.0367 - acc: 0.980 - ETA: 2s - loss: 0.0369 - acc: 0.979 - ETA: 2s - loss: 0.0345 - acc: 0.980 - ETA: 2s - loss: 0.0339 - acc: 0.982 - ETA: 2s - loss: 0.0319 - acc: 0.983 - ETA: 1s - loss: 0.0301 - acc: 0.984 - ETA: 1s - loss: 0.0326 - acc: 0.983 - ETA: 1s - loss: 0.0449 - acc: 0.979 - ETA: 1s - loss: 0.0571 - acc: 0.973 - ETA: 1s - loss: 0.0649 - acc: 0.968 - ETA: 1s - loss: 0.0679 - acc: 0.968 - ETA: 1s - loss: 0.0792 - acc: 0.964 - ETA: 1s - loss: 0.0820 - acc: 0.964 - ETA: 0s - loss: 0.0812 - acc: 0.965 - ETA: 0s - loss: 0.0830 - acc: 0.965 - ETA: 0s - loss: 0.0877 - acc: 0.962 - ETA: 0s - loss: 0.0886 - acc: 0.961 - ETA: 0s - loss: 0.0863 - acc: 0.963 - ETA: 0s - loss: 0.0835 - acc: 0.964 - ETA: 0s - loss: 0.0808 - acc: 0.965 - ETA: 0s - loss: 0.0783 - acc: 0.966 - 5s 137ms/step - loss: 0.0761 - acc: 0.9679 - val_loss: 2.3100 - val_acc: 0.8086\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 5.5567e-04 - acc: 1.000 - ETA: 4s - loss: 4.3339e-04 - acc: 1.000 - ETA: 4s - loss: 0.0018 - acc: 1.0000    - ETA: 3s - loss: 0.0039 - acc: 1.000 - ETA: 3s - loss: 0.0034 - acc: 1.000 - ETA: 3s - loss: 0.0029 - acc: 1.000 - ETA: 3s - loss: 0.0025 - acc: 1.000 - ETA: 3s - loss: 0.0024 - acc: 1.000 - ETA: 3s - loss: 0.0022 - acc: 1.000 - ETA: 2s - loss: 0.0020 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0017 - acc: 1.000 - ETA: 2s - loss: 0.0016 - acc: 1.000 - ETA: 2s - loss: 0.0015 - acc: 1.000 - ETA: 2s - loss: 0.0020 - acc: 1.000 - ETA: 2s - loss: 0.0284 - acc: 0.996 - ETA: 1s - loss: 0.1801 - acc: 0.968 - ETA: 1s - loss: 0.1978 - acc: 0.963 - ETA: 1s - loss: 0.1955 - acc: 0.962 - ETA: 1s - loss: 0.2019 - acc: 0.957 - ETA: 1s - loss: 0.2012 - acc: 0.955 - ETA: 1s - loss: 0.1946 - acc: 0.957 - ETA: 1s - loss: 0.1885 - acc: 0.959 - ETA: 1s - loss: 0.1855 - acc: 0.959 - ETA: 0s - loss: 0.1790 - acc: 0.961 - ETA: 0s - loss: 0.1664 - acc: 0.962 - ETA: 0s - loss: 0.1610 - acc: 0.964 - ETA: 0s - loss: 0.1555 - acc: 0.965 - ETA: 0s - loss: 0.1515 - acc: 0.966 - ETA: 0s - loss: 0.1466 - acc: 0.967 - ETA: 0s - loss: 0.1420 - acc: 0.968 - 5s 137ms/step - loss: 0.1410 - acc: 0.9688 - val_loss: 0.6600 - val_acc: 0.9062\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0721 - acc: 0.937 - ETA: 4s - loss: 0.0441 - acc: 0.968 - ETA: 4s - loss: 0.0322 - acc: 0.979 - ETA: 3s - loss: 0.0255 - acc: 0.984 - ETA: 3s - loss: 0.0218 - acc: 0.987 - ETA: 3s - loss: 0.0182 - acc: 0.989 - ETA: 3s - loss: 0.0180 - acc: 0.991 - ETA: 3s - loss: 0.0158 - acc: 0.992 - ETA: 3s - loss: 0.0140 - acc: 0.993 - ETA: 2s - loss: 0.0127 - acc: 0.993 - ETA: 2s - loss: 0.0115 - acc: 0.994 - ETA: 2s - loss: 0.0106 - acc: 0.994 - ETA: 2s - loss: 0.0098 - acc: 0.995 - ETA: 2s - loss: 0.0092 - acc: 0.995 - ETA: 2s - loss: 0.0086 - acc: 0.995 - ETA: 2s - loss: 0.0081 - acc: 0.996 - ETA: 2s - loss: 0.0076 - acc: 0.996 - ETA: 1s - loss: 0.0074 - acc: 0.996 - ETA: 1s - loss: 0.0070 - acc: 0.996 - ETA: 1s - loss: 0.0064 - acc: 0.996 - ETA: 1s - loss: 0.0061 - acc: 0.997 - ETA: 1s - loss: 0.0059 - acc: 0.997 - ETA: 1s - loss: 0.0056 - acc: 0.997 - ETA: 0s - loss: 0.0054 - acc: 0.997 - ETA: 0s - loss: 0.0053 - acc: 0.997 - ETA: 0s - loss: 0.0051 - acc: 0.997 - ETA: 0s - loss: 0.0049 - acc: 0.997 - ETA: 0s - loss: 0.0048 - acc: 0.997 - ETA: 0s - loss: 0.0046 - acc: 0.997 - ETA: 0s - loss: 0.0045 - acc: 0.997 - ETA: 0s - loss: 0.0043 - acc: 0.998 - 5s 137ms/step - loss: 0.0042 - acc: 0.9981 - val_loss: 3.3341 - val_acc: 0.7930\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 4.1185e-06 - acc: 1.000 - ETA: 4s - loss: 2.7373e-04 - acc: 1.000 - ETA: 3s - loss: 5.2175e-04 - acc: 1.000 - ETA: 3s - loss: 4.1860e-04 - acc: 1.000 - ETA: 3s - loss: 0.0011 - acc: 1.0000    - ETA: 2s - loss: 0.0113 - acc: 0.994 - ETA: 2s - loss: 0.1071 - acc: 0.973 - ETA: 2s - loss: 0.0954 - acc: 0.976 - ETA: 2s - loss: 0.0864 - acc: 0.979 - ETA: 2s - loss: 0.0807 - acc: 0.981 - ETA: 2s - loss: 0.0740 - acc: 0.983 - ETA: 2s - loss: 0.0693 - acc: 0.984 - ETA: 2s - loss: 0.0645 - acc: 0.985 - ETA: 2s - loss: 0.0603 - acc: 0.986 - ETA: 2s - loss: 0.0576 - acc: 0.987 - ETA: 1s - loss: 0.0554 - acc: 0.988 - ETA: 1s - loss: 0.0683 - acc: 0.985 - ETA: 1s - loss: 0.0650 - acc: 0.986 - ETA: 1s - loss: 0.0776 - acc: 0.983 - ETA: 1s - loss: 0.0790 - acc: 0.979 - ETA: 1s - loss: 0.0897 - acc: 0.976 - ETA: 1s - loss: 0.1385 - acc: 0.964 - ETA: 1s - loss: 0.1502 - acc: 0.960 - ETA: 0s - loss: 0.1471 - acc: 0.959 - ETA: 0s - loss: 0.1419 - acc: 0.961 - ETA: 0s - loss: 0.1369 - acc: 0.962 - ETA: 0s - loss: 0.1322 - acc: 0.964 - ETA: 0s - loss: 0.1277 - acc: 0.965 - ETA: 0s - loss: 0.1235 - acc: 0.966 - ETA: 0s - loss: 0.1195 - acc: 0.967 - ETA: 0s - loss: 0.1159 - acc: 0.968 - 5s 137ms/step - loss: 0.1126 - acc: 0.9698 - val_loss: 1.9125 - val_acc: 0.8477\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0118 - acc: 1.000 - ETA: 4s - loss: 0.0061 - acc: 1.000 - ETA: 4s - loss: 0.0046 - acc: 1.000 - ETA: 4s - loss: 0.0042 - acc: 1.000 - ETA: 3s - loss: 0.0041 - acc: 1.000 - ETA: 3s - loss: 0.0034 - acc: 1.000 - ETA: 3s - loss: 0.0030 - acc: 1.000 - ETA: 3s - loss: 0.0029 - acc: 1.000 - ETA: 3s - loss: 0.0029 - acc: 1.000 - ETA: 2s - loss: 0.0027 - acc: 1.000 - ETA: 2s - loss: 0.0024 - acc: 1.000 - ETA: 2s - loss: 0.0023 - acc: 1.000 - ETA: 2s - loss: 0.0021 - acc: 1.000 - ETA: 2s - loss: 0.0020 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0018 - acc: 1.000 - ETA: 1s - loss: 0.0017 - acc: 1.000 - ETA: 1s - loss: 0.0016 - acc: 1.000 - ETA: 1s - loss: 0.0015 - acc: 1.000 - ETA: 1s - loss: 0.0015 - acc: 1.000 - ETA: 1s - loss: 0.0014 - acc: 1.000 - ETA: 1s - loss: 0.0014 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 9.9563e-04 - acc: 1.000 - 5s 136ms/step - loss: 9.6799e-04 - acc: 1.0000 - val_loss: 2.2365 - val_acc: 0.8633\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 3.9157e-04 - acc: 1.000 - ETA: 4s - loss: 2.2434e-04 - acc: 1.000 - ETA: 4s - loss: 2.4604e-04 - acc: 1.000 - ETA: 3s - loss: 1.9186e-04 - acc: 1.000 - ETA: 3s - loss: 1.7820e-04 - acc: 1.000 - ETA: 3s - loss: 1.6396e-04 - acc: 1.000 - ETA: 3s - loss: 1.9030e-04 - acc: 1.000 - ETA: 3s - loss: 1.6738e-04 - acc: 1.000 - ETA: 3s - loss: 1.5532e-04 - acc: 1.000 - ETA: 2s - loss: 1.4439e-04 - acc: 1.000 - ETA: 2s - loss: 1.3815e-04 - acc: 1.000 - ETA: 2s - loss: 1.2696e-04 - acc: 1.000 - ETA: 2s - loss: 1.2028e-04 - acc: 1.000 - ETA: 2s - loss: 1.1195e-04 - acc: 1.000 - ETA: 2s - loss: 1.2017e-04 - acc: 1.000 - ETA: 1s - loss: 1.1521e-04 - acc: 1.000 - ETA: 1s - loss: 1.0980e-04 - acc: 1.000 - ETA: 1s - loss: 1.0424e-04 - acc: 1.000 - ETA: 1s - loss: 1.0860e-04 - acc: 1.000 - ETA: 1s - loss: 1.0605e-04 - acc: 1.000 - ETA: 1s - loss: 1.0146e-04 - acc: 1.000 - ETA: 1s - loss: 1.0466e-04 - acc: 1.000 - ETA: 1s - loss: 1.0069e-04 - acc: 1.000 - ETA: 0s - loss: 1.0875e-04 - acc: 1.000 - ETA: 0s - loss: 1.0471e-04 - acc: 1.000 - ETA: 0s - loss: 1.0135e-04 - acc: 1.000 - ETA: 0s - loss: 9.9602e-05 - acc: 1.000 - ETA: 0s - loss: 1.0356e-04 - acc: 1.000 - ETA: 0s - loss: 1.0156e-04 - acc: 1.000 - ETA: 0s - loss: 9.8404e-05 - acc: 1.000 - ETA: 0s - loss: 9.9144e-05 - acc: 1.000 - 4s 136ms/step - loss: 1.0943e-04 - acc: 1.0000 - val_loss: 3.2715 - val_acc: 0.8281\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 9.4876e-06 - acc: 1.000 - ETA: 4s - loss: 5.7765e-04 - acc: 1.000 - ETA: 4s - loss: 3.8817e-04 - acc: 1.000 - ETA: 4s - loss: 2.9224e-04 - acc: 1.000 - ETA: 3s - loss: 2.4029e-04 - acc: 1.000 - ETA: 3s - loss: 2.5296e-04 - acc: 1.000 - ETA: 3s - loss: 2.4874e-04 - acc: 1.000 - ETA: 3s - loss: 2.1923e-04 - acc: 1.000 - ETA: 3s - loss: 1.9503e-04 - acc: 1.000 - ETA: 2s - loss: 1.7570e-04 - acc: 1.000 - ETA: 2s - loss: 1.5975e-04 - acc: 1.000 - ETA: 2s - loss: 1.4650e-04 - acc: 1.000 - ETA: 2s - loss: 1.3528e-04 - acc: 1.000 - ETA: 2s - loss: 1.2562e-04 - acc: 1.000 - ETA: 2s - loss: 1.1880e-04 - acc: 1.000 - ETA: 2s - loss: 1.1143e-04 - acc: 1.000 - ETA: 2s - loss: 1.0502e-04 - acc: 1.000 - ETA: 1s - loss: 9.9569e-05 - acc: 1.000 - ETA: 1s - loss: 9.4387e-05 - acc: 1.000 - ETA: 1s - loss: 9.0058e-05 - acc: 1.000 - ETA: 1s - loss: 8.5941e-05 - acc: 1.000 - ETA: 1s - loss: 8.2056e-05 - acc: 1.000 - ETA: 1s - loss: 7.8676e-05 - acc: 1.000 - ETA: 1s - loss: 7.5455e-05 - acc: 1.000 - ETA: 0s - loss: 6.9858e-05 - acc: 1.000 - ETA: 0s - loss: 6.7273e-05 - acc: 1.000 - ETA: 0s - loss: 6.4872e-05 - acc: 1.000 - ETA: 0s - loss: 6.2982e-05 - acc: 1.000 - ETA: 0s - loss: 6.1090e-05 - acc: 1.000 - ETA: 0s - loss: 5.9120e-05 - acc: 1.000 - ETA: 0s - loss: 5.8593e-05 - acc: 1.000 - 5s 137ms/step - loss: 5.6891e-05 - acc: 1.0000 - val_loss: 3.1339 - val_acc: 0.8750\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 3.1957e-06 - acc: 1.000 - ETA: 4s - loss: 1.6623e-06 - acc: 1.000 - ETA: 4s - loss: 1.1586e-06 - acc: 1.000 - ETA: 3s - loss: 8.9483e-07 - acc: 1.000 - ETA: 3s - loss: 1.5410e-06 - acc: 1.000 - ETA: 3s - loss: 5.7384e-06 - acc: 1.000 - ETA: 3s - loss: 4.9193e-06 - acc: 1.000 - ETA: 3s - loss: 4.3670e-06 - acc: 1.000 - ETA: 3s - loss: 3.8932e-06 - acc: 1.000 - ETA: 2s - loss: 3.9362e-06 - acc: 1.000 - ETA: 2s - loss: 3.4570e-06 - acc: 1.000 - ETA: 2s - loss: 3.2239e-06 - acc: 1.000 - ETA: 2s - loss: 3.0149e-06 - acc: 1.000 - ETA: 2s - loss: 2.8254e-06 - acc: 1.000 - ETA: 2s - loss: 2.6654e-06 - acc: 1.000 - ETA: 1s - loss: 2.8452e-06 - acc: 1.000 - ETA: 1s - loss: 2.7399e-06 - acc: 1.000 - ETA: 1s - loss: 2.5979e-06 - acc: 1.000 - ETA: 1s - loss: 2.5131e-06 - acc: 1.000 - ETA: 1s - loss: 2.3983e-06 - acc: 1.000 - ETA: 1s - loss: 2.3084e-06 - acc: 1.000 - ETA: 1s - loss: 2.2255e-06 - acc: 1.000 - ETA: 1s - loss: 2.1778e-06 - acc: 1.000 - ETA: 0s - loss: 2.0990e-06 - acc: 1.000 - ETA: 0s - loss: 2.0208e-06 - acc: 1.000 - ETA: 0s - loss: 1.9488e-06 - acc: 1.000 - ETA: 0s - loss: 2.0990e-06 - acc: 1.000 - ETA: 0s - loss: 2.3852e-06 - acc: 1.000 - ETA: 0s - loss: 2.3076e-06 - acc: 1.000 - ETA: 0s - loss: 2.2368e-06 - acc: 1.000 - ETA: 0s - loss: 2.1680e-06 - acc: 1.000 - 5s 137ms/step - loss: 2.3533e-06 - acc: 1.0000 - val_loss: 3.3993 - val_acc: 0.8750\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - ETA: 6s - loss: 2.7210e-05 - acc: 1.000 - ETA: 4s - loss: 1.5016e-05 - acc: 1.000 - ETA: 4s - loss: 1.4278e-05 - acc: 1.000 - ETA: 4s - loss: 1.0855e-05 - acc: 1.000 - ETA: 3s - loss: 1.0430e-05 - acc: 1.000 - ETA: 3s - loss: 8.7344e-06 - acc: 1.000 - ETA: 3s - loss: 6.9950e-04 - acc: 1.000 - ETA: 3s - loss: 0.5667 - acc: 0.9492    - ETA: 3s - loss: 0.5648 - acc: 0.937 - ETA: 2s - loss: 0.5564 - acc: 0.928 - ETA: 2s - loss: 0.9141 - acc: 0.914 - ETA: 2s - loss: 0.8870 - acc: 0.916 - ETA: 2s - loss: 0.8204 - acc: 0.923 - ETA: 2s - loss: 0.7755 - acc: 0.926 - ETA: 2s - loss: 0.7278 - acc: 0.929 - ETA: 2s - loss: 0.6834 - acc: 0.933 - ETA: 2s - loss: 0.6468 - acc: 0.935 - ETA: 1s - loss: 0.6187 - acc: 0.937 - ETA: 1s - loss: 0.5863 - acc: 0.940 - ETA: 1s - loss: 0.5637 - acc: 0.942 - ETA: 1s - loss: 0.5376 - acc: 0.944 - ETA: 1s - loss: 0.5137 - acc: 0.947 - ETA: 1s - loss: 0.4925 - acc: 0.949 - ETA: 1s - loss: 0.4722 - acc: 0.951 - ETA: 0s - loss: 0.4534 - acc: 0.953 - ETA: 0s - loss: 0.4360 - acc: 0.955 - ETA: 0s - loss: 0.4198 - acc: 0.957 - ETA: 0s - loss: 0.4049 - acc: 0.958 - ETA: 0s - loss: 0.3781 - acc: 0.960 - ETA: 0s - loss: 0.3660 - acc: 0.961 - ETA: 0s - loss: 0.3555 - acc: 0.961 - 5s 137ms/step - loss: 0.3451 - acc: 0.9630 - val_loss: 1.6474 - val_acc: 0.8945\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - ETA: 5s - loss: 0.0107 - acc: 1.000 - ETA: 4s - loss: 0.0063 - acc: 1.000 - ETA: 4s - loss: 0.0051 - acc: 1.000 - ETA: 3s - loss: 0.0040 - acc: 1.000 - ETA: 3s - loss: 0.0032 - acc: 1.000 - ETA: 3s - loss: 0.0027 - acc: 1.000 - ETA: 3s - loss: 0.0026 - acc: 1.000 - ETA: 3s - loss: 0.0023 - acc: 1.000 - ETA: 3s - loss: 0.0070 - acc: 0.996 - ETA: 2s - loss: 0.0168 - acc: 0.990 - ETA: 2s - loss: 0.0153 - acc: 0.991 - ETA: 2s - loss: 0.0608 - acc: 0.987 - ETA: 2s - loss: 0.0572 - acc: 0.988 - ETA: 2s - loss: 0.0547 - acc: 0.988 - ETA: 2s - loss: 0.0513 - acc: 0.989 - ETA: 2s - loss: 0.0483 - acc: 0.990 - ETA: 2s - loss: 0.0455 - acc: 0.990 - ETA: 1s - loss: 0.0430 - acc: 0.991 - ETA: 1s - loss: 0.0408 - acc: 0.991 - ETA: 1s - loss: 0.0369 - acc: 0.992 - ETA: 1s - loss: 0.0353 - acc: 0.992 - ETA: 1s - loss: 0.0338 - acc: 0.992 - ETA: 1s - loss: 0.0324 - acc: 0.993 - ETA: 0s - loss: 0.0311 - acc: 0.993 - ETA: 0s - loss: 0.0299 - acc: 0.993 - ETA: 0s - loss: 0.0289 - acc: 0.994 - ETA: 0s - loss: 0.0280 - acc: 0.994 - ETA: 0s - loss: 0.0270 - acc: 0.994 - ETA: 0s - loss: 0.0261 - acc: 0.994 - ETA: 0s - loss: 0.0253 - acc: 0.994 - ETA: 0s - loss: 0.0245 - acc: 0.995 - 5s 138ms/step - loss: 0.0238 - acc: 0.9951 - val_loss: 1.9018 - val_acc: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv2d_layer1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv2d_layer2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_layer0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_layer0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_conv_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/bracket: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/epochs: 15</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.90625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_acc',\n",
    "    max_epochs=15,\n",
    "    directory='params',\n",
    "    hyperparameters=hp,\n",
    "    project_name='horse_or_human'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_layer0': 64, 'num_conv_layers': 3, 'conv2d_layer0': 16, 'dense_layer0': 256, 'conv2d_layer1': 64, 'conv2d_layer2': 16, 'tuner/epochs': 15, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 16)      9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,078,625\n",
      "Trainable params: 1,078,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
